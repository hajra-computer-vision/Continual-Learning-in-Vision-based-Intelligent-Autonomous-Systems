@article{wang_comprehensive_2024,
	title = {A Comprehensive Survey of Continual Learning: Theory, Method and Application},
	volume = {46},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {https://ieeexplore.ieee.org/document/10444954/},
	doi = {10.1109/TPAMI.2024.3367329},
	shorttitle = {A Comprehensive Survey of Continual Learning},
	pages = {5362--5383},
	number = {8},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	shortjournal = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
	author = {Wang, Liyuan and Zhang, Xingxing and Su, Hang and Zhu, Jun},
    year = {2024}
}

@inproceedings{castro2018end,
  title={End-to-end incremental learning},
  author={Castro, Francisco M and Mar{\'\i}n-Jim{\'e}nez, Manuel J and Guil, Nicol{\'a}s and Schmid, Cordelia and Alahari, Karteek},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={233--248},
  year={2018}
}

@article{hadsell_embracing_2020,
	title = {Embracing Change: Continual Learning in Deep Neural Networks},
	volume = {24},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661320302199},
	doi = {10.1016/j.tics.2020.09.004},
	shorttitle = {Embracing Change},
	pages = {1028--1040},
	number = {12},
	journal = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Hadsell, Raia and Rao, Dushyant and Rusu, Andrei A. and Pascanu, Razvan},
    year = {2020}
}

@inproceedings{kang2024continual,
  title={Continual Learning for Motion Prediction Model via Meta-Representation Learning and Optimal Memory Buffer Retention Strategy},
  author={Kang, DaeJun and Kum, Dongsuk and Kim, Sanmin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15438--15448},
  year={2024}
}

@inproceedings{truong2024conda,
  title={Conda: Continual unsupervised domain adaptation learning in visual perception for self-driving cars},
  author={Truong, Thanh-Dat and Helton, Pierce and Moustafa, Ahmed and Cothren, Jackson David and Luu, Khoa},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5642--5650},
  year={2024}
}

@article{hosseinzadeh2024reselect,
  title={ReSeleCT: A New Approach for Continual Learning with Application to Vehicle State Estimation},
  author={Hosseinzadeh, Arvin and Mehrizi, Reza Valiollahi and Pirani, Mohammad and Chenouri, Shojaeddin and Khajepour, Amir},
  journal={IEEE Transactions on Intelligent Vehicles},
  year={2024},
  publisher={IEEE}
}

@inproceedings{ng2023energy,
  title={Energy-Efficient Continual Learning for Autonomous Driving},
  author={Ng, Qi Ding and Loo, Chu Kiong and Pasupa, Kitsuchart and Dilokthanakul, Nat and Zhang, Jie},
  booktitle={2023 15th International Conference on Information Technology and Electrical Engineering (ICITEE)},
  pages={105--110},
  year={2023},
  organization={IEEE}
}

@article{cao2022autonomous,
  title={Autonomous driving policy continual learning with one-shot disengagement case},
  author={Cao, Zhong and Li, Xiang and Jiang, Kun and Zhou, Weitao and Liu, Xiaoyu and Deng, Nanshan and Yang, Diange},
  journal={IEEE Transactions on Intelligent Vehicles},
  volume={8},
  number={2},
  pages={1380--1391},
  year={2022},
  publisher={IEEE}
}

@inproceedings{lin2023rethinking,
  title={Rethinking Trajectory Prediction in Real-World Applications: An Online Task-Free Continual Learning Perspective},
  author={Lin, Yunlong and Li, Zirui and Gong, Cheng and Liu, Qi and Lu, Chao and Gong, Jianwei},
  booktitle={2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)},
  pages={5020--5026},
  year={2023},
  organization={IEEE}
}

@article{bao2023lifelong,
  title={Lifelong vehicle trajectory prediction framework based on generative replay},
  author={Bao, Peng and Chen, Zonghai and Wang, Jikai and Dai, Deyun and Zhao, Hao},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2023},
  publisher={IEEE}
}

@article{li2022few,
  title={Few-shot class-incremental learning via compact and separable features for fine-grained vehicle recognition},
  author={Li, De-Wang and Huang, Hua},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={11},
  pages={21418--21429},
  year={2022},
  publisher={IEEE}
}

@inproceedings{li2022class,
  title={Class-incremental gesture recognition learning with out-of-distribution detection},
  author={Li, Mingxue and Cong, Yang and Liu, Yuyang and Sun, Gan},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1503--1508},
  year={2022},
  organization={IEEE}
}

@article{verwimp2023clad,
  title={Clad: A realistic continual learning benchmark for autonomous driving},
  author={Verwimp, Eli and Yang, Kuo and Parisot, Sarah and Hong, Lanqing and McDonagh, Steven and P{\'e}rez-Pellitero, Eduardo and De Lange, Matthias and Tuytelaars, Tinne},
  journal={Neural Networks},
  volume={161},
  pages={659--669},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{zhang2022continual,
  title={Continual stereo matching of continuous driving scenes with growing architecture},
  author={Zhang, Chenghao and Tian, Kun and Fan, Bin and Meng, Gaofeng and Zhang, Zhaoxiang and Pan, Chunhong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18901--18910},
  year={2022}
}

@inproceedings{kalb2023principles,
  title={Principles of forgetting in domain-incremental semantic segmentation in adverse weather conditions},
  author={Kalb, Tobias and Beyerer, J{\"u}rgen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19508--19518},
  year={2023}
}

@article{knoedler2022improving,
  title={Improving pedestrian prediction models with self-supervised continual learning},
  author={Knoedler, Luzia and Salmi, Chadi and Zhu, Hai and Brito, Bruno and Alonso-Mora, Javier},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={2},
  pages={4781--4788},
  year={2022},
  publisher={IEEE}
}

@inproceedings{cui2025human,
  title={Human Motion Forecasting in Dynamic Domain Shifts: A Homeostatic Continual Test-Time Adaptation Framework},
  author={Cui, Qiongjie and Sun, Huaijiang and Li, Weiqing and Lu, Jianfeng and Li, Bin},
  booktitle={European Conference on Computer Vision},
  pages={435--453},
  year={2025},
  organization={Springer}
}

@inproceedings{guo2024continual,
  title={Continual Learning in an Open and Dynamic World},
  author={Guo, Yunhui},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={20},
  pages={22666--22666},
  year={2024}
}

@article{ma2021continual,
  title={Continual multi-agent interaction behavior prediction with conditional generative memory},
  author={Ma, Hengbo and Sun, Yaofeng and Li, Jiachen and Tomizuka, Masayoshi and Choi, Chiho},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={4},
  pages={8410--8417},
  year={2021},
  publisher={IEEE}
}

@inproceedings{bande2021online,
  title={Online model adaptation of autonomous underwater vehicles with LSTM networks},
  author={Bande, Miguel and Wehbe, Bilal},
  booktitle={OCEANS 2021: San Diego--Porto},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@inproceedings{yun2021conflicts,
  title={Conflicts between likelihood and knowledge distillation in task incremental learning for 3d object detection},
  author={Yun, Peng and Cen, Jun and Liu, Ming},
  booktitle={2021 International Conference on 3D Vision (3DV)},
  pages={575--585},
  year={2021},
  organization={IEEE}
}

@inproceedings{barbato2024continual,
  title={Continual road-scene semantic segmentation via feature-aligned symmetric multi-modal network},
  author={Barbato, Francesco and Camuffo, Elena and Milani, Simone and Zanuttigh, Pietro},
  booktitle={2024 IEEE International Conference on Image Processing (ICIP)},
  pages={722--728},
  year={2024},
  organization={IEEE}
}

@article{zhi2023adaptive,
  title={Adaptive trajectory prediction without catastrophic forgetting},
  author={Zhi, ChunYu and Sun, HuaiJiang and Xu, Tian},
  journal={The Journal of Supercomputing},
  volume={79},
  number={14},
  pages={15579--15596},
  year={2023},
  publisher={Springer}
}

@inproceedings{liang2024aide,
  title={AIDE: An Automatic Data Engine for Object Detection in Autonomous Driving},
  author={Liang, Mingfu and Su, Jong-Chyi and Schulter, Samuel and Garg, Sparsh and Zhao, Shiyu and Wu, Ying and Chandraker, Manmohan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14695--14706},
  year={2024}
}
@article{vCLIMB,
  author       = {Andr{\'{e}}s Villa and
                  Kumail Alhamoud and
                  Juan Le{\'{o}}n Alc{\'{a}}zar and
                  Fabian Caba Heilbron and
                  Victor Escorcia and
                  Bernard Ghanem},
  title        = {vCLIMB: {A} Novel Video Class Incremental Learning Benchmark},
  journal      = {CoRR},
  volume       = {abs/2201.09381},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.09381},
  eprinttype    = {arXiv},
  eprint       = {2201.09381},
  timestamp    = {Thu, 23 Jun 2022 20:00:33 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2201-09381.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

'
@article{OpenLORIS,
  author       = {Qi She and
                  Fan Feng and
                  Xinyue Hao and
                  Qihan Yang and
                  Chuanlin Lan and
                  Vincenzo Lomonaco and
                  Xuesong Shi and
                  Zhengwei Wang and
                  Yao Guo and
              Yimin Zhang and
                  Fei Qiao and
                  Rosa H. M. Chan},
  title        = {OpenLORIS-Object: {A} Dataset and Benchmark towards Lifelong Object
                  Recognition},
  journal      = {CoRR},
  volume       = {abs/1911.06487},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.06487},
  eprinttype    = {arXiv},
  eprint       = {1911.06487},
  timestamp    = {Tue, 31 Aug 2021 13:57:12 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1911-06487.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
 @article{zhou2017places,
   title={Places: A 10 million Image Database for Scene Recognition},
   author={Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
   year={2017},
   publisher={IEEE}
 }

@inproceedings{openlongtailrecognition,
  title={Large-Scale Long-Tailed Recognition in an Open World},
  author={Liu, Ziwei and Miao, Zhongqi and Zhan, Xiaohang and Wang, Jiayun and Gong, Boqing and Yu, Stella X.},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}
@article{EndlessCL,
  author       = {Timm Hess and
                  Martin Mundt and
                  Iuliia Pliushch and
                  Visvanathan Ramesh},
  title        = {A Procedural World Generation Framework for Systematic Evaluation
                  of Continual Learning},
  journal      = {CoRR},
  volume       = {abs/2106.02585},
  year         = {2021},
  url          = {https://arxiv.org/abs/2106.02585},
  eprinttype    = {arXiv},
  eprint       = {2106.02585},
  timestamp    = {Thu, 10 Jun 2021 16:34:18 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2106-02585.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@InProceedings{Roady_2020_Stream51,
	author = {Roady, Ryne and Hayes, Tyler L. and Vaidya, Hitesh and Kanan, Christopher},
	title = {Stream-51: Streaming Classification and Novelty Detection From Videos},
	booktitle = {The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
	month = {June},
	year = {2020}
}


@InProceedings{Core50,
  title = 	 {CORe50: a New Dataset and Benchmark for Continuous Object Recognition},
  author = 	 {Lomonaco, Vincenzo and Maltoni, Davide},
  booktitle = 	 {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = 	 {17--26},
  year = 	 {2017},
  editor = 	 {Levine, Sergey and Vanhoucke, Vincent and Goldberg, Ken},
  volume = 	 {78},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Nov},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v78/lomonaco17a/lomonaco17a.pdf},
  url = 	 {https://proceedings.mlr.press/v78/lomonaco17a.html},
  abstract = 	 {Continuous/Lifelong learning of high-dimensional data streams is a challenging research problem. In fact, fully retraining models each time new data become available is infeasible, due to computational and storage issues, while naïve incremental strategies have been shown to suffer from catastrophic forgetting. In the context of real-world object recognition applications (e.g., robotic vision), where continuous learning is crucial, very few datasets and benchmarks are available to evaluate and compare emerging techniques. In this work we propose a new dataset and benchmark CORe50, specifically designed for continuous object recognition, and introduce baseline approaches for different continuous learning scenarios.}
}
@InProceedings{CRIB,
author = {Stojanov, Stefan and Mishra, Samarth and Thai, Ngoc Anh and Dhanda, Nikhil and Humayun, Ahmad and Yu, Chen and Smith, Linda B. and Rehg, James M.},
title = {Incremental Object Learning From Contiguous Views},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}
@InProceedings{CRLMaze,
author = {Lomonaco, Vincenzo and Desai, Karan and Culurciello, Eugenio and Maltoni, Davide},
title = {Continual Reinforcement Learning in 3D Non-Stationary Environments},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2020}
}
@article{SlimageNET,
  author       = {Antreas Antoniou and
                  Massimiliano Patacchiola and
                  Mateusz Ochal and
                  Amos J. Storkey},
  title        = {Defining Benchmarks for Continual Few-Shot Learning},
  journal      = {CoRR},
  volume       = {abs/2004.11967},
  year         = {2020},
  url          = {https://arxiv.org/abs/2004.11967},
  eprinttype    = {arXiv},
  eprint       = {2004.11967},
  timestamp    = {Tue, 28 Apr 2020 16:10:02 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2004-11967.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{CALM,
  author       = {Germ{\'{a}}n Kruszewski and
                  Ionut{-}Teodor Sorodoc and
                  Tom{\'{a}}s Mikolov},
  title        = {Class-Agnostic Continual Learning of Alternating Languages and Domains},
  journal      = {CoRR},
  volume       = {abs/2004.03340},
  year         = {2020},
  url          = {https://arxiv.org/abs/2004.03340},
  eprinttype    = {arXiv},
  eprint       = {2004.03340},
  timestamp    = {Mon, 28 Dec 2020 11:31:01 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2004-03340.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{icup,
author = {Pasquale, Giulia and Ciliberto, Carlo and Rosasco, Lorenzo and Natale, Lorenzo},
year = {2016},
month = {10},
pages = {4904-4911},
title = {Object identification from few examples by improving the invariance of a Deep Convolutional Neural Network},
doi = {10.1109/IROS.2016.7759720}
}
@INPROCEEDINGS{10591909robotics1,
  author={Zhang, Yuyang and Zheng, Zhi},
  booktitle={2024 IEEE 18th International Conference on Control & Automation (ICCA)}, 
  title={A Learning Framework Combining Distillation-Generated Replay and Development Network in Continual Visual Scene Cognition for Autonomous Robot}, 
  year={2024},
  volume={},
  number={},
  pages={892-899},
  keywords={Knowledge engineering;Training;Visualization;Incremental learning;Training data;Interference;Generators;Distillation;Generated Replay;Developmental Neural Network;Catastrophic Forgetting},
  doi={10.1109/ICCA62789.2024.10591909}}
@INPROCEEDINGS{9812108robotics2,
  author={Hussein, Mohammad Haj and Ibrahim, Batool and Elhajj, Imad H. and Asmar, Daniel},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)}, 
  title={Incremental Learning for Enhanced Personalization of Autocomplete Teleoperation}, 
  year={2022},
  volume={},
  number={},
  pages={515-521},
  keywords={Representation learning;Deep learning;Adaptation models;Automation;System performance;Transfer learning;User experience},
  doi={10.1109/ICRA46639.2022.9812108}
}
@INPROCEEDINGS{10611053roboticsregression1,
  author={Uhlmann, Eckart and Polte, Mitchel and Blumberg, Julian and Yin, Sheng and Wang, Gang},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Increasing the Absolute Position Accuracy of Industrial Robots by Means of a Deep Continual Evidential Regression Model *}, 
  year={2024},
  volume={},
  number={},
  pages={4774-4780},
  keywords={Training;Continuing education;Productivity;Accuracy;Uncertainty;Service robots;Kinematics},
  doi={10.1109/ICRA57147.2024.10611053}
}
@inproceedings{wang2024universalmedicalimageregistration,
  title={Toward Universal Medical Image Registration via Sharpness-Aware Meta-Continual Learning},
  author={Wang, Bomin and Luo, Xinzhe and Zhuang, Xiahai},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={739--748},
  year={2024},
  organization={Springer}
}
@inproceedings{pellegrini2009youllrr11,
title={You'll never walk alone: Modeling social behavior for multi-target tracking},
author={Pellegrini, Stefano and Ess, Andreas and Schindler, Konrad and van Gool, Luc},
booktitle={Proc. IEEE 12th Int. Conf. Comput. Vis.},
pages={261--268},
year={2009}
}
@article{lerner2007crowdsrr12,
title={Crowds by example},
author={Lerner, Alon and Chrysanthou, Yiorgos and Lischinski, Dani},
journal={Comput. Graph. Forum},
volume={26},
number={3},
pages={655--664},
year={2007}
}
@ARTICLE{9730039roboticsregression3,
  author={Piqué, Francesco and Kalidindi, Hari Teja and Fruzzetti, Lorenzo and Laschi, Cecilia and Menciassi, Arianna and Falotico, Egidio},
  journal={IEEE Robotics and Automation Letters}, 
  title={Controlling Soft Robotic Arms Using Continual Learning}, 
  year={2022},
  volume={7},
  number={2},
  pages={5469-5476},
  keywords={Soft robotics;Robots;Task analysis;Mathematical models;Computational modeling;Loading;Training;Modeling;control;and learning for soft robots;learning and adaptive systems;soft robot applications},
  doi={10.1109/LRA.2022.3157369}}

@ARTICLE{10171996roboticsregression4,
  author={Karlsson, Robin and Carballo, Alexander and Lepe-Salazar, Francisco and Fujii, Keisuke and Ohtani, Kento and Takeda, Kazuya},
  journal={IEEE Robotics and Automation Letters}, 
  title={Learning to Predict Navigational Patterns From Partial Observations}, 
  year={2023},
  volume={8},
  number={9},
  pages={5592-5599},
  keywords={Navigation;Predictive models;Trajectory;Semantics;Visualization;Roads;Vehicle dynamics;Vision-based navigation;semantic scene understanding;continual learning;learning from experience;motion and path planning},
  doi={10.1109/LRA.2023.3291924}}

@INPROCEEDINGS{9811658roboticsdetection1,
  author={Gao, Dasong and Wang, Chen and Scherer, Sebastian},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)}, 
  title={AirLoop: Lifelong Loop Closure Detection}, 
  year={2022},
  volume={},
  number={},
  pages={10664-10671},
  keywords={Training;Simultaneous localization and mapping;Automation;Atmospheric modeling;Detectors;Data models;Robustness},
  doi={10.1109/ICRA46639.2022.9811658}}

@inproceedings{Wang2020Tartanair,
  title={Tartanair: A dataset to push the limits of visual slam},
  author={Wang, W. and Zhu, D. and Wang, X. and Hu, Y. and Qiu, Y. and Wang, C. et al.},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year={2020}
}
@article{RobotCar,
  title={1 Year 1000km: The Oxford RobotCar Dataset},
  author={Maddern, W. and Pascoe, G. and Linegar, C. and Newman, P.},
  journal={The International Journal of Robotics Research (IJRR)},
  volume={36},
  number={1},
  pages={3--15},
  year={2017}
}

@INPROCEEDINGS{9811856roboticsdetection2,
  author={Li, Yiting and Zhu, Haiyue and Tian, Sichao and Feng, Fan and Ma, Jun and Teo, Chek Sing and Xiang, Cheng and Vadakkepat, Prahlad and Lee, Tong Heng},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)}, 
  title={Incremental Few-Shot Object Detection for Robotics}, 
  year={2022},
  volume={},
  number={},
  pages={8447-8453},
  keywords={Training;Representation learning;Performance evaluation;Degradation;Image edge detection;Training data;Object detection},
  doi={10.1109/ICRA46639.2022.9811856}}

@INPROCEEDINGS{9981671roboticsdetection3,
  author={Belgiovine, Giulia and Gonzlez-Billandon, Jonas and Sciutti, Alessandra and Sandini, Giulio and Rea, Francesco},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={HRI Framework for Continual Learning in Face Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={8226-8233},
  keywords={Databases;Face recognition;Transfer learning;Social robots;Buildings;Robot sensing systems;Data models},
  doi={10.1109/IROS47612.2022.9981671}}
@misc{johnson2019mimiccxrjpglargepubliclyavailable,
      title={MIMIC-CXR-JPG, a large publicly available database of labeled chest radiographs}, 
      author={Alistair E. W. Johnson and Tom J. Pollard and Nathaniel R. Greenbaum and Matthew P. Lungren and Chih-ying Deng and Yifan Peng and Zhiyong Lu and Roger G. Mark and Seth J. Berkowitz and Steven Horng},
      year={2019},
      eprint={1901.07042},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1901.07042}, 
}
@article{doi:10.1148/ryai.230024,
author = {Wasserthal, Jakob and Breit, Hanns-Christian and Meyer, Manfred T. and Pradella, Maurice and Hinck, Daniel and Sauter, Alexander W. and Heye, Tobias and Boll, Daniel T. and Cyriac, Joshy and Yang, Shan and Bach, Michael and Segeroth, Martin},
title = {TotalSegmentator: Robust Segmentation of 104 Anatomic Structures in CT Images},
journal = {Radiology: Artificial Intelligence},
volume = {5},
number = {5},
pages = {e230024},
year = {2023},
doi = {10.1148/ryai.230024},

URL = { 
    
        https://doi.org/10.1148/ryai.230024
    
    

},
eprint = { 
    
        https://doi.org/10.1148/ryai.230024
    
    

}
,
    abstract = { Purpose To present a deep learning segmentation model that can automatically and robustly segment all major anatomic structures on body CT images. Materials and Methods In this retrospective study, 1204 CT examinations (from 2012, 2016, and 2020) were used to segment 104 anatomic structures (27 organs, 59 bones, 10 muscles, and eight vessels) relevant for use cases such as organ volumetry, disease characterization, and surgical or radiation therapy planning. The CT images were randomly sampled from routine clinical studies and thus represent a real-world dataset (different ages, abnormalities, scanners, body parts, sequences, and sites). The authors trained an nnU-Net segmentation algorithm on this dataset and calculated Dice similarity coefficients to evaluate the model’s performance. The trained algorithm was applied to a second dataset of 4004 whole-body CT examinations to investigate age-dependent volume and attenuation changes. Results The proposed model showed a high Dice score (0.943) on the test set, which included a wide range of clinical data with major abnormalities. The model significantly outperformed another publicly available segmentation model on a separate dataset (Dice score, 0.932 vs 0.871; P < .001). The aging study demonstrated significant correlations between age and volume and mean attenuation for a variety of organ groups (eg, age and aortic volume [rs = 0.64; P < .001]; age and mean attenuation of the autochthonous dorsal musculature [rs = −0.74; P < .001]). Conclusion The developed model enables robust and accurate segmentation of 104 anatomic structures. The annotated dataset (https://doi.org/10.5281/zenodo.6802613) and toolkit (https://www.github.com/wasserth/TotalSegmentator) are publicly available. Keywords: CT, Segmentation, Neural Networks Supplemental material is available for this article. © RSNA, 2023 See also commentary by Sebro and Mongan in this issue. }
}
@article{Yang_2023,
   title={MedMNIST v2 - A large-scale lightweight benchmark for 2D and 3D biomedical image classification},
   volume={10},
   ISSN={2052-4463},
   url={http://dx.doi.org/10.1038/s41597-022-01721-8},
   DOI={10.1038/s41597-022-01721-8},
   number={1},
   journal={Scientific Data},
   publisher={Springer Science and Business Media LLC},
   author={Yang, Jiancheng and Shi, Rui and Wei, Donglai and Liu, Zequan and Zhao, Lin and Ke, Bilian and Pfister, Hanspeter and Ni, Bingbing},
   year={2023},
   month=jan }
@article{10.1093/gigascience/giy065,
    author = {Litjens, Geert and Bandi, Peter and Ehteshami Bejnordi, Babak and Geessink, Oscar and Balkenhol, Maschenka and Bult, Peter and Halilovic, Altuna and Hermsen, Meyke and van de Loo, Rob and Vogels, Rob and Manson, Quirine F and Stathonikos, Nikolas and Baidoshvili, Alexi and van Diest, Paul and Wauters, Carla and van Dijk, Marcory and van der Laak, Jeroen},
    title = {1399 H\&amp;E-stained sentinel lymph node sections of breast cancer patients: the CAMELYON dataset},
    journal = {GigaScience},
    volume = {7},
    number = {6},
    pages = {giy065},
    year = {2018},
    month = {05},
    abstract = {The presence of lymph node metastases is one of the most important factors in breast cancer prognosis. The most common way to assess regional lymph node status is the sentinel lymph node procedure. The sentinel lymph node is the most likely lymph node to contain metastasized cancer cells and is excised, histopathologically processed, and examined by a pathologist. This tedious examination process is time-consuming and can lead to small metastases being missed. However, recent advances in whole-slide imaging and machine learning have opened an avenue for analysis of digitized lymph node sections with computer algorithms. For example, convolutional neural networks, a type of machine-learning algorithm, can be used to automatically detect cancer metastases in lymph nodes with high accuracy. To train machine-learning models, large, well-curated datasets are needed.We released a dataset of 1,399 annotated whole-slide images (WSIs) of lymph nodes, both with and without metastases, in 3 terabytes of data in the context of the CAMELYON16 and CAMELYON17 Grand Challenges. Slides were collected from five medical centers to cover a broad range of image appearance and staining variations. Each WSI has a slide-level label indicating whether it contains no metastases, macro-metastases, micro-metastases, or isolated tumor cells. Furthermore, for 209 WSIs, detailed hand-drawn contours for all metastases are provided. Last, open-source software tools to visualize and interact with the data have been made available.A unique dataset of annotated, whole-slide digital histopathology images has been provided with high potential for re-use.},
    issn = {2047-217X},
    doi = {10.1093/gigascience/giy065},
    url = {https://doi.org/10.1093/gigascience/giy065},
    eprint = {https://academic.oup.com/gigascience/article-pdf/7/6/giy065/60709038/gigascience\_7\_6\_giy065.pdf},
}

@misc{guttag2010chb,
    author = {Guttag, John},
    title = {CHB-MIT Scalp EEG Database},
    version = {1.0.0},
    year = {2010},
    publisher = {PhysioNet},
    doi = {10.13026/C2K

}
}

@article{Perkonigg2021,
author = {Perkonigg, Matthias and Hofmanninger, Johannes and Herold, Christian J. and Brink, James A. and Pianykh, Oleg and Prosch, Helmut and Langs, Georg},
title = {Dynamic memory to alleviate catastrophic forgetting in continual learning with medical imaging},
journal = {Nature Communications},
volume = {12},
number = {1},
pages = {5678},
year = {2021},
doi = {10.1038/s41467-021-25858-z},
url = {https://doi.org/10.1038/s41467-021-25858-z}
}

@article{Kiyasseh2021,
author = {Kiyasseh, D. and Zhu, T. and Clifton, D. A.},
title = {A clinical deep learning framework for continually learning from cardiac signals across diseases, time, modalities, and institutions},
journal = {Nat Commun},
volume = {12},
pages = {4221},
year = {2021},
doi = {10.1038/s41467-021-24483-0}
}

@inproceedings{ji2023continualsegmentsingleunified,
  title={Continual segment: Towards a single, unified and non-forgetting continual segmentation model of 143 whole-body organs in ct scans},
  author={Ji, Zhanghexuan and Guo, Dazhou and Wang, Puyang and Yan, Ke and Lu, Le and Xu, Minfeng and Wang, Qifeng and Ge, Jia and Gao, Mingchen and Ye, Xianghua and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={21140--21151},
  year={2023}
}
@article{BANDI2023102755,
title = {Continual learning strategies for cancer-independent detection of lymph node metastases},
journal = {Medical Image Analysis},
volume = {85},
pages = {102755},
year = {2023},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2023.102755},
url = {https://www.sciencedirect.com/science/article/pii/S1361841523000166},
author = {Péter Bándi and Maschenka Balkenhol and Marcory {van Dijk} and Michel Kok and Bram {van Ginneken} and Jeroen {van der Laak} and Geert Litjens},
keywords = {Cancer, Lymph node, Deep learning, Convolutional neural network, Continual learning},
abstract = {Recently, large, high-quality public datasets have led to the development of convolutional neural networks that can detect lymph node metastases of breast cancer at the level of expert pathologists. Many cancers, regardless of the site of origin, can metastasize to lymph nodes. However, collecting and annotating high-volume, high-quality datasets for every cancer type is challenging. In this paper we investigate how to leverage existing high-quality datasets most efficiently in multi-task settings for closely related tasks. Specifically, we will explore different training and domain adaptation strategies, including prevention of catastrophic forgetting, for breast, colon and head-and-neck cancer metastasis detection in lymph nodes. Our results show state-of-the-art performance on colon and head-and-neck cancer metastasis detection tasks. We show the effectiveness of adaptation of networks from one cancer type to another to obtain multi-task metastasis detection networks. Furthermore, we show that leveraging existing high-quality datasets can significantly boost performance on new target tasks and that catastrophic forgetting can be effectively mitigated.Last, we compare different mitigation strategies.}
}
@INPROCEEDINGS{10341107Wei,
  author={Wei, Bo-Quan and Chen, Jen-Jee and Tseng, Yu-Chee and Kuo, Po-Tsun Paul},
  booktitle={2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={Representative Data Selection for Efficient Medical Incremental Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  keywords={Training;Industries;Adaptation models;Semantic segmentation;Biological system modeling;Data models;Stability analysis;Adversarial network;continual learning;data management;incremental learning;variational autoencoder},
  doi={10.1109/EMBC40787.2023.10341107}}

@article{González2023,
author = {González, Camila and Ranem, Amin and Pinto dos Santos, Daniel and Othman, Ahmed and Mukhopadhyay, Anirban},
title = {Lifelong nnU-Net: a framework for standardized medical continual learning},
journal = {Scientific Reports},
volume = {13},
number = {1},
pages = {9381},
year = {2023},
doi = {10.1038/s41598-023-34484-2}
}
@inproceedings{Armstrong_2022,
   title={Continual learning of longitudinal health records},
   url={http://dx.doi.org/10.1109/BHI56158.2022.9926878},
   DOI={10.1109/bhi56158.2022.9926878},
   booktitle={2022 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)},
   publisher={IEEE},
   author={Armstrong, Jacob and Clifton, David A.},
   year={2022},
   month=sep, pages={01–06} }

@ARTICLE{10164249PC,
  author={Sun, Le and Chen, Qingyuan and Zheng, Min and Ning, Xin and Gupta, Deepak and Tiwari, Prayag},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Energy-efficient Online Continual Learning for Time Series Classification in Nanorobot-based Smart Health}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  keywords={Prototypes;Time series analysis;Task analysis;Feature extraction;Classification algorithms;Training;Nanobioscience;sensor time series classification;smart health;concept drift;online continual learning;nanorobot},
  doi={10.1109/JBHI.2023.3289992}}
@misc{li2024doctormultidiseasedetectioncontinual,
      title={DOCTOR: A Multi-Disease Detection Continual Learning Framework Based on Wearable Medical Sensors}, 
      author={Chia-Hao Li and Niraj K. Jha},
      year={2024},
      eprint={2305.05738},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.05738}, 
}
@article{Gamel2024,
  author    = {S. A. Gamel and F. M. Talaat},
  title     = {SleepSmart: An IoT-Enabled Continual Learning Algorithm for Intelligent Sleep Enhancement},
  journal   = {Neural Computing and Applications},
  volume    = {36},
  pages     = {4293--4309},
  year      = {2024},
  month     = {March},
  doi       = {10.1007/s00521-023-09310-5},
  url       = {https://doi.org/10.1007/s00521-023-09310-5},
  received  = {20 April 2023},
  accepted  = {16 November 2023},
  published = {11 December 2023}
}
@inproceedings{dadashzadeh2023pecopparameterefficientcontinual,
  title={Pecop: Parameter efficient continual pretraining for action quality assessment},
  author={Dadashzadeh, Amirhossein and Duan, Shuchao and Whone, Alan and Mirmehdi, Majid},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={42--52},
  year={2024}
}
@article{Saygili2023,
  author    = {G{\"o}zde Saygili and B{\"u}sra Ozgode Yigin},
  title     = {Continual learning approaches for single cell RNA sequencing data},
  journal   = {Scientific Reports},
  volume    = {13},
  pages     = {15286},
  year      = {2023},
  doi       = {10.1038/s41598-023-42482-7},
  url       = {https://doi.org/10.1038/s41598-023-42482-7},
  received  = {2023-06-06},
  accepted  = {2023-09-11},
  published = {2023-09-15}
}
@ARTICLE{9265181batbaatar,
  author={Batbaatar, Erdenebileg and Park, Kwang Ho and Amarbayasgalan, Tsatsral and Davagdorj, Khishigsuren and Munkhdalai, Lkhagvadorj and Pham, Van-Huy and Ryu, Keun Ho},
  journal={IEEE Access}, 
  title={Class-Incremental Learning With Deep Generative Feature Replay for DNA Methylation-Based Cancer Classification}, 
  year={2020},
  volume={8},
  number={},
  pages={210800-210815},
  keywords={Cancer;DNA;Task analysis;Data models;Computational modeling;Feature extraction;Biological system modeling;Computational biology;deep learning;class-incremental learning;continual learning;deep generative model;variational autoencoder;DNA methylation;cancer classification},
  doi={10.1109/ACCESS.2020.3039624}}

@article{Amrollahi2022,
  author    = {Farzaneh Amrollahi and Shashikumar P. Shashikumar and A. Lindsay Holder and others},
  title     = {Leveraging clinical data across healthcare institutions for continual learning of predictive risk models},
  journal   = {Scientific Reports},
  volume    = {12},
  pages     = {8380},
  year      = {2022},
  doi       = {10.1038/s41598-022-12497-7},
  url       = {https://doi.org/10.1038/s41598-022-12497-7},
  received  = {2022-01-13},
  accepted  = {2022-05-11},
  published = {2022-05-19}
}


@article{MESEGUER2024102870,
title = {MICIL: Multiple-Instance Class-Incremental Learning for skin cancer whole slide images},
journal = {Artificial Intelligence in Medicine},
volume = {152},
pages = {102870},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102870},
url = {https://www.sciencedirect.com/science/article/pii/S093336572400112X},
author = {Pablo Meseguer and Rocío {del Amor} and Valery Naranjo},
keywords = {Skin cancer, Whole slide images, Multiple instance learning, Class-incremental learning, Knowledge distillation},
abstract = {Artificial intelligence (AI) agents encounter the problem of catastrophic forgetting when they are trained in sequentially with new data batches. This issue poses a barrier to the implementation of AI-based models in tasks that involve ongoing evolution, such as cancer prediction. Moreover, whole slide images (WSI) play a crucial role in cancer management, and their automated analysis has become increasingly popular in assisting pathologists during the diagnosis process. Incremental learning (IL) techniques aim to develop algorithms capable of retaining previously acquired information while also acquiring new insights to predict future data. Deep IL techniques need to address the challenges posed by the gigapixel scale of WSIs, which often necessitates the use of multiple instance learning (MIL) frameworks. In this paper, we introduce an IL algorithm tailored for analyzing WSIs within a MIL paradigm. The proposed Multiple Instance Class-Incremental Learning (MICIL) algorithm combines MIL with class-IL for the first time, allowing for the incremental prediction of multiple skin cancer subtypes from WSIs within a class-IL scenario. Our framework incorporates knowledge distillation and data rehearsal, along with a novel embedding-level distillation, aiming to preserve the latent space at the aggregated WSI level. Results demonstrate the algorithm’s effectiveness in addressing the challenge of balancing IL-specific metrics, such as intransigence and forgetting, and solving the plasticity-stability dilemma.}
}
@article{GAO2023102290,
title = {Incremental learning for an evolving stream of medical ultrasound images via counterfactual thinking},
journal = {Computerized Medical Imaging and Graphics},
volume = {109},
pages = {102290},
year = {2023},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2023.102290},
url = {https://www.sciencedirect.com/science/article/pii/S0895611123001088},
author = {Junling Gao and Lei Xu and Mingxi Wan},
keywords = {Medical ultrasound images, Classification, Incremental classifier, Continual learning, Counterfactual thinking},
abstract = {Despite the fact that traditional deep learning (DL) approaches provide promising accuracy and efficiency in medical ultrasound image analysis, they cannot replace the physician in making a diagnosis since the DL model is only appropriate in static application scenarios. Currently, most DL-based models are incapable of learning new tasks in the dynamic clinical environments due to the catastrophic forgetting of old tasks. To address the above problem, we propose an incremental classifier that is sequentially trained on evolving tasks for medical ultrasound images by counterfactual thinking. Specifically, the proposed model consists of a feature extractor and a classifier that can add new classes at any time during training. Toward a more discriminative model in the continual learning setting, a contrastive strategy is designed to leverage fine-grained information by generating a series of counterfactual regions. For model optimization, we design a multi-task loss made up of a knowledge distillation loss, a cross-entropy loss, and a contrasting loss. This objective jointly enjoys the merits of less forgetting, better accuracy, and fine-grained information utilization. A newly collected dataset with 52 medical ultrasound classification tasks is used to demonstrate the effectiveness of our method. The proposed approach achieves 76.59%, 11.67%, and 7.93% in terms of the average incremental accuracy, forgetting rate, and feature retention, respectively.}
}
@misc{bordes_introduction_2024,
	title = {An Introduction to Vision-Language Modeling},
	url = {http://arxiv.org/abs/2405.17247},
	abstract = {Following the recent popularity of Large Language Models ({LLMs}), several attempts have been made to extend them to the visual domain. From having a visual assistant that could guide us through unfamiliar environments to generative models that produce images using only a high-level text description, the vision-language model ({VLM}) applications will significantly impact our relationship with technology. However, there are many challenges that need to be addressed to improve the reliability of those models. While language is discrete, vision evolves in a much higher dimensional space in which concepts cannot always be easily discretized. To better understand the mechanics behind mapping vision to language, we present this introduction to {VLMs} which we hope will help anyone who would like to enter the field. First, we introduce what {VLMs} are, how they work, and how to train them. Then, we present and discuss approaches to evaluate {VLMs}. Although this work primarily focuses on mapping images to language, we also discuss extending {VLMs} to videos.},
	number = {{arXiv}:2405.17247},
	publisher = {{arXiv}},
	author = {Bordes, Florian and Pang, Richard Yuanzhe and Ajay, Anurag and Li, Alexander C. and Bardes, Adrien and Petryk, Suzanne and Mañas, Oscar and Lin, Zhiqiu and Mahmoud, Anas and Jayaraman, Bargav and Ibrahim, Mark and Hall, Melissa and Xiong, Yunyang and Lebensold, Jonathan and Ross, Candace and Jayakumar, Srihari and Guo, Chuan and Bouchacourt, Diane and Al-Tahan, Haider and Padthe, Karthik and Sharma, Vasu and Xu, Hu and Tan, Xiaoqing Ellen and Richards, Megan and Lavoie, Samuel and Astolfi, Pietro and Hemmat, Reyhane Askari and Chen, Jun and Tirumala, Kushal and Assouel, Rim and Moayeri, Mazda and Talattof, Arjang and Chaudhuri, Kamalika and Liu, Zechun and Chen, Xilun and Garrido, Quentin and Ullrich, Karen and Agrawal, Aishwarya and Saenko, Kate and Celikyilmaz, Asli and Chandra, Vikas},
	urldate = {2024-09-14},
	date = {2024-05-27},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2405.17247 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\SRXGTBZY\\Bordes et al. - 2024 - An Introduction to Vision-Language Modeling.pdf:application/pdf},
}

@misc{smith_coda-prompt_2023,
	title = {{CODA}-Prompt: {COntinual} Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning},
	url = {http://arxiv.org/abs/2211.13218},
	shorttitle = {{CODA}-Prompt},
	abstract = {Computer vision models suffer from a phenomenon known as catastrophic forgetting when learning novel concepts from continuously shifting training data. Typical solutions for this continual learning problem require extensive rehearsal of previously seen data, which increases memory costs and may violate data privacy. Recently, the emergence of large-scale pre-trained vision transformer models has enabled prompting approaches as an alternative to data-rehearsal. These approaches rely on a key-query mechanism to generate prompts and have been found to be highly resistant to catastrophic forgetting in the well-established rehearsal-free continual learning setting. However, the key mechanism of these methods is not trained end-to-end with the task sequence. Our experiments show that this leads to a reduction in their plasticity, hence sacrificing new task accuracy, and inability to benefit from expanded parameter capacity. We instead propose to learn a set of prompt components which are assembled with input-conditioned weights to produce input-conditioned prompts, resulting in a novel attention-based end-to-end key-query scheme. Our experiments show that we outperform the current {SOTA} method {DualPrompt} on established benchmarks by as much as 4.5\% in average final accuracy. We also outperform the state of art by as much as 4.4\% accuracy on a continual learning benchmark which contains both class-incremental and domain-incremental task shifts, corresponding to many practical settings. Our code is available at https://github.com/{GT}-{RIPL}/{CODA}-Prompt},
	number = {{arXiv}:2211.13218},
	publisher = {{arXiv}},
	author = {Smith, James Seale and Karlinsky, Leonid and Gutta, Vyshnavi and Cascante-Bonilla, Paola and Kim, Donghyun and Arbelle, Assaf and Panda, Rameswar and Feris, Rogerio and Kira, Zsolt},
	urldate = {2024-09-14},
	date = {2023-03-30},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2211.13218 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\ELFAGZGB\\Smith et al. - 2023 - CODA-Prompt COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning.pdf:application/pdf},
}

@article{li_generative_nodate,
	title = {Generative Image Dynamics},
	abstract = {We present an approach to modeling an image-space prior on scene motion. Our prior is learned from a collection of motion trajectories extracted from real video sequences depicting natural, oscillatory dynamics of objects such as trees, ﬂowers, candles, and clothes swaying in the wind. We model dense, long-term motion in the Fourier domain as spectral volumes, which we ﬁnd are well-suited to prediction with diffusion models. Given a single image, our trained model uses a frequency-coordinated diffusion sampling process to predict a spectral volume, which can be converted into a motion texture that spans an entire video. Along with an imagebased rendering module, the predicted motion representation can be used for a number of downstream applications, such as turning still images into seamlessly looping videos, or allowing users to interact with objects in real images, producing realistic simulated dynamics (by interpreting the spectral volumes as image-space modal bases). See our project page for more results: generative-dynamics.github.io.},
	author = {Li, Zhengqi and Tucker, Richard and Snavely, Noah and Holynski, Aleksander},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\WZKYY4FQ\\Li et al. - Generative Image Dynamics.pdf:application/pdf},
}

@article{ni_enhancing_nodate,
	title = {Enhancing Visual Continual Learning with Language-Guided Supervision},
	author = {Ni, Bolin and Zhao, Hongbo and Zhang, Chenghao and Hu, Ke and Meng, Gaofeng and Zhang, Zhaoxiang and Xiang, Shiming},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\RMASP9QU\\Ni et al. - Enhancing Visual Continual Learning with Language-Guided Supervision.pdf:application/pdf},
}

@misc{aleem_test-time_2024,
	title = {Test-Time Adaptation with {SaLIP}: A Cascade of {SAM} and {CLIP} for Zero shot Medical Image Segmentation},
	url = {http://arxiv.org/abs/2404.06362},
	shorttitle = {Test-Time Adaptation with {SaLIP}},
	abstract = {The Segment Anything Model ({SAM}) and {CLIP} are remarkable vision foundation models ({VFMs}). {SAM}, a prompt-driven segmentation model, excels in segmentation tasks across diverse domains, while {CLIP} is renowned for its zero-shot recognition capabilities. However, their unified potential has not yet been explored in medical image segmentation. To adapt {SAM}, to medical imaging, existing methods primarily rely on tuning strategies that require extensive data or prior prompts tailored to the specific task, making it particularly challenging when only a limited number of data samples are available. This work presents an in-depth exploration of integrating {SAM} and {CLIP} into a unified framework for medical image segmentation. Specifically, we propose a simple unified framework, {SaLIP}, for organ segmentation. Initially, {SAM} is used for part-based segmentation within the image, followed by {CLIP} to retrieve the mask corresponding to the region of interest ({ROI}) from the pool of {SAM}’s generated masks. Finally, {SAM} is prompted by the retrieved {ROI} to segment a specific organ. Thus, {SaLIP} is training/fine-tuning free and does not rely on domain expertise or labeled data for prompt engineering. Our method shows substantial enhancements in zero-shot segmentation, showcasing notable improvements in {DICE} scores across diverse segmentation tasks like brain (63.46\%), lung (50.11\%), and fetal head (30.82\%), when compared to un-prompted {SAM}. Code and text prompts are available at {SaLIP}.},
	number = {{arXiv}:2404.06362},
	publisher = {{arXiv}},
	author = {Aleem, Sidra and Wang, Fangyijie and Maniparambil, Mayug and Arazo, Eric and Dietlmeier, Julia and Silvestre, Guenole and Curran, Kathleen and O'Connor, Noel E. and Little, Suzanne},
	urldate = {2024-09-14},
	date = {2024-04-30},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2404.06362 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\MYUPVHYH\\Aleem et al. - 2024 - Test-Time Adaptation with SaLIP A Cascade of SAM and CLIP for Zero shot Medical Image Segmentation.pdf:application/pdf},
}

@misc{zhang_vision-language_2024,
	title = {Vision-Language Models for Vision Tasks: A Survey},
	url = {http://arxiv.org/abs/2304.00685},
	shorttitle = {Vision-Language Models for Vision Tasks},
	abstract = {Most visual recognition studies rely heavily on crowd-labelled data in deep neural networks ({DNNs}) training, and they usually train a {DNN} for each single visual recognition task, leading to a laborious and time-consuming visual recognition paradigm. To address the two challenges, Vision-Language Models ({VLMs}) have been intensively investigated recently, which learns rich vision-language correlation from web-scale image-text pairs that are almost infinitely available on the Internet and enables zero-shot predictions on various visual recognition tasks with a single {VLM}. This paper provides a systematic review of visual language models for various visual recognition tasks, including: (1) the background that introduces the development of visual recognition paradigms; (2) the foundations of {VLM} that summarize the widely-adopted network architectures, pre-training objectives, and downstream tasks; (3) the widely-adopted datasets in {VLM} pre-training and evaluations; (4) the review and categorization of existing {VLM} pre-training methods, {VLM} transfer learning methods, and {VLM} knowledge distillation methods; (5) the benchmarking, analysis and discussion of the reviewed methods; (6) several research challenges and potential research directions that could be pursued in the future {VLM} studies for visual recognition. A project associated with this survey has been created at https://github.com/jingyi0000/{VLM} survey.},
	number = {{arXiv}:2304.00685},
	publisher = {{arXiv}},
	author = {Zhang, Jingyi and Huang, Jiaxing and Jin, Sheng and Lu, Shijian},
	urldate = {2024-09-14},
	date = {2024-02-16},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2304.00685 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\J58G5ABH\\Zhang et al. - 2024 - Vision-Language Models for Vision Tasks A Survey.pdf:application/pdf},
}



@article{zhang_pevl_nodate,
	title = {{PeVL}: Pose-Enhanced Vision-Language Model for Fine-Grained Human Action Recognition},
	author = {Zhang, Haosong and Leong, Mei Chee and Li, Liyuan and Lin, Weisi},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\MUR2EHAU\\Zhang et al. - PeVL Pose-Enhanced Vision-Language Model for Fine-Grained Human Action Recognition.pdf:application/pdf},
}

@article{zhang_pevl_nodate-1,
	title = {{PeVL}: Pose-Enhanced Vision-Language Model for Fine-Grained Human Action Recognition},
	author = {Zhang, Haosong and Leong, Mei Chee and Li, Liyuan and Lin, Weisi},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\R5P25E83\\Zhang et al. - PeVL Pose-Enhanced Vision-Language Model for Fine-Grained Human Action Recognition.pdf:application/pdf},
}

@misc{kim_palm_2024,
	title = {{PALM}: Predicting Actions through Language Models},
	url = {http://arxiv.org/abs/2311.17944},
	shorttitle = {{PALM}},
	abstract = {Understanding human activity is a crucial yet intricate task in egocentric vision, a field that focuses on capturing visual perspectives from the camera wearer’s viewpoint. Traditional methods heavily rely on representation learning that is trained on a large amount of video data. However, a major challenge arises from the difficulty of obtaining effective video representation. This difficulty stems from the complex and variable nature of human activities, which contrasts with the limited availability of data. In this study, we introduce {PALM}, an approach that tackles the task of long-term action anticipation, which aims to forecast forthcoming sequences of actions over an extended period. Our method {PALM} incorporates an action recognition model to track previous action sequences and a vision-language model to articulate relevant environmental details. By leveraging the context provided by these past events, we devise a prompting strategy for action anticipation using large language models ({LLMs}). Moreover, we implement maximal marginal relevance for example selection to facilitate in-context learning of the {LLMs}. Our experimental results demonstrate that {PALM} surpasses the state-of-theart methods in the task of long-term action anticipation on the Ego4D benchmark. We further validate {PALM} on two additional benchmarks, affirming its capacity for generalization across intricate activities with different sets of taxonomies.},
	number = {{arXiv}:2311.17944},
	publisher = {{arXiv}},
	author = {Kim, Sanghwan and Huang, Daoji and Xian, Yongqin and Hilliges, Otmar and Van Gool, Luc and Wang, Xi},
	urldate = {2024-09-14},
	date = {2024-07-18},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2311.17944 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\Z84LBKXU\\Kim et al. - 2024 - PALM Predicting Actions through Language Models.pdf:application/pdf},
}


@inproceedings{mosconi_mask_2024,
author = {Mosconi, Matteo and Sorokin, Andriy and Panariello, Aniello and Porrello, Angelo and Bonato, Jacopo and Cotogni, Marco and Sabetta, Luigi and Calderara, Simone and Cucchiara, Rita},
title = {Mask and Compress: Efficient Skeleton-Based Action Recognition in&nbsp;Continual Learning},
year = {2024},
isbn = {978-3-031-78188-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-78189-6_1},
doi = {10.1007/978-3-031-78189-6_1},
booktitle = {Pattern Recognition: 27th International Conference, ICPR 2024, Kolkata, India, December 1–5, 2024, Proceedings, Part IX},
pages = {1–15},
numpages = {15},
keywords = {Continual Learning, Skeleton Based Action Recognition, Class Incremental Learning, Masked Autoencoder},
location = {Kolkata, India}
}

@article{pasca_summarize_nodate,
	title = {Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction Anticipation},
	author = {Pasca, Razvan-George and Gavryushin, Alexey and Hamza, Muhammad and Kuo, Yen-Ling and Mo, Kaichun and Gool, Luc Van and Hilliges, Otmar and Wang, Xi},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\NDXNDQAE\\Pasca et al. - Summarize the Past to Predict the Future Natural Language Descriptions of Context Boost Multimodal.pdf:application/pdf},
}

@article{yu_boosting_2024,
	title = {Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters},
	author = {Yu, Jiazuo and Zhuge, Yunzhi and Zhang, Lu and Hu, Ping and Wang, Dong and Lu, Huchuan and He, You},
	date = {2024},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\FNHBJ82L\\Yu et al. - Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters.pdf:application/pdf},
}

@inproceedings{zheng_preventing_2023,
	location = {Paris, France},
	title = {Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-0718-4},
	url = {https://ieeexplore.ieee.org/document/10377061/},
	doi = {10.1109/ICCV51070.2023.01752},
	abstract = {Continual learning ({CL}) can help pre-trained visionlanguage models efficiently adapt to new or under-trained data distributions without re-training. Nevertheless, during the continual training of the Contrastive {LanguageImage} Pre-training ({CLIP}) model, we observe that the model’s zero-shot transfer ability significantly degrades due to catastrophic forgetting. Existing {CL} methods can mitigate forgetting by replaying previous data. However, since the {CLIP} dataset is private, replay methods cannot access the pre-training dataset. In addition, replaying data of previously learned downstream tasks can enhance their performance but comes at the cost of sacrificing zero-shot performance. To address this challenge, we propose a novel method {ZSCL} to prevent zero-shot transfer degradation in the continual learning of vision-language models in both feature and parameter space. In the feature space, a reference dataset is introduced for distillation between the current and initial models. The reference dataset should have semantic diversity but no need to be labeled, seen in pre-training, or matched image-text pairs. In parameter space, we prevent a large parameter shift by averaging weights during the training. We propose a more challenging Multi-domain Task Incremental Learning ({MTIL}) benchmark to evaluate different methods, where tasks are from various domains instead of class-separated in a single dataset. Our method outperforms other methods in the traditional class-incremental learning setting and the {MTIL} by 9.7\% average score. Our code locates at https: //github.com/Thunderbeee/{ZSCL}.},
	eventtitle = {2023 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	pages = {19068--19079},
	booktitle = {2023 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	publisher = {{IEEE}},
	author = {Zheng, Zangwei and Ma, Mingyuan and Wang, Kai and Qin, Ziheng and Yue, Xiangyu and You, Yang},
	urldate = {2024-09-16},
	date = {2023-10-01},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\EE4VMEIE\\Zheng et al. - 2023 - Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models.pdf:application/pdf},
}

@article{masana_class-incremental_2023,
	title = {Class-Incremental Learning: Survey and Performance Evaluation on Image Classification},
	volume = {45},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {https://ieeexplore.ieee.org/document/9915459/},
	doi = {10.1109/TPAMI.2022.3213473},
	shorttitle = {Class-Incremental Learning},
	abstract = {For future learning systems, incremental learning is desirable because it allows for: efﬁcient resource usage by eliminating the need to retrain from scratch at the arrival of new data; reduced memory usage by preventing or limiting the amount of data required to be stored – also important when privacy limitations are imposed; and learning that more closely resembles human learning. The main challenge for incremental learning is catastrophic forgetting, which refers to the precipitous drop in performance on previously learned tasks after learning a new one. Incremental learning of deep neural networks has seen explosive growth in recent years. Initial work focused on task-incremental learning, where a task-{ID} is provided at inference time. Recently, we have seen a shift towards classincremental learning where the learner must discriminate at inference time between all classes seen in previous tasks without recourse to a task-{ID}. In this paper, we provide a complete survey of existing class-incremental learning methods for image classiﬁcation, and in particular, we perform an extensive experimental evaluation on thirteen class-incremental methods. We consider several new experimental scenarios, including a comparison of class-incremental methods on multiple large-scale image classiﬁcation datasets, an investigation into small and large domain shifts, and a comparison of various network architectures.},
	pages = {5513--5533},
	number = {5},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	shortjournal = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
	author = {Masana, Marc and Liu, Xialei and Twardowski, Bartłomiej and Menta, Mikel and Bagdanov, Andrew D. and Van De Weijer, Joost},
    year = {2023}
}

@inproceedings{soutifcormerais_comprehensive_2023,
	location = {Paris, France},
	title = {A Comprehensive Empirical Evaluation on Online Continual Learning},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-0744-3},
	url = {https://ieeexplore.ieee.org/document/10351009/},
	doi = {10.1109/ICCVW60793.2023.00378},
	eventtitle = {2023 {IEEE}/{CVF} International Conference on Computer Vision Workshops ({ICCVW})},
	pages = {3510--3520},
	booktitle = {2023 {IEEE}/{CVF} International Conference on Computer Vision Workshops ({ICCVW})},
	publisher = {{IEEE}},
	author = {Soutif–Cormerais, Albin and Carta, Antonio and Cossu, Andrea and Hurtado, Julio and Lomonaco, Vincenzo and Van De Weijer, Joost and Hemati, Hamed},
	urldate = {2024-09-25},
	date = {2023-10-02},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\NFLLGG4E\\Soutif–Cormerais et al. - 2023 - A Comprehensive Empirical Evaluation on Online Continual Learning.pdf:application/pdf},
}

@inproceedings{gunasekara_survey_2023,
	location = {Macau, {SAR} China},
	title = {Survey on Online Streaming Continual Learning},
	isbn = {978-1-956792-03-4},
	url = {https://www.ijcai.org/proceedings/2023/743},
	doi = {10.24963/ijcai.2023/743},
	abstract = {Stream Learning ({SL}) attempts to learn from a data stream efficiently. A data stream learning algorithm should adapt to input data distribution shifts without sacrificing accuracy. These distribution shifts are known as ”concept drifts” in the literature. {SL} provides many supervised, semi-supervised, and unsupervised methods for detecting and adjusting to concept drift. On the other hand, Continual Learning ({CL}) attempts to preserve previous knowledge while performing well on the current concept when confronted with concept drift. In Online Continual Learning ({OCL}), this learning happens online. This survey explores the intersection of those two online learning paradigms to find synergies. We identify this intersection as Online Streaming Continual Learning ({OSCL}). The study starts with a gentle introduction to {SL} and then explores {CL}. Next, it explores {OSCL} from {SL} and {OCL} perspectives to point out new research trends and give directions for future research.},
	eventtitle = {Thirty-Second International Joint Conference on Artificial Intelligence \{{IJCAI}-23\}},
	pages = {6628--6637},
	booktitle = {Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Gunasekara, Nuwan and Pfahringer, Bernhard and Gomes, Heitor Murilo and Bifet, Albert},
	urldate = {2024-09-25},
	date = {2023-08},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\MKT32ZEX\\Gunasekara et al. - 2023 - Survey on Online Streaming Continual Learning.pdf:application/pdf},
}

@article{huang_experimental_2024,
	title = {An Experimental Survey of Incremental Transfer Learning for Multicenter Collaboration},
	volume = {12},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10605816/},
	doi = {10.1109/ACCESS.2024.3431885},
	abstract = {Due to data privacy constraints, data sharing among multiple clinical centers is restricted, which impedes the development of high performance deep learning models from multicenter collaboration. Naive weight transfer methods share intermediate model weights without raw data and hence can bypass data privacy restrictions. However, performance drops are typically observed when the model is transferred from one center to the next because of the forgetting problem. Incremental transfer learning, which combines peer-to-peer federated learning and domain incremental learning, can overcome the data privacy issue and meanwhile preserve model performance by using continual learning techniques. In this work, a conventional domain/task incremental learning framework is adapted for incremental transfer learning. A survey on the efficacy of prevalent regularization-based continual learning methods for multicenter collaboration is performed. The influences of data heterogeneity, classifier head setting, network optimizer, model initialization, center order, and weight transfer type have been investigated thoroughly. Our framework is publicly accessible to the research community for further development.},
	pages = {101210--101227},
	journal = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Huang, Yixing and Bert, Christoph and Gomaa, Ahmed and Fietkau, Rainer and Maier, Andreas and Putz, Florian},
	urldate = {2024-09-25},
	date = {2024},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\889EWXBP\\Huang et al. - 2024 - An Experimental Survey of Incremental Transfer Learning for Multicenter Collaboration.pdf:application/pdf},
}

@article{zhou_class-incremental_2024,
  title={Class-incremental learning: A survey},
  author={Zhou, Da-Wei and Wang, Qi-Wei and Qi, Zhi-Hong and Ye, Han-Jia and Zhan, De-Chuan and Liu, Ziwei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@article{wickramasinghe_continual_2024,
	title = {Continual Learning: A Review of Techniques, Challenges, and Future Directions},
	volume = {5},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {2691-4581},
	url = {https://ieeexplore.ieee.org/document/10341211/},
	doi = {10.1109/TAI.2023.3339091},
	shorttitle = {Continual Learning},
	pages = {2526--2546},
	number = {6},
	journal = {{IEEE} Transactions on Artificial Intelligence},
	shortjournal = {{IEEE} Trans. Artif. Intell.},
	author = {Wickramasinghe, Buddhi and Saha, Gobinda and Roy, Kaushik},
    year = {2024}
}

@misc{yang_continual_2024,
	title = {Continual Learning for Smart City: A Survey},
	url = {http://arxiv.org/abs/2404.00983},
	shorttitle = {Continual Learning for Smart City},
	abstract = {With the digitization of modern cities, large data volumes and powerful computational resources facilitate the rapid update of intelligent models deployed in smart cities. Continual learning ({CL}) is a novel machine learning paradigm that constantly updates models to adapt to changing environments, where the learning tasks, data, and distributions can vary over time. Our survey provides a comprehensive review of continual learning methods that are widely used in smart city development. The content consists of three parts: 1) Methodology-wise. We categorize a large number of basic {CL} methods and advanced {CL} frameworks in combination with other learning paradigms including graph learning, spatial-temporal learning, multi-modal learning, and federated learning. 2) Application-wise. We present numerous {CL} applications covering transportation, environment, public health, safety, networks, and associated datasets related to urban computing. 3) Challenges. We discuss current problems and challenges and envision several promising research directions. We believe this survey can help relevant researchers quickly familiarize themselves with the current state of continual learning research used in smart city development and direct them to future research trends.},
	number = {{arXiv}:2404.00983},
	publisher = {{arXiv}},
	author = {Yang, Li and Luo, Zhipeng and Zhang, Shiming and Teng, Fei and Li, Tianrui},
	urldate = {2024-09-25},
	date = {2024-04-01},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2404.00983 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\CBPZYZZU\\Yang et al. - 2024 - Continual Learning for Smart City A Survey.pdf:application/pdf},
}

@article{shaheen_continual_2022,
	title = {Continual Learning for Real-World Autonomous Systems: Algorithms, Challenges and Frameworks},
	volume = {105},
	issn = {0921-0296, 1573-0409},
	url = {https://link.springer.com/10.1007/s10846-022-01603-6},
	doi = {10.1007/s10846-022-01603-6},
	shorttitle = {Continual Learning for Real-World Autonomous Systems},
	pages = {9},
	number = {1},
	journal = {Journal of Intelligent \& Robotic Systems},
	shortjournal = {J Intell Robot Syst},
	author = {Shaheen, Khadija and Hanif, Muhammad Abdullah and Hasan, Osman and Shafique, Muhammad},
	urldate = {2024-09-25},
	year = {2022-05}
}

@article{menezes_continual_2023,
	title = {Continual Object Detection: A review of definitions, strategies, and challenges},
	volume = {161},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608023000539},
	doi = {10.1016/j.neunet.2023.01.041},
	shorttitle = {Continual Object Detection},
	abstract = {The field of Continual Learning investigates the ability to learn consecutive tasks without losing performance on those previously learned. The efforts of researchers have been mainly focused on incremental classification tasks. Yet, we believe that continual object detection deserves even more attention due to its vast range of applications in robotics and autonomous vehicles. This scenario is also more complex than conventional classification, given the occurrence of instances of classes that are unknown at the time but can appear in subsequent tasks as a new class to be learned, resulting in missing annotations and conflicts with the background label. In this review, we analyze the current strategies proposed to tackle the problem of class-incremental object detection. Our main contributions are: (1) a short and systematic review of the methods that propose solutions to traditional incremental object detection scenarios; (2) A comprehensive evaluation of the existing approaches using a new metric to quantify the stability and plasticity of each technique in a standard way; (3) an overview of the current trends within continual object detection and a discussion of possible future research directions.},
	pages = {476--493},
	journal = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Menezes, Angelo G. and De Moura, Gustavo and Alves, Cézanne and De Carvalho, André C.P.L.F.},
    year = {2023}
}

@misc{zhou_continual_2024,
	title = {Continual Learning with Pre-Trained Models: A Survey},
	url = {http://arxiv.org/abs/2401.16386},
	shorttitle = {Continual Learning with Pre-Trained Models},
	abstract = {Nowadays, real-world applications often face streaming data, which requires the learning system to absorb new knowledge as data evolves. Continual Learning ({CL}) aims to achieve this goal and meanwhile overcome the catastrophic forgetting of former knowledge when learning new ones. Typical {CL} methods build the model from scratch to grow with incoming data. However, the advent of the pre-trained model ({PTM}) era has sparked immense research interest, particularly in leveraging {PTMs}’ robust representational capabilities for {CL}. This paper presents a comprehensive survey of the latest advancements in {PTM}-based {CL}. We categorize existing methodologies into three distinct groups, providing a comparative analysis of their similarities, differences, and respective advantages and disadvantages. Additionally, we offer an empirical study contrasting various stateof-the-art methods to highlight concerns regarding fairness in comparisons. The source code to reproduce these evaluations is available at: https: //github.com/sun-hailong/{LAMDA}-{PILOT}.},
	number = {{arXiv}:2401.16386},
	publisher = {{arXiv}},
	author = {Zhou, Da-Wei and Sun, Hai-Long and Ning, Jingyi and Ye, Han-Jia and Zhan, De-Chuan},
	urldate = {2024-09-25},
	date = {2024-04-23},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2401.16386 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\9W6QSZ7F\\Zhou et al. - 2024 - Continual Learning with Pre-Trained Models A Survey.pdf:application/pdf},
}

@article{graffieti_continual_2022,
	title = {Continual Learning in Real-Life Applications},
	volume = {7},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {2377-3766, 2377-3774},
	url = {https://ieeexplore.ieee.org/document/9760237/},
	doi = {10.1109/LRA.2022.3167736},
	abstract = {Existing Continual Learning benchmarks only partially address the complexity of real-life applications, limiting the realism of learning agents. In this letter, we propose and focus on benchmarks characterized by common key elements of real-life scenarios, including temporally ordered streams as input data, strong correlation of samples in short time ranges, high data distribution drift over the long time frame, and heavy class unbalancing. Moreover, we enforce online training constraints such as the need for frequent model updates without the possibility of storing a large amount of past data or passing the dataset multiple times through the model. Besides, we introduce a novel hybrid approach based on Continual Learning, whose architectural elements and replay memory management proved to be useful and effective in the considered scenarios. The experimental validation carried out, including comparisons with existing methods and an ablation study, conﬁrms the validity and the suitability of the proposed approach.},
	pages = {6195--6202},
	number = {3},
	journal = {{IEEE} Robotics and Automation Letters},
	shortjournal = {{IEEE} Robot. Autom. Lett.},
	author = {Graffieti, Gabriele and Borghi, Guido and Maltoni, Davide},
	urldate = {2024-09-25},
	date = {2022-07},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\325N3VLL\\Graffieti et al. - 2022 - Continual Learning in Real-Life Applications.pdf:application/pdf},
}

@article{yuan_survey_2024,
	title = {A Survey on Continual Semantic Segmentation: Theory, Challenge, Method and Application},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {http://arxiv.org/abs/2310.14277},
	doi = {10.1109/TPAMI.2024.3446949},
	shorttitle = {A Survey on Continual Semantic Segmentation},
	abstract = {Continual learning, also known as incremental learning or life-long learning, stands at the forefront of deep learning and {AI} systems. It breaks through the obstacle of one-way training on close sets and enables continuous adaptive learning on open-set conditions. In the recent decade, continual learning has been explored and applied in multiple fields especially in computer vision covering classification, detection and segmentation tasks. Continual semantic segmentation ({CSS}), of which the dense prediction peculiarity makes it a challenging, intricate and burgeoning task. In this paper, we present a review of {CSS}, committing to building a comprehensive survey on problem formulations, primary challenges, universal datasets, neoteric theories and multifarious applications. Concretely, we begin by elucidating the problem definitions and primary challenges. Based on an in-depth investigation of relevant approaches, we sort out and categorize current {CSS} models into two main branches including data-replay and data-free sets. In each branch, the corresponding approaches are similarity-based clustered and thoroughly analyzed, following qualitative comparison and quantitative reproductions on relevant datasets. Besides, we also introduce four {CSS} specialities with diverse application scenarios and development tendencies. Furthermore, we develop a benchmark for {CSS} encompassing representative references, evaluation results and reproductions, which is available at https://github.com/{YBIO}/{SurveyCSS}. We hope this survey can serve as a reference-worthy and stimulating contribution to the advancement of the life-long learning field, while also providing valuable perspectives for related fields.},
	pages = {1--20},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	shortjournal = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
	author = {Yuan, Bo and Zhao, Danpei},
    year = {2024}
}

@article{yang_federated_2024,
	title = {Federated Continual Learning via Knowledge Fusion: A Survey},
	volume = {36},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1041-4347, 1558-2191, 2326-3865},
	url = {https://ieeexplore.ieee.org/document/10423871/},
	doi = {10.1109/TKDE.2024.3363240},
	shorttitle = {Federated Continual Learning via Knowledge Fusion},
	abstract = {Data privacy and silos are nontrivial and greatly challenging in many real-world applications. Federated learning is a decentralized approach to training models across multiple local clients without the exchange of raw data from client devices to global servers. However, existing works focus on a static data environment and ignore continual learning from streaming data with incremental tasks. Federated Continual Learning ({FCL}) is an emerging paradigm to address model learning in both federated and continual learning environments. The key objective of {FCL} is to fuse heterogeneous knowledge from different clients and retain knowledge of previous tasks while learning on new ones. In this work, we delineate federated learning and continual learning ﬁrst and then discuss their integration, i.e., {FCL}, and particular {FCL} via knowledge fusion. In summary, our motivations are four-fold: we (1) raise a fundamental problem called “spatial-temporal catastrophic forgetting” and evaluate its impact on the performance using a well-known method called federated averaging ({FedAvg}), (2) integrate most of the existing {FCL} methods into two generic frameworks, namely synchronous {FCL} and asynchronous {FCL}, (3) categorize a large number of methods according to the mechanism involved in knowledge fusion, and ﬁnally (4) showcase an outlook on the future work of {FCL}.},
	pages = {3832--3850},
	number = {8},
	journal = {{IEEE} Transactions on Knowledge and Data Engineering},
	shortjournal = {{IEEE} Trans. Knowl. Data Eng.},
	author = {Yang, Xin and Yu, Hao and Gao, Xin and Wang, Hao and Zhang, Junbo and Li, Tianrui},
	urldate = {2024-09-25},
	date = {2024-08},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\5RJYV67B\\Yang et al. - 2024 - Federated Continual Learning via Knowledge Fusion A Survey.pdf:application/pdf},
}

@article{yuan_survey_2024-1,
	title = {A Survey on Continual Semantic Segmentation: Theory, Challenge, Method and Application},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {https://ieeexplore.ieee.org/document/10643308/},
	doi = {10.1109/TPAMI.2024.3446949},
	shorttitle = {A Survey on Continual Semantic Segmentation},
	abstract = {Continual learning, also known as incremental learning or life-long learning, stands at the forefront of deep learning and {AI} systems. It breaks through the obstacle of one-way training on close sets and enables continuous adaptive learning on open-set conditions. In the recent decade, continual learning has been explored and applied in multiple ﬁelds especially in computer vision covering classiﬁcation, detection and segmentation tasks. Continual semantic segmentation ({CSS}), of which the dense prediction peculiarity makes it a challenging, intricate and burgeoning task. In this paper, we present a review of {CSS}, committing to building a comprehensive survey on problem formulations, primary challenges, universal datasets, neoteric theories and multifarious applications. Concretely, we begin by elucidating the problem deﬁnitions and primary challenges. Based on an in-depth investigation of relevant approaches, we sort out and categorize current {CSS} models into two main branches including data-replay and data-free sets. In each branch, the corresponding approaches are similarity-based clustered and thoroughly analyzed, following qualitative comparison and quantitative reproductions on relevant datasets. Besides, we also introduce four {CSS} specialities with diverse application scenarios and development tendencies. Furthermore, we develop a benchmark for {CSS} encompassing representative references, evaluation results and reproductions, which is available at https://github.com/{YBIO}/{SurveyCSS}. We hope this survey can serve as a reference-worthy and stimulating contribution to the advancement of the life-long learning ﬁeld, while also providing valuable perspectives for related ﬁelds.},
	pages = {1--20},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	shortjournal = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
	author = {Yuan, Bo and Zhao, Danpei},
	urldate = {2024-09-25},
	date = {2024},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\3VZHGWZ6\\Yuan and Zhao - 2024 - A Survey on Continual Semantic Segmentation Theory, Challenge, Method and Application.pdf:application/pdf},
}

@article{ao_continual_2023,
	title = {Continual Deep Learning for Time Series Modeling},
	volume = {23},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/16/7167},
	doi = {10.3390/s23167167},
	abstract = {The multi-layer structures of Deep Learning facilitate the processing of higher-level abstractions from data, thus leading to improved generalization and widespread applications in diverse domains with various types of data. Each domain and data type presents its own set of challenges. Real-world time series data may have a non-stationary data distribution that may lead to Deep Learning models facing the problem of catastrophic forgetting, with the abrupt loss of previously learned knowledge. Continual learning is a paradigm of machine learning to handle situations when the stationarity of the datasets may no longer be true or required. This paper presents a systematic review of the recent Deep Learning applications of sensor time series, the need for advanced preprocessing techniques for some sensor environments, as well as the summaries of how to deploy Deep Learning in time series modeling while alleviating catastrophic forgetting with continual learning methods. The selected case studies cover a wide collection of various sensor time series applications and can illustrate how to deploy tailor-made Deep Learning, advanced preprocessing techniques, and continual learning algorithms from practical, real-world application aspects.},
	pages = {7167},
	number = {16},
	journal = {Sensors},
	shortjournal = {Sensors},
	author = {Ao, Sio-Iong and Fayek, Haytham},
	urldate = {2024-09-25},
	date = {2023-08-14},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\6ITI75C9\\Ao and Fayek - 2023 - Continual Deep Learning for Time Series Modeling.pdf:application/pdf},
}





@misc{chang_reviewing_2021,
	title = {Reviewing continual learning from the perspective of human-level intelligence},
	url = {http://arxiv.org/abs/2111.11964},
	abstract = {Humans continual learning ({CL}) ability is closely related to Stability Versus Plasticity Dilemma that describes how humans achieve ongoing learning capacity and preservation for learned information. The notion of {CL} has always been present in artiﬁcial intelligence ({AI}) since its births. This paper proposes a comprehensive review on {CL}. Different from previous reviews that mainly focus on the catastrophic forgetting phenomenon in {CL}, this paper surveys {CL} from a more macroscopic perspective based on the Stability Versus Plasticity mechansim. Analogous to biological counterpart, ”smart” {AI} agents are supposed to i) remember previously learned information (information retrospection); ii) infer on new information continuously (information prospection:); iii) transfer useful information (information transfer), to achieve high-level {CL}. According to the taxonomy, evaluation metrics, algorithms, applications as well as some open issues are then introduced. Our main contributions concern i) recheck {CL} from the level of artiﬁcial general intelligence; ii) provide a detailed and extensive overview on {CL} topics; iii) present some novel ideas on the potential development of {CL}.},
	number = {{arXiv}:2111.11964},
	publisher = {{arXiv}},
	author = {Chang, Yifan and Li, Wenbo and Peng, Jian and Tang, Bo and Kang, Yu and Lei, Yinjie and Gui, Yuanmiao and Zhu, Qing and Liu, Yu and Li, Haifeng},
	urldate = {2024-09-25},
	date = {2021-11-23},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2111.11964 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\2HDYYB85\\Chang et al. - 2021 - Reviewing continual learning from the perspective of human-level intelligence.pdf:application/pdf},
}

@misc{mccaffary_towards_2021,
	title = {Towards continual task learning in artificial neural networks: current approaches and insights from neuroscience},
	url = {http://arxiv.org/abs/2112.14146},
	shorttitle = {Towards continual task learning in artificial neural networks},
	abstract = {The innate capacity of humans and other animals to learn a diverse, and often interfering, range of knowledge and skills throughout their lifespan is a hallmark of natural intelligence, with obvious evolutionary motivations. In parallel, the ability of artiﬁcial neural networks ({ANNs}) to learn across a range of tasks and domains, combining and re-using learned representations where required, is a clear goal of artiﬁcial intelligence. This capacity, widely described as continual learning, has become a proliﬁc subﬁeld of research in machine learning. Despite the numerous successes of deep learning in recent years, across domains ranging from image recognition to machine translation, such continual task learning has proved challenging. Neural networks trained on multiple tasks in sequence with stochastic gradient descent often suffer from representational interference, whereby the learned weights for a given task effectively overwrite those of previous tasks in a process termed catastrophic forgetting. This represents a major impediment to the development of more generalised artiﬁcial learning systems, capable of accumulating knowledge over time and task space, in a manner analogous to humans. A repository of selected papers and implementations accompanying this review can be found at https://github.com/mccaffary/ continual-learning.},
	number = {{arXiv}:2112.14146},
	publisher = {{arXiv}},
	author = {{McCaffary}, David},
	urldate = {2024-09-25},
	date = {2021-12-28},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2112.14146 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\UCEUUYN5\\McCaffary - 2021 - Towards continual task learning in artificial neural networks current approaches and insights from.pdf:application/pdf},
}

@misc{zhang_continual_2024,
	title = {Continual Learning on Graphs: Challenges, Solutions, and Opportunities},
	url = {http://arxiv.org/abs/2402.11565},
	shorttitle = {Continual Learning on Graphs},
	abstract = {Continual learning on graph data has recently attracted paramount attention for its aim to resolve the catastrophic forgetting problem on existing tasks while adapting the sequentially updated model to newly emerged graph tasks. While there have been efforts to summarize progress on continual learning research over Euclidean data, e.g., images and texts, a systematic review of progress in continual learning on graphs, a.k.a, continual graph learning ({CGL}) or lifelong graph learning, is still demanding. Graph data are far more complex in terms of data structures and application scenarios, making {CGL} task settings, model designs, and applications extremely challenging. To bridge the gap, we provide a comprehensive review of existing continual graph learning ({CGL}) algorithms by elucidating the different task settings and categorizing the existing methods based on their characteristics. We compare the {CGL} methods with traditional continual learning techniques and analyze the applicability of the traditional continual learning techniques to {CGL} tasks. Additionally, we review the benchmark works that are crucial to {CGL} research. Finally, we discuss the remaining challenges and propose several future directions. We will maintain an up-to-date {GitHub} repository featuring a comprehensive list of {CGL} algorithms, accessible at https://github.com/{UConn}-{DSIS}/Survey-of-Continual-Learning-on-Graphs.},
	number = {{arXiv}:2402.11565},
	publisher = {{arXiv}},
	author = {Zhang, Xikun and Song, Dongjin and Tao, Dacheng},
	urldate = {2024-09-25},
	date = {2024-02-18},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2402.11565 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\WMJ6NNZU\\Zhang et al. - 2024 - Continual Learning on Graphs Challenges, Solutions, and Opportunities.pdf:application/pdf},
}

@misc{wu_continual_2024,
	title = {Continual Learning for Large Language Models: A Survey},
	url = {http://arxiv.org/abs/2402.01364},
	shorttitle = {Continual Learning for Large Language Models},
	abstract = {Large language models ({LLMs}) are not amenable to frequent re-training, due to high training costs arising from their massive scale. However, updates are necessary to endow {LLMs} with new skills and keep them up-to-date with rapidly evolving human knowledge. This paper surveys recent works on continual learning for {LLMs}. Due to the unique nature of {LLMs}, we catalog continue learning techniques in a novel multi-staged categorization scheme, involving continual pretraining, instruction tuning, and alignment. We contrast continual learning for {LLMs} with simpler adaptation methods used in smaller models, as well as with other enhancement strategies like retrievalaugmented generation and model editing. Moreover, informed by a discussion of benchmarks and evaluation, we identify a number of challenges and future work directions for this crucial task.},
	number = {{arXiv}:2402.01364},
	publisher = {{arXiv}},
	author = {Wu, Tongtong and Luo, Linhao and Li, Yuan-Fang and Pan, Shirui and Vu, Thuy-Trang and Haffari, Gholamreza},
	urldate = {2024-09-25},
	date = {2024-02-07},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2402.01364 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\PAMKV3ZI\\Wu et al. - 2024 - Continual Learning for Large Language Models A Survey.pdf:application/pdf},
}

@misc{tian_continual_2024,
	title = {Continual Learning on Graphs: A Survey},
	url = {http://arxiv.org/abs/2402.06330},
	shorttitle = {Continual Learning on Graphs},
	abstract = {Recently, continual graph learning has been increasingly adopted for diverse graph-structured data processing tasks in non-stationary environments. Despite its promising learning capability, current studies on continual graph learning mainly focus on mitigating the catastrophic forgetting problem while ignoring continuous performance improvement. To bridge this gap, this article aims to provide a comprehensive survey of recent efforts on continual graph learning. Specifically, we introduce a new taxonomy of continual graph learning from the perspective of overcoming catastrophic forgetting. Moreover, we systematically analyze the challenges of applying these continual graph learning methods in improving performance continuously and then discuss the possible solutions. Finally, we present open issues and future directions pertaining to the development of continual graph learning and discuss how they impact continuous performance improvement. {CCS} Concepts: • Computing methodologies → Lifelong machine learning; Neural networks.},
	number = {{arXiv}:2402.06330},
	publisher = {{arXiv}},
	author = {Tian, Zonggui and Zhang, Du and Dai, Hong-Ning},
	urldate = {2024-09-25},
	date = {2024-02-09},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2402.06330 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\TXD3BZW3\\Tian et al. - 2024 - Continual Learning on Graphs A Survey.pdf:application/pdf},
}

@article{li_continual_2024,
	title = {Continual Learning with Deep Neural Networks in Physiological Signal Data: A Survey},
	volume = {12},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2227-9032},
	url = {https://www.mdpi.com/2227-9032/12/2/155},
	doi = {10.3390/healthcare12020155},
	shorttitle = {Continual Learning with Deep Neural Networks in Physiological Signal Data},
	abstract = {Deep-learning algorithms hold promise in processing physiological signal data, including electrocardiograms ({ECGs}) and electroencephalograms ({EEGs}). However, healthcare often requires long-term monitoring, posing a challenge to traditional deep-learning models. These models are generally trained once and then deployed, which limits their ability to adapt to the dynamic and evolving nature of healthcare scenarios. Continual learning—known for its adaptive learning capabilities over time—offers a promising solution to these challenges. However, there remains an absence of consolidated literature, which reviews the techniques, applications, and challenges of continual learning specific to physiological signal analysis, as well as its future directions. Bridging this gap, our review seeks to provide an overview of the prevailing techniques and their implications for smart healthcare. We delineate the evolution from traditional approaches to the paradigms of continual learning. We aim to offer insights into the challenges faced and outline potential paths forward. Our discussion emphasizes the need for benchmarks, adaptability, computational efficiency, and user-centric design in the development of future healthcare systems.},
	pages = {155},
	number = {2},
	journal = {Healthcare},
	shortjournal = {Healthcare},
	author = {Li, Ao and Li, Huayu and Yuan, Geng},
	urldate = {2024-09-25},
	date = {2024-01-09},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\ZW2RH9XM\\Li et al. - 2024 - Continual Learning with Deep Neural Networks in Physiological Signal Data A Survey.pdf:application/pdf},
}

@article{cossu_continual_2021,
	title = {Continual learning for recurrent neural networks: An empirical evaluation},
	volume = {143},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608021002847},
	doi = {10.1016/j.neunet.2021.07.021},
	shorttitle = {Continual learning for recurrent neural networks},
	abstract = {Learning continuously during all model lifetime is fundamental to deploy machine learning solutions robust to drifts in the data distribution. Advances in Continual Learning ({CL}) with recurrent neural networks could pave the way to a large number of applications where incoming data is non stationary, like natural language processing and robotics. However, the existing body of work on the topic is still fragmented, with approaches which are application-specific and whose assessment is based on heterogeneous learning protocols and datasets. In this paper, we organize the literature on {CL} for sequential data processing by providing a categorization of the contributions and a review of the benchmarks. We propose two new benchmarks for {CL} with sequential data based on existing datasets, whose characteristics resemble real-world applications.},
	pages = {607--627},
	journal = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Cossu, Andrea and Carta, Antonio and Lomonaco, Vincenzo and Bacciu, Davide},
	urldate = {2024-09-25},
	date = {2021-11},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\I94Y2F7S\\Cossu et al. - 2021 - Continual learning for recurrent neural networks An empirical evaluation.pdf:application/pdf},
}



@misc{safa_continual_2024,
	title = {Continual Learning in Bio-plausible Spiking Neural Networks with Hebbian and Spike Timing Dependent Plasticity: A Survey and Perspective},
	url = {http://arxiv.org/abs/2407.17305},
	shorttitle = {Continual Learning in Bio-plausible Spiking Neural Networks with Hebbian and Spike Timing Dependent Plasticity},
	abstract = {Recently, the use bio-plausible learning techniques such as Hebbian and Spike-Timing-Dependent Plasticity ({STDP}) have drawn significant attention for the design of compute-efficient {AI} systems that can continuously learn on-line at the edge. A key differentiating factor regarding this emerging class of neuromorphic continual learning system lies in the fact that learning must be carried using a data stream received in its natural order, as opposed to conventional gradient-based offline training where a static training dataset is assumed available a priori and randomly shuffled to make the training set independent and identically distributed (i.i.d). In contrast, the emerging class of neuromorphic continual learning systems covered in this survey must learn to integrate new information on the fly in a non-i.i.d manner, which makes these systems subject to catastrophic forgetting. In order to build the next generation of neuromorphic {AI} systems that can continuously learn at the edge, a growing number of research groups are studying the use of bio-plausible Hebbian neural network architectures and Spiking Neural Networks ({SNNs}) equipped with {STDP} learning. However, since this research field is still emerging, there is a need for providing a holistic view of the different approaches proposed in literature so far. To this end, this survey covers a number of recent works in the field of neuromorphic continual learning; provides background theory to help interested researchers to quickly learn the key concepts; and discusses important future research questions in light of the different works covered in this paper. It is hoped that this survey will contribute towards future research in the field of neuromorphic continual learning.},
	number = {{arXiv}:2407.17305},
	publisher = {{arXiv}},
	author = {Safa, Ali},
	urldate = {2024-09-25},
	date = {2024-07-24},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2407.17305 [cs]},
	keywords = {Computer Science - Neural and Evolutionary Computing},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\4DR23I7N\\Safa - 2024 - Continual Learning in Bio-plausible Spiking Neural Networks with Hebbian and Spike Timing Dependent.pdf:application/pdf},
}

@article{khodaee_knowledge_2024,
	title = {Knowledge transfer in lifelong machine learning: a systematic literature review},
	volume = {57},
	issn = {1573-7462},
	url = {https://link.springer.com/10.1007/s10462-024-10853-9},
	doi = {10.1007/s10462-024-10853-9},
	shorttitle = {Knowledge transfer in lifelong machine learning},
	abstract = {Lifelong Machine Learning ({LML}) denotes a scenario involving multiple sequential tasks, each accompanied by its respective dataset, in order to solve specific learning problems. In this context, the focus of {LML} techniques is on utilizing already acquired knowledge to adapt to new tasks efficiently. Essentially, {LML} concerns about facing new tasks while exploiting the knowledge previously gathered from earlier tasks not only to help in adapting to new tasks but also to enrich the understanding of past ones. By understanding this concept, one can better grasp one of the major obstacles in {LML}, known as Knowledge Transfer ({KT}). This systematic literature review aims to explore state-of-the-art {KT} techniques within {LML} and assess the evaluation metrics and commonly utilized datasets in this field, thereby keeping the {LML} research community updated with the latest developments. From an initial pool of 417 articles from four distinguished databases, 30 were deemed highly pertinent for the information extraction phase. The analysis recognizes four primary {KT} techniques: Replay, Regularization, Parameter Isolation, and Hybrid. This study delves into the characteristics of these techniques across both neural network ({NN}) and non-neural network (non-{NN}) frameworks, highlighting their distinct advantages that have captured researchers’ interest. It was found that the majority of the studies focused on supervised learning within an {NN} modelling framework, particularly employing Parameter Isolation and Hybrid for {KT}. The paper concludes by pinpointing research opportunities, including investigating non-{NN} models for Replay and exploring applications outside of computer vision ({CV}).},
	pages = {217},
	number = {8},
	journal = {Artificial Intelligence Review},
	shortjournal = {Artif Intell Rev},
	author = {Khodaee, Pouya and Viktor, Herna L. and Michalowski, Wojtek},
	urldate = {2024-09-25},
	date = {2024-07-26},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\M3LQ3Z2N\\Khodaee et al. - 2024 - Knowledge transfer in lifelong machine learning a systematic literature review.pdf:application/pdf},
}

@inproceedings{besnard_continual_2024,
	title = {Continual Learning for Time Series Forecasting: A First Survey},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	url = {https://www.mdpi.com/2673-4591/68/1/49},
	doi = {10.3390/engproc2024068049},
	shorttitle = {Continual Learning for Time Series Forecasting},
	abstract = {Deep learning has brought significant advancements in the field of artificial intelligence, particularly in robotics, imaging, sound processing, etc. However, a common major challenge faced by all neural networks is their substantial demand for data during the learning process. The required data must be both quantitative and stationary to ensure the proper computing of standard models. Nevertheless, complying to these constraints is often impossible for many real-life applications because of dynamic environments. Indeed, modifications can occur in the distribution of the data or even in the goals to pursue within these environments. This is known as data and concept drift. Research in the field of continual learning seeks to address these challenges by implementing evolving models capable of adaptation over time. This notably involves finding a compromise on the plasticity/stability dilemma while taking into account material and computational constraints. Exploratory efforts are evident in all applications of deep learning (graphs, reinforcement learning, etc.), but to date, there is still a limited amount of work in the case of time series, specifically in the context of regression and forecasting. This paper aims to provide a first survey on this field of continuous learning applied to time series forecasting.},
	eventtitle = {{ITISE} 2024},
	pages = {49},
	booktitle = {{ITISE} 2024},
	publisher = {{MDPI}},
	author = {Besnard, Quentin and Ragot, Nicolas},
	urldate = {2024-09-25},
	date = {2024-07-17},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\PQMRVLVZ\\Besnard and Ragot - 2024 - Continual Learning for Time Series Forecasting A First Survey.pdf:application/pdf},
}

@misc{farquhar_towards_2019,
	title = {Towards Robust Evaluations of Continual Learning},
	url = {http://arxiv.org/abs/1805.09733},
	abstract = {Experiments used in current continual learning research do not faithfully assess fundamental challenges of learning continually. Instead of assessing performance on challenging and representative experiment designs, recent research has focused on increased dataset difﬁculty, while still using ﬂawed experiment set-ups. We examine standard evaluations and show why these evaluations make some continual learning approaches look better than they are. We introduce desiderata for continual learning evaluations and explain why their absence creates misleading comparisons. Based on our desiderata we then propose new experiment designs which we demonstrate with various continual learning approaches and datasets. Our analysis calls for a reprioritization of research effort by the community.},
	number = {{arXiv}:1805.09733},
	publisher = {{arXiv}},
	author = {Farquhar, Sebastian and Gal, Yarin},
	urldate = {2024-09-25},
	date = {2019-06-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1805.09733 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{lesort_continual_2020,
	title = {Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges},
	volume = {58},
	issn = {15662535},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253519307377},
	doi = {10.1016/j.inffus.2019.12.004},
	shorttitle = {Continual learning for robotics},
	pages = {52--68},
	journal = {Information Fusion},
	shortjournal = {Information Fusion},
	author = {Lesort, Timothée and Lomonaco, Vincenzo and Stoian, Andrei and Maltoni, Davide and Filliat, David and Díaz-Rodríguez, Natalia},
	urldate = {2024-09-25},
	year = {2020},
	langid = {english}
}

@misc{mendez_how_2023,
	title = {How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition},
	url = {http://arxiv.org/abs/2207.07730},
	shorttitle = {How to Reuse and Compose Knowledge for a Lifetime of Tasks},
	abstract = {A major goal of artificial intelligence ({AI}) is to create an agent capable of acquiring a general understanding of the world. Such an agent would require the ability to continually accumulate and build upon its knowledge as it encounters new experiences. Lifelong or continual learning addresses this setting, whereby an agent faces a continual stream of problems and must strive to capture the knowledge necessary for solving each new task it encounters. If the agent is capable of accumulating knowledge in some form of compositional representation, it could then selectively reuse and combine relevant pieces of knowledge to construct novel solutions. Despite the intuitive appeal of this simple idea, the literatures on lifelong learning and compositional learning have proceeded largely separately. In an effort to promote developments that bridge between the two fields, this article surveys their respective research landscapes and discusses existing and future connections between them.},
	number = {{arXiv}:2207.07730},
	publisher = {{arXiv}},
	author = {Mendez, Jorge A. and Eaton, Eric},
	urldate = {2024-09-25},
	date = {2023-06-13},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2207.07730 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\ADYLFREM\\Mendez and Eaton - 2023 - How to Reuse and Compose Knowledge for a Lifetime of Tasks A Survey on Continual Learning and Funct.pdf:application/pdf},
}

@misc{shi_continual_2024,
	title = {Continual Learning of Large Language Models: A Comprehensive Survey},
	url = {http://arxiv.org/abs/2404.16789},
	shorttitle = {Continual Learning of Large Language Models},
	abstract = {The recent success of large language models ({LLMs}) trained on static, pre-collected, general datasets has sparked numerous research directions and applications. One such direction addresses the non-trivial challenge of integrating pre-trained {LLMs} into dynamic data distributions, task structures, and user preferences. Pre-trained {LLMs}, when tailored for specific needs, often experience significant performance degradation in previous knowledge domains -- a phenomenon known as "catastrophic forgetting". While extensively studied in the continual learning ({CL}) community, it presents new manifestations in the realm of {LLMs}. In this survey, we provide a comprehensive overview of the current research progress on {LLMs} within the context of {CL}. This survey is structured into four main sections: we first describe an overview of continually learning {LLMs}, consisting of two directions of continuity: vertical continuity (or vertical continual learning), i.e., continual adaptation from general to specific capabilities, and horizontal continuity (or horizontal continual learning), i.e., continual adaptation across time and domains (Section 3). We then summarize three stages of learning {LLMs} in the context of modern {CL}: Continual Pre-Training ({CPT}), Domain-Adaptive Pre-training ({DAP}), and Continual Fine-Tuning ({CFT}) (Section 4). Then we provide an overview of evaluation protocols for continual learning with {LLMs}, along with the current available data sources (Section 5). Finally, we discuss intriguing questions pertaining to continual learning for {LLMs} (Section 6). The full list of papers examined in this survey is available at https://github.com/Wang-{ML}-Lab/llm-continual-learning-survey.},
	number = {{arXiv}:2404.16789},
	publisher = {{arXiv}},
	author = {Shi, Haizhou and Xu, Zihao and Wang, Hengyi and Qin, Weiyi and Wang, Wenyuan and Wang, Yibin and Wang, Zifeng and Ebrahimi, Sayna and Wang, Hao},
	urldate = {2024-09-25},
	date = {2024-06-29},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2404.16789 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\3SP6QS5W\\Shi et al. - 2024 - Continual Learning of Large Language Models A Comprehensive Survey.pdf:application/pdf},
}

@misc{verwimp_continual_2024,
	title = {Continual Learning: Applications and the Road Forward},
	url = {http://arxiv.org/abs/2311.11908},
	shorttitle = {Continual Learning},
	abstract = {Continual learning is a subfield of machine learning, which aims to allow machine learning models to continuously learn on new data, by accumulating knowledge without forgetting what was learned in the past. In this work, we take a step back, and ask: “Why should one care about continual learning in the first place?”. We set the stage by examining recent continual learning papers published at four major machine learning conferences, and show that memory-constrained settings dominate the field. Then, we discuss five open problems in machine learning, and even though they might seem unrelated to continual learning at first sight, we show that continual learning will inevitably be part of their solution. These problems are model editing, personalization and specialization, on-device learning, faster (re-)training and reinforcement learning. Finally, by comparing the desiderata from these unsolved problems and the current assumptions in continual learning, we highlight and discuss four future directions for continual learning research. We hope that this work offers an interesting perspective on the future of continual learning, while displaying its potential value and the paths we have to pursue in order to make it successful. This work is the result of the many discussions the authors had at the Dagstuhl seminar on Deep Continual Learning, in March 2023.},
	number = {{arXiv}:2311.11908},
	publisher = {{arXiv}},
	author = {Verwimp, Eli and Aljundi, Rahaf and Ben-David, Shai and Bethge, Matthias and Cossu, Andrea and Gepperth, Alexander and Hayes, Tyler L. and Hüllermeier, Eyke and Kanan, Christopher and Kudithipudi, Dhireesha and Lampert, Christoph H. and Mundt, Martin and Pascanu, Razvan and Popescu, Adrian and Tolias, Andreas S. and van de Weijer, Joost and Liu, Bing and Lomonaco, Vincenzo and Tuytelaars, Tinne and van de Ven, Gido M.},
	urldate = {2024-09-25},
	date = {2024-03-28},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2311.11908 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\PCC9V9CT\\Verwimp et al. - 2024 - Continual Learning Applications and the Road Forward.pdf:application/pdf},
}

@misc{ke_continual_2023,
	title = {Continual Learning of Natural Language Processing Tasks: A Survey},
	url = {http://arxiv.org/abs/2211.12701},
	shorttitle = {Continual Learning of Natural Language Processing Tasks},
	abstract = {Continual learning ({CL}) is a learning paradigm that emulates the human capability of learning and accumulating knowledge continually without forgetting the previously learned knowledge and also transferring the learned knowledge to help learn new tasks better. This survey presents a comprehensive review and analysis of the recent progress of {CL} in {NLP}, which has significant differences from {CL} in computer vision and machine learning. It covers (1) all {CL} settings with a taxonomy of existing techniques; (2) catastrophic forgetting ({CF}) prevention, (3) knowledge transfer ({KT}), which is particularly important for {NLP} tasks; and (4) some theory and the hidden challenge of inter-task class separation ({ICS}). (1), (3) and (4) have not been included in the existing survey. Finally, a list of future directions is discussed.},
	number = {{arXiv}:2211.12701},
	publisher = {{arXiv}},
	author = {Ke, Zixuan and Liu, Bing},
	urldate = {2024-09-25},
	date = {2023-05-11},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2211.12701 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Computation and Language},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\8UUP9NGP\\Ke and Liu - 2023 - Continual Learning of Natural Language Processing Tasks A Survey.pdf:application/pdf},
}

@misc{qazi_continual_2024,
	title = {Continual Learning in Medical Imaging from Theory to Practice: A Survey and Practical Analysis},
	url = {http://arxiv.org/abs/2405.13482},
	shorttitle = {Continual Learning in Medical Imaging from Theory to Practice},
	abstract = {Deep Learning has shown great success in reshaping medical imaging, yet it faces numerous challenges hindering widespread application. Issues like catastrophic forgetting and distribution shifts in the continuously evolving data stream increase the gap between research and applications. Continual Learning offers promise in addressing these hurdles by enabling the sequential acquisition of new knowledge without forgetting previous learnings in neural networks. In this survey, we comprehensively review the recent literature on continual learning in the medical domain, highlight recent trends, and point out the practical issues. Specifically, we survey the continual learning studies on classification, segmentation, detection, and other tasks in the medical domain. Furthermore, we develop a taxonomy for the reviewed studies, identify the challenges, and provide insights to overcome them. We also critically discuss the current state of continual learning in medical imaging, including identifying open problems and outlining promising future directions. We hope this survey will provide researchers with a useful overview of the developments in the field and will further increase interest in the community. To keep up with the fast-paced advancements in this field, we plan to routinely update the repository with the latest relevant papers at https://github.com/{BioMedIA}-{MBZUAI}/awesome-cl-in-medical .},
	number = {{arXiv}:2405.13482},
	publisher = {{arXiv}},
	author = {Qazi, Mohammad Areeb and Hashmi, Anees Ur Rehman and Sanjeev, Santosh and Almakky, Ibrahim and Saeed, Numan and Yaqub, Mohammad},
	urldate = {2024-09-25},
    year = {2024}
}

@misc{yang_recent_2024,
	title = {Recent Advances of Foundation Language Models-based Continual Learning: A Survey},
	url = {http://arxiv.org/abs/2405.18653},
	shorttitle = {Recent Advances of Foundation Language Models-based Continual Learning},
	abstract = {Recently, foundation language models ({LMs}) have marked significant achievements in the domains of natural language processing ({NLP}) and computer vision ({CV}). Unlike traditional neural network models, foundation {LMs} obtain a great ability for transfer learning by acquiring rich commonsense knowledge through pre-training on extensive unsupervised datasets with a vast number of parameters. However, they still can not emulate human-like continuous learning due to catastrophic forgetting. Consequently, various continual learning ({CL})-based methodologies have been developed to refine {LMs}, enabling them to adapt to new tasks without forgetting previous knowledge. However, a systematic taxonomy of existing approaches and a comparison of their performance are still lacking, which is the gap that our survey aims to fill. We delve into a comprehensive review, summarization, and classification of the existing literature on {CL}-based approaches applied to foundation language models, such as pre-trained language models ({PLMs}), large language models ({LLMs}) and vision-language models ({VLMs}). We divide these studies into offline {CL} and online {CL}, which consist of traditional methods, parameter-efficient-based methods, instruction tuning-based methods and continual pre-training methods. Offline {CL} encompasses domain-incremental learning, task-incremental learning, and class-incremental learning, while online {CL} is subdivided into hard task boundary and blurry task boundary settings. Additionally, we outline the typical datasets and metrics employed in {CL} research and provide a detailed analysis of the challenges and future work for {LMs}-based continual learning.},
	number = {{arXiv}:2405.18653},
	publisher = {{arXiv}},
	author = {Yang, Yutao and Zhou, Jie and Ding, Xuanwen and Huai, Tianyu and Liu, Shunyu and Chen, Qin and He, Liang and Xie, Yuan},
	date = {2024-05-28},

}

@article{faber_lifelong_2024,
	title = {Lifelong Continual Learning for Anomaly Detection: New Challenges, Perspectives, and Insights},
	volume = {12},
	rights = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10473036/},
	doi = {10.1109/ACCESS.2024.3377690},
	shorttitle = {Lifelong Continual Learning for Anomaly Detection},
	pages = {41364--41380},
	journal = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Faber, Kamil and Corizzo, Roberto and Sniezynski, Bartlomiej and Japkowicz, Nathalie},
	urldate = {2024-09-25},
	date = {2024},
	langid = {english},
}

@misc{khetarpal_towards_2022,
	title = {Towards Continual Reinforcement Learning: A Review and Perspectives},
	url = {http://arxiv.org/abs/2012.13490},
	shorttitle = {Towards Continual Reinforcement Learning},
	publisher = {{arXiv}},
	author = {Khetarpal, Khimya and Riemer, Matthew and Rish, Irina and Precup, Doina},
	urldate = {2024-09-25},
	date = {2022-11-11},
}


@misc{aljundi_continual_2019,
	title = {Continual Learning in Neural Networks},
	url = {http://arxiv.org/abs/1910.02718},
	number = {{arXiv}:1910.02718},
	publisher = {{arXiv}},
	author = {Aljundi, Rahaf},
	urldate = {2024-09-25},
	date = {2019-10-18},
}

@article{mai_online_2022,
	title = {Online continual learning in image classification: An empirical survey},
	volume = {469},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231221014995},
	doi = {10.1016/j.neucom.2021.10.021},
	shorttitle = {Online continual learning in image classification},
	pages = {28--51},
	journal = {Neurocomputing},
	shortjournal = {Neurocomputing},
	author = {Mai, Zheda and Li, Ruiwen and Jeong, Jihwan and Quispe, David and Kim, Hyunwoo and Sanner, Scott},
	urldate = {2024-09-25},
	date = {2022-01},
	langid = {english},
}

@article{liu_incremental_2023,
	title = {Incremental learning with neural networks for computer vision: a survey},
	volume = {56},
	issn = {0269-2821, 1573-7462},
	url = {https://link.springer.com/10.1007/s10462-022-10294-2},
	doi = {10.1007/s10462-022-10294-2},
	shorttitle = {Incremental learning with neural networks for computer vision},
	pages = {4557--4589},
	number = {5},
	journal = {Artificial Intelligence Review},
	shortjournal = {Artif Intell Rev},
	author = {Liu, Hao and Zhou, Yong and Liu, Bing and Zhao, Jiaqi and Yao, Rui and Shao, Zhiwen},
	urldate = {2024-09-25},
	date = {2023-05},
}

@misc{soutif--cormerais_comprehensive_2023,
	title = {A Comprehensive Empirical Evaluation on Online Continual Learning},
	url = {http://arxiv.org/abs/2308.10328},
	publisher = {{arXiv}},
	author = {Soutif--Cormerais, Albin and Carta, Antonio and Cossu, Andrea and Hurtado, Julio and Hemati, Hamed and Lomonaco, Vincenzo and Van de Weijer, Joost},
	urldate = {2024-09-25},
	date = {2023-09-23},
	langid = {english},
}

@article{hurtado_continual_2023,
	title = {Continual learning for predictive maintenance: Overview and challenges},
	volume = {19},
	issn = {26673053},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2667305323000765},
	doi = {10.1016/j.iswa.2023.200251},
	shorttitle = {Continual learning for predictive maintenance},
	pages = {200251},
	journal = {Intelligent Systems with Applications},
	shortjournal = {Intelligent Systems with Applications},
	author = {Hurtado, Julio and Salvati, Dario and Semola, Rudy and Bosio, Mattia and Lomonaco, Vincenzo},
	urldate = {2024-09-25},
	date = {2023-09}
}

@misc{son_when_2024,
	title = {When Meta-Learning Meets Online and Continual Learning: A Survey},
	url = {http://arxiv.org/abs/2311.05241},
	shorttitle = {When Meta-Learning Meets Online and Continual Learning},
	abstract = {Over the past decade, deep neural networks have demonstrated significant success using the training scheme that involves mini-batch stochastic gradient descent on extensive datasets. Expanding upon this accomplishment, there has been a surge in research exploring the application of neural networks in other learning scenarios. One notable framework that has garnered significant attention is meta-learning. Often described as “learning to learn,” meta-learning is a data-driven approach to optimize the learning algorithm. Other branches of interest are continual learning and online learning, both of which involve incrementally updating a model with streaming data. While these frameworks were initially developed independently, recent works have started investigating their combinations, proposing novel problem settings and learning algorithms. However, due to the elevated complexity and lack of unified terminology, discerning differences between the learning frameworks can be challenging even for experienced researchers. To facilitate a clear understanding, this paper provides a comprehensive survey that organizes various problem settings using consistent terminology and formal descriptions. By offering an overview of these learning paradigms, our work aims to foster further advancements in this promising area of research.},
	number = {{arXiv}:2311.05241},
	publisher = {{arXiv}},
	author = {Son, Jaehyeon and Lee, Soochan and Kim, Gunhee},
	urldate = {2024-09-25},
	date = {2024-07-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2311.05241 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{guo_attention_2022,
	title = {Attention mechanisms in computer vision: A survey},
	volume = {8},
	issn = {2096-0433, 2096-0662},
	url = {https://link.springer.com/10.1007/s41095-022-0271-y},
	doi = {10.1007/s41095-022-0271-y},
	shorttitle = {Attention mechanisms in computer vision},
	abstract = {Humans can naturally and eﬀectively ﬁnd salient regions in complex scenes. Motivated by this observation, attention mechanisms were introduced into computer vision with the aim of imitating this aspect of the human visual system. Such an attention mechanism can be regarded as a dynamic weight adjustment process based on features of the input image. Attention mechanisms have achieved great success in many visual tasks, including image classiﬁcation, object detection, semantic segmentation, video understanding, image generation, 3D vision, multimodal tasks, and self-supervised learning. In this survey, we provide a comprehensive review of various attention mechanisms in computer vision and categorize them according to approach, such as channel attention, spatial attention, temporal attention, and branch attention; a related repository https://github.com/{MenghaoGuo}/ Awesome-Vision-Attentions is dedicated to collecting related work. We also suggest future directions for attention mechanism research.},
	pages = {331--368},
	number = {3},
	journal = {Computational Visual Media},
	shortjournal = {Comp. Visual Media},
	author = {Guo, Meng-Hao and Xu, Tian-Xing and Liu, Jiang-Jiang and Liu, Zheng-Ning and Jiang, Peng-Tao and Mu, Tai-Jiang and Zhang, Song-Hai and Martin, Ralph R. and Cheng, Ming-Ming and Hu, Shi-Min},
	urldate = {2024-10-14},
	date = {2022-09},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\4GM5G85A\\Guo et al. - 2022 - Attention mechanisms in computer vision A survey.pdf:application/pdf},
}

@misc{hassanin_visual_2024,
	title = {Visual Attention Methods in Deep Learning: An In-Depth Survey},
	url = {http://arxiv.org/abs/2204.07756},
	shorttitle = {Visual Attention Methods in Deep Learning},
	abstract = {Inspired by the human cognitive system, attention is a mechanism that imitates the human cognitive awareness about specific information, amplifying critical details to focus more on the essential aspects of data. Deep learning has employed attention to boost performance for many applications. Interestingly, the same attention design can suit processing different data modalities and can easily be incorporated into large networks. Furthermore, multiple complementary attention mechanisms can be incorporated into one network. Hence, attention techniques have become extremely attractive. However, the literature lacks a comprehensive survey on attention techniques to guide researchers in employing attention in their deep models. Note that, besides being demanding in terms of training data and computational resources, transformers only cover a single category in self-attention out of the many categories available. We fill this gap and provide an in-depth survey of 50 attention techniques, categorizing them by their most prominent features. We initiate our discussion by introducing the fundamental concepts behind the success of the attention mechanism. Next, we furnish some essentials such as the strengths and limitations of each attention category, describe their fundamental building blocks, basic formulations with primary usage, and applications specifically for computer vision. We also discuss the challenges and general open questions related to attention mechanisms. Finally, we recommend possible future research directions for deep attention. All the information about visual attention methods in deep learning is provided at {\textbackslash}href\{https://github.com/saeed-anwar/{VisualAttention}\}\{https://github.com/saeed-anwar/{VisualAttention}\}},
	number = {{arXiv}:2204.07756},
	publisher = {{arXiv}},
	author = {Hassanin, Mohammed and Anwar, Saeed and Radwan, Ibrahim and Khan, Fahad S. and Mian, Ajmal},
	urldate = {2024-10-14},
	date = {2024-05-05},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2204.07756 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\AE89ZUMJ\\Hassanin et al. - 2024 - Visual Attention Methods in Deep Learning An In-Depth Survey.pdf:application/pdf},
}

@misc{lomonaco_cvpr_2020,
	title = {{CVPR} 2020 Continual Learning in Computer Vision Competition: Approaches, Results, Current Challenges and Future Directions},
	url = {http://arxiv.org/abs/2009.09929},
	shorttitle = {{CVPR} 2020 Continual Learning in Computer Vision Competition},
	abstract = {In the last few years, we have witnessed a renewed and fast-growing interest in continual learning with deep neural networks with the shared objective of making current {AI} systems more adaptive, efﬁcient and autonomous. However, despite the signiﬁcant and undoubted progress of the ﬁeld in addressing the issue of catastrophic forgetting, benchmarking different continual learning approaches is a difﬁcult task by itself. In fact, given the proliferation of different settings, training and evaluation protocols, metrics and nomenclature, it is often tricky to properly characterize a continual learning algorithm, relate it to other solutions and gauge its real-world applicability. The ﬁrst Continual Learning in Computer Vision challenge held at {CVPR} in 2020 has been one of the ﬁrst opportunities to evaluate different continual learning algorithms on a common hardware with a large set of shared evaluation metrics and 3 different settings based on the realistic {CORe}50 video benchmark. In this paper, we report the main results of the competition, which counted more than 79 teams registered, 11 ﬁnalists and 2300\$ in prizes. We also summarize the winning approaches, current challenges and future research directions.},
	number = {{arXiv}:2009.09929},
	publisher = {{arXiv}},
	author = {Lomonaco, Vincenzo and Pellegrini, Lorenzo and Rodriguez, Pau and Caccia, Massimo and She, Qi and Chen, Yu and Jodelet, Quentin and Wang, Ruiping and Mai, Zheda and Vazquez, David and Parisi, German I. and Churamani, Nikhil and Pickett, Marc and Laradji, Issam and Maltoni, Davide},
	urldate = {2024-11-09},
	date = {2020-09-14},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2009.09929 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\C4UGMY76\\Lomonaco et al. - 2020 - CVPR 2020 Continual Learning in Computer Vision Competition Approaches, Results, Current Challenges.pdf:application/pdf},
}

@article{tian_survey_2024,
	title = {A survey on few-shot class-incremental learning},
	volume = {169},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608023006019},
	doi = {10.1016/j.neunet.2023.10.039},
	abstract = {Large deep learning models are impressive, but they struggle when real-time data is not available. Fewshot class-incremental learning ({FSCIL}) poses a significant challenge for deep neural networks to learn new tasks from just a few labeled samples without forgetting the previously learned ones. This setup can easily leads to catastrophic forgetting and overfitting problems, severely affecting model performance. Studying {FSCIL} helps overcome deep learning model limitations on data volume and acquisition time, while improving practicality and adaptability of machine learning models. This paper provides a comprehensive survey on {FSCIL}. Unlike previous surveys, we aim to synthesize few-shot learning and incremental learning, focusing on introducing {FSCIL} from two perspectives, while reviewing over 30 theoretical research studies and more than 20 applied research studies. From the theoretical perspective, we provide a novel categorization approach that divides the field into five subcategories, including traditional machine learning methods, meta learning-based methods, feature and feature space-based methods, replay-based methods, and dynamic network structurebased methods. We also evaluate the performance of recent theoretical research on benchmark datasets of {FSCIL}. From the application perspective, {FSCIL} has achieved impressive achievements in various fields of computer vision such as image classification, object detection, and image segmentation, as well as in natural language processing and graph. We summarize the important applications. Finally, we point out potential future research directions, including applications, problem setups, and theory development. Overall, this paper offers a comprehensive analysis of the latest advances in {FSCIL} from a methodological, performance, and application perspective.},
	pages = {307--324},
	journal = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Tian, Songsong and Li, Lusi and Li, Weijun and Ran, Hang and Ning, Xin and Tiwari, Prayag},
	urldate = {2024-11-09},
	date = {2024-01},
	langid = {english},
	file = {PDF:C\:\\Users\\Dell\\Zotero\\storage\\WXB2XTWC\\Tian et al. - 2024 - A survey on few-shot class-incremental learning.pdf:application/pdf},
}

@inproceedings{churamani_continual_2020,
	location = {Naples, Italy},
	title = {Continual Learning for Affective Robotics: Why, What and How?},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-7281-6075-7},
	url = {https://ieeexplore.ieee.org/document/9223564/},
	doi = {10.1109/RO-MAN47096.2020.9223564},
	shorttitle = {Continual Learning for Affective Robotics},
	abstract = {Creating and sustaining closed-loop dynamic and social interactions with humans require robots to continually adapt towards their users’ behaviours, their affective states and moods while keeping them engaged in the task they are performing. Analysing, understanding and appropriately responding to human nonverbal behaviour and affective states are the central objectives of affective robotics research. Conventional machine learning approaches do not scale well to the dynamic nature of such real-world interactions as they require samples from stationary data distributions. The real-world is not stationary, it changes continuously. In such contexts, the training data and learning objectives may also change rapidly. Continual Learning ({CL}), by design, is able to address this very problem by learning incrementally. In this paper, we argue that {CL} is an essential paradigm for creating fully adaptive affective robots (why). To support this argument, we ﬁrst provide an introduction to {CL} approaches and what they can offer for various dynamic (interactive) situations (what). We then formulate guidelines for the affective robotics community on how to utilise {CL} for perception and behaviour learning with adaptation (how). For each case, we reformulate the problem as a {CL} problem and outline a corresponding {CL}-based solution. We conclude the paper by highlighting the potential challenges to be faced and by providing speciﬁc recommendations on how to utilise {CL} for affective robotics.},
	eventtitle = {2020 29th {IEEE} International Conference on Robot and Human Interactive Communication ({RO}-{MAN})},
	pages = {425--431},
	booktitle = {2020 29th {IEEE} International Conference on Robot and Human Interactive Communication ({RO}-{MAN})},
	publisher = {{IEEE}},
	author = {Churamani, Nikhil and Kalkan, Sinan and Gunes, Hatice},
    year = {2020}
}

@article{parisi_continual_2019,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural networks},
  volume={113},
  pages={54--71},
  year={2019},
  publisher={Elsevier}
}
@misc{johnson2019mimiccxrjpglargepubliclyavailable,
      title={MIMIC-CXR-JPG, a large publicly available database of labeled chest radiographs}, 
      author={Alistair E. W. Johnson and Tom J. Pollard and Nathaniel R. Greenbaum and Matthew P. Lungren and Chih-ying Deng and Yifan Peng and Zhiyong Lu and Roger G. Mark and Seth J. Berkowitz and Steven Horng},
      year={2019},
      eprint={1901.07042},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1901.07042}, 
}
@article{sun2022elasticedge,
  title={Elasticedge: An intelligent elastic edge framework for live video analytics},
  author={Sun, Hui and Li, Qiyuan and Sha, Kewei and Yu, Ying},
  journal={IEEE Internet of Things Journal},
  volume={9},
  number={22},
  pages={23031--23046},
  year={2022},
  publisher={IEEE}
}
@article{sun2022edgeeye,
  title={EdgeEye: A data-driven approach for optimal deployment of edge video analytics},
  author={Sun, Hui and Yu, Ying and Sha, Kewei and Zhong, Hong},
  journal={IEEE Internet of Things Journal},
  volume={9},
  number={19},
  pages={19273--19295},
  year={2022},
  publisher={IEEE}
}
@article{liu2020temporal,
  title={Temporal memory network towards real-time video understanding},
  author={Liu, Ziming and Li, Jinyang and Gao, Guangyu and Qin, Alex K},
  journal={IEEE Access},
  volume={8},
  pages={223837--223847},
  year={2020},
  publisher={IEEE}
}
@article{yan2024spatial,
  title={Spatial and Temporal Detection With Attention for Real-Time Video Analytics At Edges},
  author={Yan, Yuting and Zhang, Sheng and Jin, Yibo and Cheng, Fangwen and Qian, Zhuzhong and Lu, Sanglu},
  journal={IEEE Transactions on Mobile Computing},
  year={2024},
  publisher={IEEE}
}
@article{ma2019ts,
  title={TS-LSTM and temporal-inception: Exploiting spatiotemporal dynamics for activity recognition},
  author={Ma, Chih-Yao and Chen, Min-Hung and Kira, Zsolt and AlRegib, Ghassan},
  journal={Signal Processing: Image Communication},
  volume={71},
  pages={76--87},
  year={2019},
  publisher={Elsevier}
}
@inproceedings{Kumar2023ALA,
  title={A Large-Scale Analysis on Self-Supervised Video Representation Learning},
  author={Akash Kumar and Ashlesha Kumar and Vibhav Vineet and Yogesh Singh Rawat},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:259129829}
}
@article{selva2023video,
  title={Video transformers: A survey},
  author={Selva, Javier and Johansen, Anders S and Escalera, Sergio and Nasrollahi, Kamal and Moeslund, Thomas B and Clap{\'e}s, Albert},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={11},
  pages={12922--12943},
  year={2023},
  publisher={IEEE}
}
@inproceedings{bertasius2021space,
  title={Is space-time attention all you need for video understanding?},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  booktitle={ICML},
  volume={2},
  number={3},
  pages={4},
  year={2021}
}

@inproceedings{ma_class_2021,
	location = {Anchorage, {AK}, {USA}},
	title = {Class Incremental Learning for Video Action Classification},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-6654-4115-5},
	url = {https://ieeexplore.ieee.org/document/9506788/},
	doi = {10.1109/ICIP42928.2021.9506788},
	eventtitle = {2021 {IEEE} International Conference on Image Processing ({ICIP})},
	pages = {504--508},
	booktitle = {2021 {IEEE} International Conference on Image Processing ({ICIP})},
	publisher = {{IEEE}},
	author = {Ma, Jiawei and Tao, Xiaoyu and Ma, Jianxing and Hong, Xiaopeng and Gong, Yihong},
	urldate = {2025-01-20},
	date = {2021-09-19},
    year = {2021},
}
@inproceedings{avidan_continual_2022,
	location = {Cham},
	title = {Continual 3D Convolutional Neural Networks for Real-time Processing of Videos},
	volume = {13664},
	isbn = {978-3-031-19771-0 978-3-031-19772-7},
	url = {https://link.springer.com/10.1007/978-3-031-19772-7_22},
	pages = {369--385},
	booktitle = {Computer Vision – {ECCV} 2022},
	publisher = {Springer Nature Switzerland},
	author = {Hedegaard, Lukas and Iosifidis, Alexandros},
	editor = {Avidan, Shai and Brostow, Gabriel and Cissé, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
	urldate = {2025-01-18},
	date = {2022},
    year = {2022},
	langid = {english},
	doi = {10.1007/978-3-031-19772-7_22},
	note = {Series Title: Lecture Notes in Computer Science},
}
@article{pei2022learning,
  title={Learning a condensed frame for memory-efficient video class-incremental learning},
  author={Pei, Yixuan and Qing, Zhiwu and Cen, Jun and Wang, Xiang and Zhang, Shiwei and Wang, Yaxiong and Tang, Mingqian and Sang, Nong and Qian, Xueming},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={31002--31016},
  year={2022},
}
@inproceedings{castagnolo_baseline_2023,
  title={A baseline on continual learning methods for video action recognition},
  author={Castagnolo, Giulia and Spampinato, Concetto and Rundo, Francesco and Giordano, Daniela and Palazzo, Simone},
  booktitle={2023 IEEE International Conference on Image Processing (ICIP)},
  pages={3240--3244},
  year={2023},
  organization={IEEE},
}
@inproceedings{villa_pivot_2023,
	location = {Vancouver, {BC}, Canada},
	title = {{PIVOT}: Prompting for Video Continual Learning},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-0129-8},
	url = {https://ieeexplore.ieee.org/document/10203136/},
	doi = {10.1109/CVPR52729.2023.02319},
	shorttitle = {{PIVOT}},
	eventtitle = {2023 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {24214--24223},
	booktitle = {2023 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	publisher = {{IEEE}},
	author = {Villa, Andrés and Alcázar, Juan León and Alfarra, Motasem and Alhamoud, Kumail and Hurtado, Julio and Heilbron, Fabian Caba and Soto, Alvaro and Ghanem, Bernard},
	urldate = {2025-01-18},
	date = {2023-06},
    year = {2023},
}
@inproceedings{alssum_just_2023,
	location = {Vancouver, {BC}, Canada},
	title = {Just a Glimpse: Rethinking Temporal Information for Video Continual Learning},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-0249-3},
	url = {https://ieeexplore.ieee.org/document/10208593/},
	doi = {10.1109/CVPRW59228.2023.00246},
	shorttitle = {Just a Glimpse},
	eventtitle = {2023 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	pages = {2474--2483},
	booktitle = {2023 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	publisher = {{IEEE}},
	author = {Alssum, Lama and León Alcázar, Juan and Ramazanova, Merey and Zhao, Chen and Ghanem, Bernard},
	urldate = {2025-01-18},
	date = {2023-06},
    year = {2023},
}
@inproceedings{long_mixup-inspired_2023,
	location = {Shanghai, China},
	title = {Mixup-Inspired Video Class-Incremental Learning},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-0788-7},
	url = {https://ieeexplore.ieee.org/document/10415756/},
	doi = {10.1109/ICDM58522.2023.00145},
	eventtitle = {2023 {IEEE} International Conference on Data Mining ({ICDM})},
	pages = {1181--1186},
	booktitle = {2023 {IEEE} International Conference on Data Mining ({ICDM})},
	publisher = {{IEEE}},
	author = {Long, Jinqiang and Gao, Yizhao and Lu, Zhiwu},
	urldate = {2025-01-18},
	date = {2023-12-01},
    year = {2023},
}
@inproceedings{park_class-incremental_2021,
  title={Class-incremental learning for action recognition in videos},
  author={Park, Jaeyoo and Kang, Minsoo and Han, Bohyung},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={13698--13707},
  year={2021}
}
@article{wang_continuous_2022,
	title = {Continuous Multi-View Human Action Recognition},
	volume = {32},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1051-8215, 1558-2205},
	url = {https://ieeexplore.ieee.org/document/9536666/},
	doi = {10.1109/TCSVT.2021.3112214},
	pages = {3603--3614},
	number = {6},
	journal = {{IEEE} Transactions on Circuits and Systems for Video Technology},
	shortjournal = {{IEEE} Trans. Circuits Syst. Video Technol.},
	author = {Wang, Qiang and Sun, Gan and Dong, Jiahua and Wang, Qianqian and Ding, Zhengming},
	urldate = {2025-01-18},
	date = {2022-06},
    year = {2022},
}
@article{feng_spatiotemporal_2024,
	title = {Spatiotemporal Orthogonal Projection Capsule Network for Incremental Few-Shot Action Recognition},
	volume = {26},
	issn = {1941-0077},
	url = {https://ieeexplore.ieee.org/document/10530059},
	doi = {10.1109/TMM.2024.3399453},
	pages = {9825--9838},
	journal = {{IEEE} Transactions on Multimedia},
	author = {Feng, Yangbo and Gao, Junyu and Xu, Changsheng},
	urldate = {2025-01-28},
	date = {2024},
    year = {2024},
	note = {Conference Name: {IEEE} Transactions on Multimedia},
}
@inproceedings{kann_evaluation_2023,
	location = {Atlanta, {GA}, {USA}},
	title = {Evaluation of Regularization-based Continual Learning Approaches: Application to {HAR}},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-6654-5381-3},
	url = {https://ieeexplore.ieee.org/document/10150281/},
	doi = {10.1109/PerComWorkshops56833.2023.10150281},
	shorttitle = {Evaluation of Regularization-based Continual Learning Approaches},	eventtitle = {2023 {IEEE} International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events ({PerCom} Workshops)},
	pages = {460--465},
	booktitle = {2023 {IEEE} International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events ({PerCom} Workshops)},
	publisher = {{IEEE}},
	author = {Kann, Bonpagna and Castellanos-Paez, Sandra and Lalanda, Philippe},
	urldate = {2024-12-23},
	date = {2023-03-13},
    year = {2023},
}
@inproceedings{pei_space-time_2023,
	location = {Paris, France},
	title = {Space-time Prompting for Video Class-incremental Learning},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-0718-4},
	url = {https://ieeexplore.ieee.org/document/10378035/},
	doi = {10.1109/ICCV51070.2023.01096},
	eventtitle = {2023 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	pages = {11898--11908},
	booktitle = {2023 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	publisher = {{IEEE}},
	author = {Pei, Yixuan and Qing, Zhiwu and Zhang, Shiwei and Wang, Xiang and Zhang, Yingya and Zhao, Deli and Qian, Xueming},
	urldate = {2025-01-28},
	date = {2023-10-01},
    year = {2023},
}
@article{pei_2024,
    author = {Pei, Sen and Xu, Shixiong and Jin, Xiaojie},
    year = {2024},
    month = {03},
    pages = {10155-10163},
    title = {Exploring Domain Incremental Video Highlights Detection with the LiveFood Benchmark},
    volume = {38},
    journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
    doi = {10.1609/aaai.v38i9.28880}
}
@inproceedings{Fu2024DecoupledPT,
  author       = {Di Fu, Thanh Vinh Vo, Haozhe Ma, Tze{-}Yun Leong},
  title        = {Decoupled Prompt-Adapter Tuning for Continual Activity Recognition},
  booktitle    = {CoLLAs},
  series       = {Proceedings of Machine Learning Research},
  volume       = {274},
  pages        = {784--797},
  publisher    = {{PMLR}},
  year         = {2024}
}
@inproceedings{lu_video_2024,
	location = {Abu Dhabi, United Arab Emirates},
	title = {Video Class-Incremental Learning With Clip Based Transformer},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-4939-9},
	url = {https://ieeexplore.ieee.org/document/10647787/},
	doi = {10.1109/ICIP51287.2024.10647787},
	eventtitle = {2024 {IEEE} International Conference on Image Processing ({ICIP})},
	pages = {500--506},
	booktitle = {2024 {IEEE} International Conference on Image Processing ({ICIP})},
	publisher = {{IEEE}},
	author = {Lu, Shuyun and Jiao, Jian and Wang, Lanxiao and Qiu, Heqian and Lin, Xingtao and Mei, Hefei and Li, Hongliang},
	urldate = {2025-01-18},
	date = {2024-10-27},
    year = {2024}
}
@inproceedings{kurpukdee_temporal_2024,
	location = {Abu Dhabi, United Arab Emirates},
	title = {Temporal Transformer Encoder for Video Class Incremental Learning},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-4939-9},
	url = {https://ieeexplore.ieee.org/document/10647854/},
	doi = {10.1109/ICIP51287.2024.10647854},
	eventtitle = {2024 {IEEE} International Conference on Image Processing ({ICIP})},
	pages = {1295--1301},
	booktitle = {2024 {IEEE} International Conference on Image Processing ({ICIP})},
	publisher = {{IEEE}},
	author = {Kurpukdee, Nattapong and Bors, Adrian G.},
	urldate = {2025-01-18},
	date = {2024-10-27},
    year = {2024},
}
@inproceedings{cheng2024stsp,
  title={Stsp: Spatial-temporal subspace projection for video class-incremental learning},
  author={Cheng, Hao and Yang, Siyuan and Wang, Chong and Zhou, Joey Tianyi and Kot, Alex C and Wen, Bihan},
  booktitle={European Conference on Computer Vision},
  pages={374--391},
  year={2024},
  organization={Springer}
}
@article{xin2023transformer,
  title={Transformer for skeleton-based action recognition: A review of recent advances},
  author={Xin, Wentian and Liu, Ruyi and Liu, Yi and Chen, Yu and Yu, Wenxin and Miao, Qiguang},
  journal={Neurocomputing},
  volume={537},
  pages={164--186},
  year={2023},
  publisher={Elsevier}
}
@article{sun2022human,
  title={Human action recognition from various data modalities: A review},
  author={Sun, Zehua and Ke, Qiuhong and Rahmani, Hossein and Bennamoun, Mohammed and Wang, Gang and Liu, Jun},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={3},
  pages={3200--3225},
  year={2022},
  publisher={IEEE}
}
@inproceedings{li_else-net_2021,
	location = {Montreal, {QC}, Canada},
	title = {Else-Net: Elastic Semantic Network for Continual Action Recognition from Skeleton Data},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-6654-2812-5},
	url = {https://ieeexplore.ieee.org/document/9711342/},
	doi = {10.1109/ICCV48922.2021.01318},
	shorttitle = {Else-Net},
	eventtitle = {2021 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	pages = {13414--13423},
	booktitle = {2021 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	publisher = {{IEEE}},
	author = {Li, Tianjiao and Ke, Qiuhong and Rahmani, Hossein and Ho, Rui En and Ding, Henghui and Liu, Jun},
	urldate = {2024-12-23},
	date = {2021-10},
    year = {2021},
	langid = {english},
}
@inproceedings{mosconi2025mask,
  title={Mask and compress: Efficient skeleton-based action recognition in continual learning},
  author={Mosconi, Matteo and Sorokin, Andriy and Panariello, Aniello and Porrello, Angelo and Bonato, Jacopo and Cotogni, Marco and Sabetta, Luigi and Calderara, Simone and Cucchiara, Rita},
  booktitle={International Conference on Pattern Recognition},
  pages={1--15},
  year={2025},
  organization={Springer}
}
@inproceedings{zhu2024advancing,
  title={Advancing Video Anomaly Detection: A concise review and a new dataset},
  author={Zhu, Liyun and Wang, Lei and Raj, Arjun and Gedeon, Tom and Chen, Chen},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2024}
}
@inproceedings{doshi_continual_2020,
	location = {Seattle, {WA}, {USA}},
	title = {Continual Learning for Anomaly Detection in Surveillance Videos},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-7281-9360-1},
	url = {https://ieeexplore.ieee.org/document/9150686/},
	doi = {10.1109/CVPRW50498.2020.00135},
	eventtitle = {2020 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	pages = {1025--1034},
	booktitle = {2020 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	publisher = {{IEEE}},
	author = {Doshi, Keval and Yilmaz, Yasin},
	urldate = {2025-01-18},
	date = {2020-06},
    year = {2020},
	langid = {english},
}
@inproceedings{doshi_rethinking_2022,
	location = {Waikoloa, {HI}, {USA}},
	title = {Rethinking Video Anomaly Detection - A Continual Learning Approach},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-6654-0915-5},
	url = {https://ieeexplore.ieee.org/document/9706619/},
	doi = {10.1109/WACV51458.2022.00309},
	eventtitle = {2022 {IEEE}/{CVF} Winter Conference on Applications of Computer Vision ({WACV})},
	pages = {3036--3045},
	booktitle = {2022 {IEEE}/{CVF} Winter Conference on Applications of Computer Vision ({WACV})},
	publisher = {{IEEE}},
	author = {Doshi, Keval and Yilmaz, Yasin},
	urldate = {2025-01-18},
	date = {2022-01},
    year = {2022},
	langid = {english},
}
@inproceedings{zaghdoud2023metaplastic,
  title={A metaplastic neural network technique for human activity recognition for Alzheimer’s patients},
  author={Zaghdoud, Ahmed and Jemai, Olfa},
  booktitle={2023 International Conference on Innovations in Intelligent Systems and Applications (INISTA)},
  pages={1--6},
  year={2023},
  organization={IEEE}
}
@article{he2024continual,
  title={Continual Egocentric Activity Recognition with Foreseeable-Generalized Visual-IMU Representations},
  author={He, Chiyuan and Cheng, Shaoxu and Qiu, Zihuan and Xu, Linfeng and Meng, Fanman and Wu, Qingbo and Li, Hongliang},
  journal={IEEE Sensors Journal},
  year={2024},
  publisher={IEEE}
}
@inproceedings{wang_catnet_2020,
	location = {Seattle, {WA}, {USA}},
	title = {{CatNet}: Class Incremental 3D {ConvNets} for Lifelong Egocentric Gesture Recognition},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-7281-9360-1},
	url = {https://ieeexplore.ieee.org/document/9150823/},
	doi = {10.1109/CVPRW50498.2020.00123},
	shorttitle = {{CatNet}},
	eventtitle = {2020 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	pages = {935--944},
	booktitle = {2020 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	publisher = {{IEEE}},
	author = {Wang, Zhengwei and She, Qi and Chalasani, Tejo and Smolic, Aljosa},
	urldate = {2025-01-18},
	date = {2020-06},
    year = {2020},
}

@inproceedings{tasar2019continual,
  title={Continual learning for dense labeling of satellite images},
  author={Tasar, Onur and Tarabalka, Yuliya and Alliez, Pierre},
  booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
  pages={4943--4946},
  year={2019},
  organization={IEEE}
}

@article{li2020clrs,
  title={CLRS: Continual learning benchmark for remote sensing image scene classification},
  author={Li, Haifeng and Jiang, Hao and Gu, Xin and Peng, Jian and Li, Wenbo and Hong, Liang and Tao, Chao},
  journal={Sensors},
  volume={20},
  number={4},
  pages={1226},
  year={2020},
  publisher={MDPI}
}

@article{lu2021lil,
  title={LIL: Lightweight incremental learning approach through feature transfer for remote sensing image scene classification},
  author={Lu, Xiaonan and Sun, Xian and Diao, Wenhui and Feng, Yingchao and Wang, Peijin and Fu, Kun},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--20},
  year={2021},
  publisher={IEEE}
}

@inproceedings{xi2021continual,
  title={Continual learning for scene classification of high resolution remote sensing images},
  author={Xi, Jiangbo and Yan, Ziyun and Jiang, Wandong and Xiang, Yaobing and Xie, Dashuai},
  booktitle={Twelfth International Conference on Information Optics and Photonics},
  volume={12057},
  pages={558--574},
  year={2021},
  organization={SPIE}
}

@article{peng2022continual,
  title={Continual contrastive learning for cross-dataset scene classification},
  author={Peng, Rui and Zhao, Wenzhi and Li, Kaiyuan and Ji, Fengcheng and Rong, Caixia},
  journal={Remote Sensing},
  volume={14},
  number={20},
  pages={5105},
  year={2022},
  publisher={MDPI}
}

@article{ye2022better,
  title={Better memorization, better recall: A lifelong learning framework for remote sensing image scene classification},
  author={Ye, Dingqi and Peng, Jian and Li, Haifeng and Bruzzone, Lorenzo},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--14},
  year={2022},
  publisher={IEEE}
}

@inproceedings{alakooz2022contrastive,
  title={A contrastive continual learning for the classification of remote sensing imagery},
  author={Alakooz, Abdulaziz S and Ammour, Nassim},
  booktitle={IGARSS 2022-2022 IEEE International Geoscience and Remote Sensing Symposium},
  pages={7902--7905},
  year={2022},
  organization={IEEE}
}

@article{rong2023micro,
  title={MiCro: Modeling cross-image semantic relationship dependencies for class-incremental semantic segmentation in remote sensing images},
  author={Rong, Xuee and Wang, Peijin and Diao, Wenhui and Yang, Yiran and Yin, Wenxin and Zeng, Xuan and Wang, Hongqi and Sun, Xian},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2023},
  publisher={IEEE}
}

@article{bhat2023efficient,
  title={Efficient curriculum based continual learning with informative subset selection for remote sensing scene classification},
  author={Bhat, S Divakar and Banerjee, Biplab and Chaudhuri, Subhasis and Bhattacharya, Avik},
  journal={arXiv preprint arXiv:2309.01050},
  year={2023}
}

@article{zhao2023continual,
  title={Continual learning for remote sensing image scene classification with prompt learning},
  author={Zhao, Ling and Xu, Linrui and Zhao, Li and Zhang, Xiaoling and Wang, Yuhan and Ye, Dingqi and Peng, Jian and Li, Haifeng},
  journal={IEEE Geoscience and Remote Sensing Letters},
  year={2023},
  publisher={IEEE}
}

@article{tasar2019incremental,
  title={Incremental learning for semantic segmentation of large-scale remote sensing data},
  author={Tasar, Onur and Tarabalka, Yuliya and Alliez, Pierre},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={12},
  number={9},
  pages={3524--3537},
  year={2019},
  publisher={IEEE}
}

@article{feng2021continual,
  title={Continual learning with structured inheritance for semantic segmentation in aerial imagery},
  author={Feng, Yingchao and Sun, Xian and Diao, Wenhui and Li, Jihao and Gao, Xin and Fu, Kun},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--17},
  year={2021},
  publisher={IEEE}
}

@article{li2022sil,
  title={Sil-land: Segmentation incremental learning in aerial imagery via label number distribution consistency},
  author={Li, Junxi and Diao, Wenhui and Lu, Xiaonan and Wang, Peijin and Zhang, Yidan and Yang, Zhujun and Xu, Guangluan and Sun, Xian},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--20},
  year={2022},
  publisher={IEEE}
}

@inproceedings{lenczner2022weakly,
  title={Weakly-supervised continual learning for class-incremental segmentation},
  author={Lenczner, Gaston and Chan-Hon-Tong, Adrien and Luminari, Nicola and Le Saux, Bertrand},
  booktitle={IGARSS 2022-2022 IEEE International Geoscience and Remote Sensing Symposium},
  pages={4843--4846},
  year={2022},
  organization={IEEE}
}

@article{rong2022historical,
  title={Historical information-guided class-incremental semantic segmentation in remote sensing images},
  author={Rong, Xuee and Sun, Xian and Diao, Wenhui and Wang, Peijin and Yuan, Zhiqiang and Wang, Hongqi},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--18},
  year={2022},
  publisher={IEEE}
}

@article{lenczner2022dial,
  title={DIAL: Deep interactive and active learning for semantic segmentation in remote sensing},
  author={Lenczner, Gaston and Chan-Hon-Tong, Adrien and Le Saux, Bertrand and Luminari, Nicola and Le Besnerais, Guy},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={15},
  pages={3376--3389},
  year={2022},
  publisher={IEEE}
}

@article{marsocci2023continual,
  title={Continual barlow twins: continual self-supervised learning for remote sensing semantic segmentation},
  author={Marsocci, Valerio and Scardapane, Simone},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={16},
  pages={5049--5060},
  year={2023},
  publisher={IEEE}
}

@article{li2021class,
  title={Class-incremental learning network for small objects enhancing of semantic segmentation in aerial imagery},
  author={Li, Junxi and Sun, Xian and Diao, Wenhui and Wang, Peijin and Feng, Yingchao and Lu, Xiaonan and Xu, Guangluan},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--20},
  year={2021},
  publisher={IEEE}
}

@article{shan2022class,
  title={Class-incremental semantic segmentation of aerial images via pixel-level feature generation and task-wise distillation},
  author={Shan, Lianlei and Wang, Weiqiang and Lv, Ke and Luo, Bin},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--17},
  year={2022},
  publisher={IEEE}
}

@article{shan2021class,
  title={Class-incremental learning for semantic segmentation in aerial imagery via distillation in all aspects},
  author={Shan, Lianlei and Wang, Weiqiang and Lv, Ke and Luo, Bin},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--12},
  year={2021},
  publisher={IEEE}
}

@article{rong2023micro,
  title={MiCro: Modeling cross-image semantic relationship dependencies for class-incremental semantic segmentation in remote sensing images},
  author={Rong, Xuee and Wang, Peijin and Diao, Wenhui and Yang, Yiran and Yin, Wenxin and Zeng, Xuan and Wang, Hongqi and Sun, Xian},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2023},
  publisher={IEEE}
}

@article{chen2020incremental,
  title={Incremental detection of remote sensing objects with feature pyramid and knowledge distillation},
  author={Chen, Jingzhou and Wang, Shihao and Chen, Ling and Cai, Haibin and Qian, Yuntao},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--13},
  year={2020},
  publisher={IEEE}
}

@article{li2022incremental,
  title={Incremental learning based on anchored class centers for SAR automatic target recognition},
  author={Li, Bin and Cui, Zongyong and Cao, Zongjie and Yang, Jianyu},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--13},
  year={2022},
  publisher={IEEE}
}

@article{li2021class,
  title={Class-incremental learning network for small objects enhancing of semantic segmentation in aerial imagery},
  author={Li, Junxi and Sun, Xian and Diao, Wenhui and Wang, Peijin and Feng, Yingchao and Lu, Xiaonan and Xu, Guangluan},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--20},
  year={2021},
  publisher={IEEE}
}

@article{chen2023online,
  title={An online continual object detector on VHR remote sensing images with class imbalance},
  author={Chen, Xi and Jiang, Jie and Li, Zhiqiang and Qi, Honggang and Li, Qingli and Liu, Jiapeng and Zheng, Laiwen and Liu, Min and Deng, Yongqiang},
  journal={Engineering Applications of Artificial Intelligence},
  volume={117},
  pages={105549},
  year={2023},
  publisher={Elsevier}
}

@article{dang2023distribution,
  title={Distribution reliability assessment-based incremental learning for automatic target recognition},
  author={Dang, Sihang and Cui, Zongyong and Cao, Zongjie and Pi, Yiming and Feng, Xiaoyi},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={61},
  pages={1--13},
  year={2023},
  publisher={IEEE}
}

@article{tian2024continual,
  title={Continual Learning for SAR Target Incremental Detection via Predicted Location Probability Representation and Proposal Selection},
  author={Tian, Yu and Cui, Zongyong and Ma, Jizhen and Zhou, Zheng and Cao, Zongjie},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

@article{zhao2024decoupled,
  title={Decoupled Self-Supervised Subspace Classifier for Few-Shot Class-Incremental SAR Target Recognition},
  author={Zhao, Yan and Zhao, Lingjun and Zhang, Siqian and Liu, Li and Ji, Kefeng and Kuang, Gangyao},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

@article{li2022sil,
  title={Sil-land: Segmentation incremental learning in aerial imagery via label number distribution consistency},
  author={Li, Junxi and Diao, Wenhui and Lu, Xiaonan and Wang, Peijin and Zhang, Yidan and Yang, Zhujun and Xu, Guangluan and Sun, Xian},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--20},
  year={2022},
  publisher={IEEE}
}

@article{li2021class,
  title={Class-incremental learning network for small objects enhancing of semantic segmentation in aerial imagery},
  author={Li, Junxi and Sun, Xian and Diao, Wenhui and Wang, Peijin and Feng, Yingchao and Lu, Xiaonan and Xu, Guangluan},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--20},
  year={2021},
  publisher={IEEE}
}

@article{shan2022class,
  title={Class-incremental semantic segmentation of aerial images via pixel-level feature generation and task-wise distillation},
  author={Shan, Lianlei and Wang, Weiqiang and Lv, Ke and Luo, Bin},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--17},
  year={2022},
  publisher={IEEE}
}

@article{shan2021class,
  title={Class-incremental learning for semantic segmentation in aerial imagery via distillation in all aspects},
  author={Shan, Lianlei and Wang, Weiqiang and Lv, Ke and Luo, Bin},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--12},
  year={2021},
  publisher={IEEE}
}

@article{yang2020geoboost,
  title={GeoBoost: An incremental deep learning approach toward global mapping of buildings from VHR remote sensing images},
  author={Yang, Naisen and Tang, Hong},
  journal={Remote Sensing},
  volume={12},
  number={11},
  pages={1794},
  year={2020},
  publisher={MDPI}
}

@article{zhao2022life,
  title={Life-long learning with continual spectral-spatial feature distillation for hyperspectral image classification},
  author={Zhao, Wenzhi and Peng, Rui and Wang, Qiao and Cheng, Changxiu and Emery, William J and Zhang, Liqiang},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--14},
  year={2022},
  publisher={IEEE}
}

@article{zhu2023few,
  title={Few-shot incremental learning with continual prototype calibration for remote sensing image fine-grained classification},
  author={Zhu, Zining and Wang, Peijin and Diao, Wenhui and Yang, Jinze and Wang, Hongqi and Sun, Xian},
  journal={ISPRS Journal of Photogrammetry and Remote Sensing},
  volume={196},
  pages={210--227},
  year={2023},
  publisher={Elsevier}
}

@article{shen2023continual,
  title={A continual learning-guided training framework for pansharpening},
  author={Shen, Kangqing and Yang, Xiaoyuan and Lolli, Simone and Vivone, Gemine},
  journal={ISPRS Journal of Photogrammetry and Remote Sensing},
  volume={196},
  pages={45--57},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{song2023class,
  title={Class-Incremental Learning for Remote Sensing Images Based on Knowledge Distillation},
  author={Song, Jingduo and Jia, Hecheng and Xu, Feng},
  booktitle={IGARSS 2023-2023 IEEE International Geoscience and Remote Sensing Symposium},
  pages={5026--5028},
  year={2023},
  organization={IEEE}
}

@inproceedings{chien2024plant,
  title={Plant Species Recognition Based on Continual Learning Strategy},
  author={Chien, Hung-Yi and Liu, Keng-Hao and Lin, Chinsu},
  booktitle={IGARSS 2024-2024 IEEE International Geoscience and Remote Sensing Symposium},
  pages={10363--10367},
  year={2024},
  organization={IEEE}
}

@article{yu2024continual,
  title={A continual learning-based multilayer perceptron for improved reconstruction of three-dimensional nitrate concentration},
  author={Yu, Xiang and Guo, Huadong and Zhang, Jiahua and Ma, Yi and Wang, Xiaopeng and Liu, Guangsheng and Xing, Mingming and Xu, Nuo and Seka, Ayalkibet},
  journal={Earth System Science Data Discussions},
  volume={2024},
  pages={1--35},
  year={2024},
  publisher={G{\"o}ttingen, Germany}
}

@inproceedings{boum2024continual,
  title={Continual learning in remote sensing: Leveraging foundation models and generative classifiers to mitigate forgetting},
  author={Boum, Marie-Ange and Herbin, St{\'e}phane and Fournier, Pierre and Lassalle, Pierre},
  booktitle={IGARSS 2024-2024 IEEE International Geoscience and Remote Sensing Symposium},
  pages={8535--8540},
  year={2024},
  organization={IEEE}
}

@inproceedings{yuan2024continual,
  title={Continual panoptic perception: Towards multi-modal incremental interpretation of remote sensing images},
  author={Yuan, Bo and Zhao, Danpei and Liu, Zhuoran and Li, Wentao and Li, Tian},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={2117--2126},
  year={2024}
}

@article{yang2023knowledge,
  title={A Knowledge Distillation-based Ground Feature Classification Network with Multiscale Feature Fusion in Remote Sensing Images},
  author={Yang, Yang and Wang, Yanhui and Dong, Junwu and Yu, Bibo},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  year={2023},
  publisher={IEEE}
}
@inproceedings{ayromlou2022classimpressiondatafreeincremental,
  title={Class impression for data-free incremental learning},
  author={Ayromlou, Sana and Abolmaesumi, Purang and Tsang, Teresa and Li, Xiaoxiao},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={320--329},
  year={2022},
  organization={Springer}
}
@InProceedings{10.1007/978-3-031-16961-8_18,
author="Kaustaban, Veena
and Ba, Qinle
and Bhattacharya, Ipshita
and Sobh, Nahil
and Mukherjee, Satarupa
and Martin, Jim
and Miri, Mohammad Saleh
and Guetter, Christoph
and Chaturvedi, Amal",
editor="Huo, Yuankai
and Millis, Bryan A.
and Zhou, Yuyin
and Wang, Xiangxue
and Harrison, Adam P.
and Xu, Ziyue",
title="Characterizing Continual Learning Scenarios for Tumor Classification in Histopathology Images",
booktitle="Medical Optical Imaging and Virtual Microscopy Image Analysis",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="177--187",
abstract="Recent years have seen great advancements in the development of deep-learning models for histopathology image analysis in digital pathology (DP) applications, evidenced by the increasingly common deployment of these models in both research and clinical settings. Although such models have shown unprecedented performance in solving fundamental computational tasks in DP applications, they suffer from catastrophic forgetting when adapted to unseen data with transfer learning. With an increasing need for deep-learning models to handle ever-changing data distributions, including evolving patient population and new diagnosis assays, continual learning (CL) models that alleviate model forgetting need to be introduced in DP-based analysis. However, to our best knowledge, there's no systematic study of such models for DP-specific applications. Here, we propose CL scenarios in DP settings, where histopathology image data from different sources/distributions arrive sequentially, the knowledge of which is integrated into a single model without training all the data from scratch. We then established an augmented dataset for colorectal cancer H {\&}E classification to simulate shifts of image appearance and evaluated CL model performance in the proposed CL scenarios. We leveraged a breast tumor H {\&}E dataset along with the colorectal cancer to evaluate CL from different tumor types. In addition, we evaluated CL methods in an online few-shot setting under the constraints of annotation and computational resources. We revealed promising results of CL in DP applications, potentially paving the way for application of these methods in clinical practice.",
isbn="978-3-031-16961-8"
}

@article{yang2022continuallearningbayesianmodel,
  title={Continual learning with bayesian model based on a fixed pre-trained feature extractor},
  author={Yang, Yang and Cui, Zhiying and Xu, Junjie and Zhong, Changhong and Zheng, Wei-Shi and Wang, Ruixuan},
  journal={Visual Intelligence},
  volume={1},
  number={1},
  pages={5},
  year={2023},
  publisher={Springer}
}

@article{TANG2023107399,
title = {CLELNet: A continual learning network for esophageal lesion analysis on endoscopic images},
journal = {Computer Methods and Programs in Biomedicine},
volume = {231},
pages = {107399},
year = {2023},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2023.107399},
url = {https://www.sciencedirect.com/science/article/pii/S0169260723000664},
author = {Suigu Tang and Xiaoyuan Yu and Chak Fong Cheang and Xiaoyu Ji and Hon Ho Yu and I Cheong Choi},
keywords = {Continual learning, Convolutional autoencoder, Classification, Esophageal endoscopic images, Segmentation},
abstract = {Background and Objective: A deep learning-based intelligent diagnosis system can significantly reduce the burden of endoscopists in the daily analysis of esophageal lesions. Considering the need to add new tasks in the diagnosis system, a deep learning model that can train a series of tasks incrementally using endoscopic images is essential for identifying the types and regions of esophageal lesions. Method: In this paper, we proposed a continual learning-based esophageal lesion network (CLELNet), in which a convolutional autoencoder was designed to extract representation features of endoscopic images among different esophageal lesions. The proposed CLELNet consists of shared layers and task-specific layers. Shared layers are used to extract common features among different lesions while task-specific layers can complete different tasks. The first two tasks trained by the CLELNet are the classification (task 1) and the segmentation (task 2). We collected a dataset of esophageal endoscopic images from Macau Kiang Wu Hospital for training and testing the CLELNet. Results: The experimental results showed that the classification accuracy of task 1 was 95.96%, and the Intersection Over Union and the Dice Similarity Coefficient of task 2 were 65.66% and 78.08%, respectively. Conclusions: The proposed CLELNet can realize task-incremental learning without forgetting the previous tasks and thus become a useful computer-aided diagnosis system in esophageal lesions analysis.}
}

@inproceedings{chen2024testimagedeservesspecific,
  title={Each test image deserves a specific prompt: Continual test-time adaptation for 2d medical image segmentation},
  author={Chen, Ziyang and Pan, Yongsheng and Ye, Yiwen and Lu, Mengkang and Xia, Yong},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11184--11193},
  year={2024}
}
@INPROCEEDINGS{10385304,
  author={Zhao, Defeng and Ye, Zejun and Zheng, Wei-Shi and Wang, Ruixuan},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Class-specific Prompts in Vision Transformer for Continual Learning of New Diseases}, 
  year={2023},
  volume={},
  number={},
  pages={994-999},
  keywords={Image segmentation;Data privacy;Source coding;Training data;Feature extraction;Transformers;Lesions;Continual learning;Prompt learning;Disease diagnosis},
  doi={10.1109/BIBM58861.2023.10385304}
}

@inproceedings{sadafi2023continuallearningapproachcrossdomain,
  title={A continual learning approach for cross-domain white blood cell classification},
  author={Sadafi, Ario and Salehi, Raheleh and Gruber, Armin and Boushehri, Sayedali Shetab and Giehr, Pascal and Navab, Nassir and Marr, Carsten},
  booktitle={MICCAI Workshop on Domain Adaptation and Representation Transfer},
  pages={136--146},
  year={2023},
  organization={Springer}
}
@misc{item_9fda3f3594bd4a32b2ee17c2b70e419a, 
title={Resource-Efficient Continual Learning for Personalized Online Seizure Detection}, url={https://infoscience.epfl.ch/handle/20.500.14299/207514}, abstractNote={Epilepsy, a major neurological disease, requires careful diagnosis and treatment. However, the detection of epileptic seizures remains a significant challenge. Current clinical practice relies on expert analysis of EEG signals, a process that is time-consuming and requires specialized knowledge. This paper explores the potential for automated epileptic seizure detection using deep learning techniques, with a particular focus on personalized models based on continual learning. We highlight the importance of adapting these models to each patient’s unique EEG signal features, which evolve over time. Our approach addresses the fundamental challenge of integrating new data into existing models without losing previously acquired information, a common issue in static deep learning models when applied in dynamic environments. In this study, we propose a novel continual learning algorithm for seizure detection, which integrates a replay buffer mechanism. This mechanism is key to retaining relevant information on past data while acquiring new one, thus effectively enhancing the model’s performance over time. Our methodology is designed to be resource-efficient, making it suitable for implementation in embedded systems. We demonstrate the effectiveness of our approach using the CHB-MIT dataset, achieving an improvement of 35.34% in the F1 score with respect to a fine-tuning approach that does not consider catastrophic forgetting. Furthermore, we show that a small 1-hour data replay buffer suffices to achieve F1 scores comparable to that of a resource-unlimited scenario, while also decreasing the False Alarm Rate in 24 hours by 33% compared to a resource-unconstrained method.}, author={Shahbazinia, Amirhossein and Ponzina, Flavio and Miranda Calero, José Angel and Dan, Jonathan and Ansaloni, Giovanni and Atienza Alonso, David}, year={2024}, month={apr}, keywords={Seizure Detection | Continual Learning | Incremental Learning | Deep Learning | Personalized Models | Wearable Devices} }

@Article{healthcare12020155,
AUTHOR = {Li, Ao and Li, Huayu and Yuan, Geng},
TITLE = {Continual Learning with Deep Neural Networks in Physiological Signal Data: A Survey},
JOURNAL = {Healthcare},
VOLUME = {12},
YEAR = {2024},
NUMBER = {2},
ARTICLE-NUMBER = {155},
URL = {https://www.mdpi.com/2227-9032/12/2/155},
PubMedID = {38255045},
ISSN = {2227-9032},
ABSTRACT = {Deep-learning algorithms hold promise in processing physiological signal data, including electrocardiograms (ECGs) and electroencephalograms (EEGs). However, healthcare often requires long-term monitoring, posing a challenge to traditional deep-learning models. These models are generally trained once and then deployed, which limits their ability to adapt to the dynamic and evolving nature of healthcare scenarios. Continual learning—known for its adaptive learning capabilities over time—offers a promising solution to these challenges. However, there remains an absence of consolidated literature, which reviews the techniques, applications, and challenges of continual learning specific to physiological signal analysis, as well as its future directions. Bridging this gap, our review seeks to provide an overview of the prevailing techniques and their implications for smart healthcare. We delineate the evolution from traditional approaches to the paradigms of continual learning. We aim to offer insights into the challenges faced and outline potential paths forward. Our discussion emphasizes the need for benchmarks, adaptability, computational efficiency, and user-centric design in the development of future healthcare systems.},
DOI = {10.3390/healthcare12020155}
}

@article{ZHANG2024106087,
title = {Continual learning for cuffless blood pressure estimation},
journal = {Biomedical Signal Processing and Control},
volume = {92},
pages = {106087},
year = {2024},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.106087},
url = {https://www.sciencedirect.com/science/article/pii/S1746809424001459},
author = {Chunlin Zhang and Wenyan Wang and Xinyue Song and Yuxuan Lin and Yifan Chen and Xiaorong Ding},
keywords = {Continual learning, Cuffless blood pressure estimation, Machine learning, Dynamic learning, Concept drift},
abstract = {Despite extensive studies on cuffless continuous blood pressure (BP) estimation through machine learning models, those models are typically constrained by a one-off training strategy resulting in fixed model parameters and inadequate adaptation in response to new patterns of data. BP is a dynamic vital sign with a concept drift characteristic. With static models trained with fixed BP datasets and traditional learning (TL) technique, the estimation performance would degrade when the to-be predicted BP distributions deviate from trained ones. In this paper, we propose a novel continual learning (CL) framework for continuous BP estimation. Such framework enables deep learning models to dynamically and sequentially learn continuous BP signals even in the presence of concept drift. We validated the proposed framework through two types of CL models on the data from 3,850 samples (403.67 h) in the University of California Irvine (UCI) database, and compared with the TL model under several controlled experiments. The results showed that the CL model learns well even when different level of concept drift exists in continuous BP. Further, the BP estimation performance of the CL model equipped with 1D-CNN improved by 20.86% on average compared to that of the TL model. These findings suggest that the CL model has a great advantage over the TL model for dynamic continuous BP estimation.}
}
@misc{singh2023classincrementalcontinuallearninggeneral,
      title={Class-Incremental Continual Learning for General Purpose Healthcare Models}, 
      author={Amritpal Singh and Mustafa Burak Gurbuz and Shiva Souhith Gantha and Prahlad Jasti},
      year={2023},
      eprint={2311.04301},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2311.04301}, 
}
@inproceedings{ye2023continualselfsupervisedlearninguniversal,
  title={Continual self-supervised learning: Towards universal multi-modal medical data representation learning},
  author={Ye, Yiwen and Xie, Yutong and Zhang, Jianpeng and Chen, Ziyang and Wu, Qi and Xia, Yong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11114--11124},
  year={2024}
}
@article {Bappi2024.12.14.24319041,
	author = {Bappi, Ilias and Richter, David J. and Kolekar, Shivani Sanjay and Kim, Kyungbaek},
	title = {HCLmNet: A Unified Hybrid Continual Learning Strategy Multimodal Network for Lung Cancer Survival Prediction},
	elocation-id = {2024.12.14.24319041},
	year = {2024},
	doi = {10.1101/2024.12.14.24319041},
	publisher = {Cold Spring Harbor Laboratory Press},
	abstract = {Lung cancer survival prediction is a critical task in healthcare, where accurate and timely predictions can significantly impact patient outcomes. In hospital settings, new patient data is constantly generated, requiring predictive models to adapt without forgetting previously learned knowledge. This challenge is intensified by the need to seamlessly integrate complex multimodal data, such as imaging, DNA, and patient records. Traditional Deep Learning (DL) models, while powerful, often suffer from catastrophic forgetting during incremental learning, further complicating the task of reliable survival prediction in dynamic environments. To address these challenges, we introduce a hybrid Continual Learning (CL) framework that integrates Elastic Weight Consolidation (EWC) with replay-based modules, including EWC Experience Replay (ER), Instance-Level Correlation Replay (EICR), and Class-Level Correlation Replay (ECCR). The ER module preserves knowledge by replaying representative samples from previous data, mitigating interference from new data. The EICR module ensures the retention of fine-grained feature patterns through inter-instance relationship modeling, while the ECCR module consolidates global knowledge across tasks using random triplet probabilities to preserve inter-class correlations. Together, these components create a robust framework, addressing catastrophic forgetting while enhancing adaptability for real-time survival prediction. Another critical challenge is the limitations of Convolutional Neural Networks (CNNs), which tend to miss ground-glass opacities or tiny tumor features in CT and PET images due to their reliance on datasets similar to their pretraining data. To overcome this, we propose a Swin Transformer (SwinT)-based method to extract critical features, addressing CNN shortcomings in such multimodal scenarios. Additionally, XLNet-permutation enriches multimodal analysis by effectively handling small DNA datasets and capturing latent patterns, whereas Fully Connected Network (FCN) process clinical features. A cross-attention fusion mechanism integrates clinical, CT, PET, and DNA data, producing a robust survival prediction model. The final prediction is guided by FCN and Cox Proportional Hazards (CoxPH) techniques, achieves state-of-the-art performance with a 7.7\% concordance index (C-Index) improvement (0.84), a mean absolute error (MAE) reduction to 140 days, and minimized forgetting to 0.08. Ablation studies demonstrate the importance of the DNA modality, cross-attention mechanism, and CL strategies, advancing adaptive survival prediction and stability.Competing Interest StatementThe authors have declared no competing interest.Funding StatementThe author(s) received no specific funding for this work.Author DeclarationsI confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.YesThe details of the IRB/oversight body that provided approval or exemption for the research described are given below:N/A: We used a publicly open dataset in our research, and the dataset does not contain sensitive or private information requiring ethical approval, it is acceptable to state that no IRB (Institutional Review Board) approval is required.I confirm that all necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived, and that any patient/participant/sample identifiers included were not known to anyone (e.g., hospital staff, patients or participants themselves) outside the research group so cannot be used to identify individuals.YesI understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).YesI have followed all appropriate research reporting guidelines, such as any relevant EQUATOR Network research reporting checklist(s) and other pertinent material, if applicable.YesDataset are publicly accessed in online. Link: https://aihub.or.kr/aihubdata/data/view.do?currMenu=115\&amp;topMenu=100\&amp;dataSetSn=228 https://aihub.or.kr/aihubdata/data/view.do?currMenu=115\&amp;topMenu=100\&amp;dataSetSn=228},
	URL = {https://www.medrxiv.org/content/early/2024/12/16/2024.12.14.24319041},
	eprint = {https://www.medrxiv.org/content/early/2024/12/16/2024.12.14.24319041.full.pdf},
	journal = {medRxiv}
}

@INPROCEEDINGS{10677812Imran,
  author={Imran, Muhammad and Akram, Muhammad Usman and Salam, Anum Abdul},
  booktitle={2024 14th International Conference on Pattern Recognition Systems (ICPRS)}, 
  title={Transformer-Based Skin Carcinoma Classification using Histopathology Images via Incremental Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  keywords={Deep learning;Analytical models;Incremental learning;Image analysis;Histopathology;Biological system modeling;Transformers;Biomedical image analysis;incremental image classification;transformer;computational pathology;skin cancer},
  doi={10.1109/ICPRS62101.2024.10677812}}

@INPROCEEDINGS{10658489,
  author={Wang, Huyong and Wu, Huisi and Qin, Jing},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Incremental Nuclei Segmentation from Histopathological Images via Future-class Awareness and Compatibility-inspired Distillation}, 
  year={2024},
  volume={},
  number={},
  pages={11408-11417},
  keywords={Training;Computer vision;Codes;Computational modeling;Semantic segmentation;Software;Pattern recognition},
  doi={10.1109/CVPR52733.2024.01084}}

@inproceedings{chen2024trafficflowoptimisationlifelong,
  title={Traffic flow optimisation for lifelong multi-agent path finding},
  author={Chen, Zhe and Harabor, Daniel and Li, Jiaoyang and Stuckey, Peter J},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={18},
  pages={20674--20682},
  year={2024}
}

@inproceedings{skrynnik2023learnfollowdecentralizedlifelong,
  title={Learn to follow: Decentralized lifelong multi-agent pathfinding via planning and learning},
  author={Skrynnik, Alexey and Andreychuk, Anton and Nesterova, Maria and Yakovlev, Konstantin and Panov, Aleksandr},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17541--17549},
  year={2024}
}

@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, K},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}
@inbook{V_disch_2023,
   title={Continual SLAM: Beyond Lifelong Simultaneous Localization andMapping Through Continual Learning},
   ISBN={9783031255557},
   ISSN={2511-1264},
   url={http://dx.doi.org/10.1007/978-3-031-25555-7_3},
   DOI={10.1007/978-3-031-25555-7_3},
   booktitle={Robotics Research},
   publisher={Springer Nature Switzerland},
   author={Vödisch, Niclas and Cattaneo, Daniele and Burgard, Wolfram and Valada, Abhinav},
   year={2023},
   pages={19–35} }

@article{Karlsson_2023,
   title={Learning to Predict Navigational Patterns From Partial Observations},
   volume={8},
   ISSN={2377-3774},
   url={http://dx.doi.org/10.1109/LRA.2023.3291924},
   DOI={10.1109/lra.2023.3291924},
   number={9},
   journal={IEEE Robotics and Automation Letters},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Karlsson, Robin and Carballo, Alexander and Lepe-Salazar, Francisco and Fujii, Keisuke and Ohtani, Kento and Takeda, Kazuya},
   year={2023},
   month=sep, pages={5592–5599} }

@article{YANG2022110022,
title = {Continual learning-based trajectory prediction with memory augmented networks},
journal = {Knowledge-Based Systems},
volume = {258},
pages = {110022},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.110022},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122011157},
author = {Biao Yang and Fucheng Fan and Rongrong Ni and Jie Li and Loochu Kiong and Xiaofeng Liu},
keywords = {Trajectory prediction, Multi-hop attention, Memory augmented neural networks, Continual learning, Catastrophic forgetting},
}
@misc{hong2022bridginggaplearningdiscrete,
      title={Bridging the Gap Between Learning in Discrete and Continuous Environments for Vision-and-Language Navigation}, 
      author={Yicong Hong and Zun Wang and Qi Wu and Stephen Gould},
      year={2022},
      eprint={2203.02764},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2203.02764}, 
}
@INPROCEEDINGS{9811906Xu2022,
  author={Xu, Jie and Wang, Shihong and Chen, Xingyu and Zhang, Jiahao and Lan, Xuguang and Zheng, Nanning},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)}, 
  title={A Continuous Learning Approach for Probabilistic Human Motion Prediction}, 
  year={2022},
  volume={},
  number={},
  pages={11222-11228},
  keywords={Uncertainty;Neural networks;Human-robot interaction;Training data;Benchmark testing;Probabilistic logic;Prediction algorithms},
  doi={10.1109/ICRA46639.2022.9811906}
}
@inproceedings{aljundi2019taskfreecontinuallearning,
  title={Task-free continual learning},
  author={Aljundi, Rahaf and Kelchtermans, Klaas and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11254--11263},
  year={2019}
}
@ARTICLE{9384183Bodnar,
  author={Bodnar, Cristian and Hausman, Karol and Dulac-Arnold, Gabriel and Jonschkowski, Rico},
  journal={IEEE Robotics and Automation Letters}, 
  title={A Metric Space Perspective on Self-Supervised Policy Adaptation}, 
  year={2021},
  volume={6},
  number={3},
  pages={4329-4336},
  keywords={Training;Euclidean distance;Deep learning;Reinforcement learning;Continual learning;deep learning methods;reinforcement learning},
  doi={10.1109/LRA.2021.3068100}}

@article{SANTHAKUMAR2022167,
title = {Lifelong 3D object recognition and grasp synthesis using dual memory recurrent self-organization networks},
journal = {Neural Networks},
volume = {150},
pages = {167-180},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.02.027},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022000685},
author = {Krishnakumar Santhakumar and Hamidreza Kasaei},
keywords = {Lifelong learning, Continual learning, Dual memory recurrent self-organization, Object recognition, Grasp synthesis, Memory replay},
abstract = {Humans learn to recognize and manipulate new objects in lifelong settings without forgetting the previously gained knowledge under non-stationary and sequential conditions. In autonomous systems, the agents also need to mitigate similar behaviour to continually learn the new object categories and adapt to new environments. In most conventional deep neural networks, this is not possible due to the problem of catastrophic forgetting, where the newly gained knowledge overwrites existing representations. Furthermore, most state-of-the-art models excel either in recognizing the objects or in grasp prediction, while both tasks use visual input. The combined architecture to tackle both tasks is very limited. In this paper, we proposed a hybrid model architecture consists of a dynamically growing dual-memory recurrent neural network (GDM) and an autoencoder to tackle object recognition and grasping simultaneously. The autoencoder network is responsible to extract a compact representation for a given object, which serves as input for the GDM learning, and is responsible to predict pixel-wise antipodal grasp configurations. The GDM part is designed to recognize the object in both instances and categories levels. We address the problem of catastrophic forgetting using the intrinsic memory replay, where the episodic memory periodically replays the neural activation trajectories in the absence of external sensory information. To extensively evaluate the proposed model in a lifelong setting, we generate a synthetic dataset due to lack of sequential 3D objects dataset. Experiment results demonstrated that the proposed model can learn both object representation and grasping simultaneously in continual learning scenarios.}
}
@misc{li2022incrementalfewshotobjectdetection,
      title={Incremental Few-Shot Object Detection for Robotics}, 
      author={Yiting Li and Haiyue Zhu and Sichao Tian and Fan Feng and Jun Ma and Chek Sing Teo and Cheng Xiang and Prahlad Vadakkepat and Tong Heng Lee},
      year={2022},
      eprint={2005.02641},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2005.02641}, 
}

@article{auddy2023continuallearningdemonstrationrobotics,
  title={Continual learning from demonstration of robotics skills},
  author={Auddy, Sayantan and Hollenstein, Jakob and Saveriano, Matteo and Rodr{\'\i}guez-S{\'a}nchez, Antonio and Piater, Justus},
  journal={Robotics and Autonomous Systems},
  volume={165},
  pages={104427},
  year={2023},
  publisher={Elsevier}
}

@article{xu2020continuallearningcontrolprimitives,
  title={Continual learning of control primitives: Skill discovery via reset-games},
  author={Xu, Kelvin and Verma, Siddharth and Finn, Chelsea and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4999--5010},
  year={2020}
}

@article{qureshi2020motionplanningnetworksbridging,
  title={Motion planning networks: Bridging the gap between learning-based and classical motion planners},
  author={Qureshi, Ahmed Hussain and Miao, Yinglong and Simeonov, Anthony and Yip, Michael C},
  journal={IEEE Transactions on Robotics},
  volume={37},
  number={1},
  pages={48--66},
  year={2020},
  publisher={IEEE}
}
@INPROCEEDINGS{10611053,
  author={Uhlmann, Eckart and Polte, Mitchel and Blumberg, Julian and Yin, Sheng and Wang, Gang},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Increasing the Absolute Position Accuracy of Industrial Robots by Means of a Deep Continual Evidential Regression Model *}, 
  year={2024},
  volume={},
  number={},
  pages={4774-4780},
  keywords={Training;Continuing education;Productivity;Accuracy;Uncertainty;Service robots;Kinematics},
  doi={10.1109/ICRA57147.2024.10611053}}
@article{bahadir2024continual,
  title={Continual learning approaches to hand–eye calibration in robots},
  author={Bahadir, O. and Siebert, J.P. and Aragon-Camarasa, G.},
  journal={Machine Vision and Applications},
  volume={35},
  number={97},
  year={2024},
  doi={10.1007/s00138-024-01572-w},
  note={Received: 28 January 2024; Revised: 10 June 2024; Accepted: 21 June 2024; Published: 10 July 2024}
}
@article{madi2024new,
  title={A new hybrid incremental learning system for an enhanced KNN algorithm (hoKNN)},
  author={Madi, S. and Baba-Ali, A.R.},
  journal={Evolving Systems},
  volume={15},
  pages={1001--1019},
  year={2024},
  doi={10.1007/s12530-023-09531-y},
  note={Received: 23 November 2022; Accepted: 21 July 2023; Published: 06 August 2023; Issue Date: June 2024}
}
@ARTICLE{9730039Pique,
  author={Piqué, Francesco and Kalidindi, Hari Teja and Fruzzetti, Lorenzo and Laschi, Cecilia and Menciassi, Arianna and Falotico, Egidio},
  journal={IEEE Robotics and Automation Letters}, 
  title={Controlling Soft Robotic Arms Using Continual Learning}, 
  year={2022},
  volume={7},
  number={2},
  pages={5469-5476},
  keywords={Soft robotics;Robots;Task analysis;Mathematical models;Computational modeling;Loading;Training;Modeling;control;and learning for soft robots;learning and adaptive systems;soft robot applications},
  doi={10.1109/LRA.2022.3157369}}

@article{li2021sler,
  title={SLER: Self-generated long-term experience replay for continual reinforcement learning},
  author={Li, C. and Li, Y. and Zhao, Y. and et al.},
  journal={Appl Intell},
  volume={51},
  pages={185--201},
  year={2021},
  doi={10.1007/s10489-020-01786-1},
  note={Published: 07 August 2020; Issue Date: January 2021}
}
@inproceedings{hayes2019memoryefficientexperiencereplay,
  title={Memory efficient experience replay for streaming learning},
  author={Hayes, Tyler L and Cahill, Nathan D and Kanan, Christopher},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={9769--9776},
  year={2019},
  organization={IEEE}
}
@inproceedings{huang2021continualmodelbasedreinforcementlearning,
  title={Continual model-based reinforcement learning with hypernetworks},
  author={Huang, Yizhou and Xie, Kevin and Bharadhwaj, Homanga and Shkurti, Florian},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={799--805},
  year={2021},
  organization={IEEE}
}

@article{mendez2020lifelongpolicygradientlearning,
  title={Lifelong policy gradient learning of factored policies for faster training without forgetting},
  author={Mendez, Jorge and Wang, Boyu and Eaton, Eric},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14398--14409},
  year={2020}
}
@ARTICLE{10737442DongandZeng,
  author={Dong, Qingwei and Zeng, Peng and He, Yunpeng and Wan, Guangxi and Dong, Xiaoting},
  journal={IEEE Robotics and Automation Letters}, 
  title={Mitigating Catastrophic Forgetting in Robot Continual Learning: A Guided Policy Search Approach Enhanced With Memory-Aware Synapses}, 
  year={2024},
  volume={9},
  number={12},
  pages={11242-11249},
  keywords={Continuing education;Reinforcement learning;Training;Trajectory;Neural networks;Global Positioning System;Heuristic algorithms;Computational modeling;Synapses;Deep reinforcement learning;Continuing education;Multitasking;Deep reinforcement learning;continual learning;sequential multitask learning;catastrophic forgetting},
  doi={10.1109/LRA.2024.3487484}}

@article{GANIE2024128139,
title = {Lifelong reinforcement learning tracking control of nonlinear strict-feedback systems using multilayer neural networks with constraints},
journal = {Neurocomputing},
volume = {600},
pages = {128139},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128139},
url = {https://www.sciencedirect.com/science/article/pii/S092523122400910X},
author = {Irfan Ganie and S. Jagannathan},
keywords = {Optimal control, Strict-feedback, Neural networks, Lifelong learning, Barrier constraints},
abstract = {This paper presents a novel safe integral reinforcement learning (IRL)-based optimal trajectory tracking scheme for nonlinear systems with uncertain dynamics that is subject to constraints. We leverage multilayer neural networks (MNNs) for actor-critic MNNs along with an NN identifier in the backstepping process for minimizing a discounted value function. A time-varying barrier Lyapunov function (TVBLF) is utilized for handling constraints and to provide safety assurances. Online weight update laws for the actor and critic MNNs are derived that are driven by Bellman error and control input error. We introduce an online lifelong learning (LL) method in the critic NN, utilizing the Bellman error in MNNs to address catastrophic forgetting. The method’s effectiveness is demonstrated through simulations on mobile robot multitask tracking. The paper concludes with a stability analysis of the closed-loop system.}
}
@article{xiong2021state,
  title={State Primitive Learning to Overcome Catastrophic Forgetting in Robotics},
  author={Xiong, F. and Liu, Z. and Huang, K. and et al.},
  journal={Cogn Comput},
  volume={13},
  pages={394--402},
  year={2021},
  doi={10.1007/s12559-020-09784-8},
  note={Received: 09 January 2020; Accepted: 20 October 2020; Published: 09 November 2020; Issue Date: March 2021}
}
@INPROCEEDINGS{9265509,
  author={Szadkowski, Rudolf and Prágr, Miloš and Faigl, Jan},
  booktitle={2020 4th International Conference on Automation, Control and Robots (ICACR)}, 
  title={Transfer of Inter-Robotic Inductive Classifier}, 
  year={2020},
  volume={},
  number={},
  pages={32-36},
  keywords={Robots;Task analysis;Robot sensing systems;Classification algorithms;Legged locomotion;Indexes;Testing;component;multi-robotics;incremental learning;inductive transfer learning;classification},
  doi={10.1109/ICACR51161.2020.9265509}
}
@article{daruna2021continuallearningknowledgegraph,
  title={Continual learning of knowledge graph embeddings},
  author={Daruna, Angel and Gupta, Mehul and Sridharan, Mohan and Chernova, Sonia},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={2},
  pages={1128--1135},
  year={2021},
  publisher={IEEE}
}
@INPROCEEDINGS{9981671,
  author={Belgiovine, Giulia and Gonzlez-Billandon, Jonas and Sciutti, Alessandra and Sandini, Giulio and Rea, Francesco},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={HRI Framework for Continual Learning in Face Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={8226-8233},
  keywords={Databases;Face recognition;Transfer learning;Social robots;Buildings;Robot sensing systems;Data models},
  doi={10.1109/IROS47612.2022.9981671}}


@INPROCEEDINGS{9812108Haj,
  author={Hussein, Mohammad Haj and Ibrahim, Batool and Elhajj, Imad H. and Asmar, Daniel},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)}, 
  title={Incremental Learning for Enhanced Personalization of Autocomplete Teleoperation}, 
  year={2022},
  volume={},
  number={},
  pages={515-521},
  keywords={Representation learning;Deep learning;Adaptation models;Automation;System performance;Transfer learning;User experience},
  doi={10.1109/ICRA46639.2022.9812108}}
@INPROCEEDINGS{10355028Oztop,
  author={Say, Hanne and Oztop, Erhan},
  booktitle={2023 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, 
  title={A Model for Cognitively Valid Lifelong Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  keywords={Training;Computational modeling;Computer architecture;Switches;Multitasking;Robot learning;Task analysis},
  doi={10.1109/ROBIO58561.2023.10355028}}

@INPROCEEDINGS{9423189Kishida,
  author={Kishida, Ikki and Chen, Hong and Baba, Masaki and Jin, Jiren and Amma, Ayako and Nakayama, Hideki},
  booktitle={2021 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Object Recognition with Continual Open Set Domain Adaptation for Home Robot}, 
  year={2021},
  volume={},
  number={},
  pages={1516-1525},
  keywords={Training;Learning systems;Computer vision;Conferences;Object detection;Detectors;Search problems},
  doi={10.1109/WACV48630.2021.00156}
}
@article{kay2017kinetics,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}
@inproceedings{zhao_when_2021,
	location = {New York, {NY}, {USA}},
	title = {When Video Classification Meets Incremental Classes},
	isbn = {978-1-4503-8651-7},
	url = {https://doi.org/10.1145/3474085.3475265},
	doi = {10.1145/3474085.3475265},
	series = {{MM} '21},
	pages = {880--889},
	booktitle = {Proceedings of the 29th {ACM} International Conference on Multimedia},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Hanbin and Qin, Xin and Su, Shihao and Fu, Yongjian and Lin, Zibo and Li, Xi},
	urldate = {2025-01-29},
	date = {2021-10-17},
    year = {2021},
}
@inproceedings{kuehne2011hmdb,
  title={HMDB: a large video database for human motion recognition},
  booktitle={2011 International conference on computer vision},
  pages={2556--2563},
  year={2011},
  organization={IEEE}
}
@article{liu2017pku,
  title={Pku-mmd: A large scale benchmark for continuous multi-modal human action understanding},
  author={Liu, Chunhui and Hu, Yueyu and Li, Yanghao and Song, Sijie and Liu, Jiaying},
  journal={arXiv preprint arXiv:1703.07475},
  year={2017}
}
@inproceedings{shahroudy2016ntu,
  title={Ntu rgb+ d: A large scale dataset for 3d human activity analysis},
  author={Shahroudy, Amir and Liu, Jun and Ng, Tian-Tsong and Wang, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1010--1019},
  year={2016}
}
@inproceedings{goyal2017something,
  title={The" something something" video database for learning and evaluating visual common sense},
  author={Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzynska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz and others},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5842--5850},
  year={2017}
}
@inproceedings{caba2015activitynet,
  title={Activitynet: A large-scale video benchmark for human activity understanding},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle={Proceedings of the ieee conference on computer vision and pattern recognition},
  pages={961--970},
  year={2015}
}
@article{damen2020epic,
  title={The epic-kitchens dataset: Collection, challenges and baselines},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Fidler, Sanja and Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={43},
  number={11},
  pages={4125--4141},
  year={2020},
  publisher={IEEE}
}
@article{xu2023towards,
  title={Towards continual egocentric activity recognition: A multi-modal egocentric activity dataset for continual learning},
  author={Xu, Linfeng and Wu, Qingbo and Pan, Lili and Meng, Fanman and Li, Hongliang and He, Chiyuan and Wang, Hanxin and Cheng, Shaoxu and Dai, Yu},
  journal={IEEE Transactions on Multimedia},
  year={2023},
  publisher={IEEE}
}

@article{Gonzalez2023Lifelong,
  author    = {González, C. and Ranem, A. and Pinto dos Santos, D. and others},
  title     = {Lifelong nnU-Net: a framework for standardized medical continual learning},
  journal   = {Scientific Reports},
  volume    = {13},
  pages     = {9381},
  year      = {2023},
  doi       = {10.1038/s41598-023-34484-2},
  url       = {https://doi.org/10.1038/s41598-023-34484-2}
}


@inproceedings{ref1,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={652--660},
  year={2017}
}

@article{ref2,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{ref3,
  title={Voxnet: A 3d convolutional neural network for real-time object recognition},
  author={Maturana, Daniel and Scherer, Sebastian},
  booktitle={2015 IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  pages={922--928},
  year={2015},
  organization={IEEE}
}


@article{ref4,
  title={Self-supervised deep learning on point clouds by reconstructing space},
  author={Sauder, Jonathan and Sievers, Bjarne},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}





@inproceedings{ref5,
  title={Pointcontrast: Unsupervised pre-training for 3d point cloud understanding},
  author={Xie, Saining and Gu, Jiatao and Guo, Demi and Qi, Charles R and Guibas, Leonidas and Litany, Or},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part III 16},
  pages={574--591},
  year={2020},
  organization={Springer}
}

@inproceedings{ref6,
  title={Unsupervised 3D object recognition and reconstruction in unordered datasets},
  author={Brown, Matthew and Lowe, David G},
  booktitle={Fifth International Conference on 3-D Digital Imaging and Modeling (3DIM'05)},
  pages={56--63},
  year={2005},
  organization={IEEE}
}


@inproceedings{ref7,
  title={Robust 3d object detection from lidar-radar point clouds via cross-modal feature augmentation},
  author={Deng, Jianning and Chan, Gabriel and Zhong, Hantao and Lu, Chris Xiaoxuan},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6585--6591},
  year={2024},
  organization={IEEE}
}


@inproceedings{ref8,
  title={Learning without forgetting for 3d point cloud objects},
  author={Chowdhury, Townim and Jalisha, Mahira and Cheraghian, Ali and Rahman, Shafin},
  booktitle={Advances in Computational Intelligence: 16th International Work-Conference on Artificial Neural Networks, IWANN 2021, Virtual Event, June 16--18, 2021, Proceedings, Part I 16},
  pages={484--497},
  year={2021},
  organization={Springer}
}


@inproceedings{ref9,
  title={I3dol: Incremental 3d object learning without catastrophic forgetting},
  author={Dong, Jiahua and Cong, Yang and Sun, Gan and Ma, Bingtao and Wang, Lichen},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={7},
  pages={6066--6074},
  year={2021}
}


@article{ref10,
  title={Continual learning on 3D point clouds with random compressed rehearsal},
  author={Zamorski, Maciej and Stypu{\l}kowski, Micha{\l} and Karanowski, Konrad and Trzci{\'n}ski, Tomasz and Zi{\k{e}}ba, Maciej},
  journal={Computer Vision and Image Understanding},
  volume={228},
  pages={103621},
  year={2023},
  publisher={Elsevier}
}


@inproceedings{ref11,
  title={Few-shot class-incremental Simultaneous objects},
  author={Chowdhury, Townim and Cheraghian, Ali and Ramasinghe, Sameera and Ahmadi, Sahar and Saberi, Morteza and Rahman, Shafin},
  booktitle={European Conference on Computer Vision},
  pages={204--220},
  year={2022},
  organization={Springer}
}


@inproceedings{ref12,
  title={Incremental object learning from contiguous views},
  author={Stojanov, Stefan and Mishra, Samarth and Thai, Ngoc Anh and Dhanda, Nikhil and Humayun, Ahmad and Yu, Chen and Smith, Linda B and Rehg, James M},
  booktitle={Proceedings of the ieee/cvf conference on computer vision and pattern recognition},
  pages={8777--8786},
  year={2019}
}


@article{kasaei2022simultaneousmultiviewobjectrecognition,
  title={Simultaneous multi-view object recognition and grasping in open-ended domains},
  author={Kasaei, Hamidreza and Kasaei, Mohammadreza and Tziafas, Georgios and Luo, Sha and Sasso, Remo},
  journal={Journal of Intelligent \& Robotic Systems},
  volume={110},
  number={2},
  pages={1--19},
  year={2024},
  publisher={Springer}
}

@article{ref14,
  title={L3DOC: Lifelong 3D object classification},
  author={Liu, Yuyang and Cong, Yang and Sun, Gan and Zhang, Tao and Dong, Jiahua and Liu, Hongsen},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={7486--7498},
  year={2021},
  publisher={IEEE}
}

@inproceedings{ref15,
  title={ReFu: Recursive Fusion for Exemplar-Free 3D Class-Incremental Learning},
  author={Yang, Yi and Zhong, Lei and Zhuang, Huiping},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages={3396--3405},
  year={2025},
  organization={IEEE}
}

@article{ref16,
  title={Orthographicnet: A deep transfer learning approach for 3-d object recognition in open-ended domains},
  author={Kasaei, S Hamidreza},
  journal={IEEE/ASME Transactions on Mechatronics},
  volume={26},
  number={6},
  pages={2910--2921},
  year={2020},
  publisher={IEEE}
}

@article{ref17,
  title={Lifelong ensemble learning based on multiple representations for few-shot object recognition},
  author={Kasaei, Hamidreza and Xiong, Songsong},
  journal={Robotics and Autonomous Systems},
  volume={174},
  pages={104615},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{ref18,
  title={Novel class discovery for 3d point cloud semantic segmentation},
  author={Riz, Luigi and Saltori, Cristiano and Ricci, Elisa and Poiesi, Fabio},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9393--9402},
  year={2023}
}

@inproceedings{ref19,
  title={Multi-modal continual test-time adaptation for 3d semantic segmentation},
  author={Cao, Haozhi and Xu, Yuecong and Yang, Jianfei and Yin, Pengyu and Yuan, Shenghai and Xie, Lihua},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={18809--18819},
  year={2023}
}




@inproceedings{ref20,
  title={Geometry and uncertainty-aware 3d point cloud class-incremental semantic segmentation},
  author={Yang, Yuwei and Hayat, Munawar and Jin, Zhao and Ren, Chao and Lei, Yinjie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21759--21768},
  year={2023}
}


@article{ref21,
  title={Cross-Domain Incremental Feature Learning for ALS Point Cloud Semantic Segmentation with Few Samples},
  author={Dai, Mofan and Xing, Shuai and Xu, Qing and Li, Pengcheng and Pan, Jiechen and Wang, Hanyun},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

@inproceedings{ref22,
  title={A Probability-Driven Framework for Open World 3D Point Cloud Semantic Segmentation},
  author={Xu, Jinfeng and Yang, Siyuan and Li, Xianzhi and Tang, Yuan and Hao, Yixue and Hu, Long and Chen, Min},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5977--5986},
  year={2024}
}


@inproceedings{ref23,
  title={Label-guided knowledge distillation for continual semantic segmentation on 2d images and 3d point clouds},
  author={Yang, Ze and Li, Ruibo and Ling, Evan and Zhang, Chi and Wang, Yiming and Huang, Dezhao and Ma, Keng Teck and Hur, Minhoe and Lin, Guosheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={18601--18612},
  year={2023}
}

@inproceedings{ref24,
  title={Continual Learning and Unknown Object Discovery in 3D Scenes via Self-distillation},
  author={Boudjoghra, Mohamed El Amine and Lahoud, Jean and Cholakkal, Hisham and Anwer, Rao Muhammad and Khan, Salman and Khan, Fahad Shahbaz},
  booktitle={European Conference on Computer Vision},
  pages={416--431},
  year={2024},
  organization={Springer}
}


@inproceedings{ref25,
  title={Conflicts between likelihood and knowledge distillation in task incremental learning for 3d object detection},
  author={Yun, Peng and Cen, Jun and Liu, Ming},
  booktitle={2021 International Conference on 3D Vision (3DV)},
  pages={575--585},
  year={2021},
  organization={IEEE}
}


@inproceedings{ref26,
  title={Static-dynamic co-teaching for class-incremental 3d object detection},
  author={Zhao, Na and Lee, Gim Hee},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={3},
  pages={3436--3445},
  year={2022}
}

@inproceedings{ref27,
  author       = {Ziyuan Zhao, Mingxi Xu, Peisheng Qian, Ramanpreet Singh Pahwa, Richard Chang},
  title        = {{DA-CIL:} Towards Domain Adaptive Class-Incremental 3D Object Detection},
  booktitle    = {{BMVC}},
  pages        = {916},
  publisher    = {{BMVA} Press},
  year         = {2022}
}

@inproceedings{ref28,
  title={COCO-TEACH: A Contrastive Co-Teaching Network For Incremental 3D Object Detection},
  author={Cheng, Zhongyao and Chen, Cen and Zhao, Ziyuan and Qian, Peisheng and Li, Xiaoli and Yang, Xulei},
  booktitle={2023 IEEE International Conference on Image Processing (ICIP)},
  pages={1990--1994},
  year={2023},
  organization={IEEE}
}



@article{ref29,
  title={Diversity Knowledge Distillation for LiDAR-Based 3-D Object Detection},
  author={Ning, Kanglin and Liu, Yanfei and Su, Yanzhao and Jiang, Ke},
  journal={IEEE Sensors Journal},
  volume={23},
  number={11},
  pages={11181--11193},
  year={2023},
  publisher={IEEE}
}



@inproceedings{ref30,
  title={Continual neural mapping: Learning an implicit scene representation from sequential observations},
  author={Yan, Zike and Tian, Yuxin and Shi, Xuesong and Guo, Ping and Wang, Peng and Zha, Hongbin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15782--15792},
  year={2021}
}



@inproceedings{ref31,
  title={imap: Implicit mapping and positioning in real-time},
  author={Sucar, Edgar and Liu, Shikun and Ortiz, Joseph and Davison, Andrew J},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6229--6238},
  year={2021}
}


@inproceedings{ref32,
  title={Unsupervised continual semantic adaptation through neural rendering},
  author={Liu, Zhizheng and Milano, Francesco and Frey, Jonas and Siegwart, Roland and Blum, Hermann and Cadena, Cesar},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3031--3040},
  year={2023}
}



@inproceedings{ref33,
  title={Structure-from-sherds: Incremental 3d reassembly of axially symmetric pots from unordered and mixed fragment collections},
  author={Hong, Je Hyeong and Yoo, Seong Jong and Zeeshan, Muhammad Arshad and Kim, Young Min and Kim, Jinwook},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5443--5451},
  year={2021}
}



@article{ref34,
  title={Building a scalable and interpretable Bayesian deep learning framework for quality control of free form surfaces},
  author={Sinha, Sumit and Franciosa, Pasquale and Ceglarek, Dariusz},
  journal={IEEE Access},
  volume={9},
  pages={50188--50208},
  year={2021},
  publisher={IEEE}
}


@inproceedings{ref35,
  title={Continual reinforcement learning in 3d non-stationary environments},
  author={Lomonaco, Vincenzo and Desai, Karan and Culurciello, Eugenio and Maltoni, Davide},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={248--249},
  year={2020}
}


@inproceedings{ref36,
  title={Continual learning for image-based camera localization},
  author={Wang, Shuzhe and Laskar, Zakaria and Melekhov, Iaroslav and Li, Xiaotian and Kannala, Juho},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3252--3262},
  year={2021}
}


@article{ref37,
  title={Learning to predict navigational patterns from partial observations},
  author={Karlsson, Robin and Carballo, Alexander and Lepe-Salazar, Francisco and Fujii, Keisuke and Ohtani, Kento and Takeda, Kazuya},
  journal={IEEE Robotics and Automation Letters},
  year={2023},
  publisher={IEEE}
}



@article{ref38,
  title={Temporal continual learning with prior compensation for human motion prediction},
  author={Tang, Jianwei and Sun, Jiangxin and Lin, Xiaotong and Zheng, Wei-Shi and Hu, Jian-Fang and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@inproceedings{ref39,
  title={POET: Prompt Offset Tuning for Continual Human Action Adaptation},
  author={Garg, Prachi and Joseph, KJ and Balasubramanian, Vineeth N and Camgoz, Necati Cihan and Wan, Chengde and Kin, Kenrick and Si, Weiguang and Ma, Shugao and De La Torre, Fernando},
  booktitle={European Conference on Computer Vision},
  pages={436--455},
  year={2024},
  organization={Springer}
}



@inproceedings{ref40,
  title={SplaTAM: Splat Track \& Map 3D Gaussians for Dense RGB-D SLAM},
  author={Keetha, Nikhil and Karhade, Jay and Jatavallabhula, Krishna Murthy and Yang, Gengshan and Scherer, Sebastian and Ramanan, Deva and Luiten, Jonathon},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21357--21366},
  year={2024}
}


@article{ref41,
  title={Residual learning with annularly convolutional neural networks for classification and segmentation of 3D point clouds},
  author={Hassan, Rabbia and Fraz, MM and Rajput, A and Shahzad, Muhammad},
  journal={Neurocomputing},
  volume={526},
  pages={96--108},
  year={2023},
  publisher={Elsevier}
}


@article{ref42,
  title={Deep unsupervised learning for 3d als point clouds change detection},
  author={de G{\'e}lis, Iris and Saha, Sudipan and Shahzad, Muhammad and Corpetti, Thomas and Lef{\`e}vre, S{\'e}bastien and Zhu, Xiao Xiang},
  journal={ISPRS Open Journal of Photogrammetry and Remote Sensing},
  volume={9},
  pages={100044},
  year={2023},
  publisher={Elsevier}
}


@inproceedings{ref43,
  title={Pointclustering: Unsupervised point cloud pre-training using transformation invariance in clustering},
  author={Long, Fuchen and Yao, Ting and Qiu, Zhaofan and Li, Lusong and Mei, Tao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21824--21834},
  year={2023}
}


@inproceedings{ref44,
  title={Masked autoencoder for self-supervised pre-training on lidar point clouds},
  author={Hess, Georg and Jaxing, Johan and Svensson, Elias and Hagerman, David and Petersson, Christoffer and Svensson, Lennart},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={350--359},
  year={2023}
}


@article{ref45,
  title={Pointgpt: Auto-regressively generative pre-training from point clouds},
  author={Chen, Guangyan and Wang, Meiling and Yang, Yi and Yu, Kai and Yuan, Li and Yue, Yufeng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}



@inproceedings{ref46,
  title={A-cnn: Annularly convolutional neural networks on point clouds},
  author={Komarichev, Artem and Zhong, Zichun and Hua, Jing},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7421--7430},
  year={2019}
}





@inproceedings{ref47,
  title={Pointwise convolutional neural networks},
  author={Hua, Binh-Son and Tran, Minh-Khoi and Yeung, Sai-Kit},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={984--993},
  year={2018}
}


@inproceedings{ref48,
  title={Kpconv: Flexible and deformable convolution for point clouds},
  author={Thomas, Hugues and Qi, Charles R and Deschaud, Jean-Emmanuel and Marcotegui, Beatriz and Goulette, Fran{\c{c}}ois and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6411--6420},
  year={2019}
}

@article{ref49,
  title={A unifying bayesian view of continual learning},
  author={Farquhar, Sebastian and Gal, Yarin},
  journal={arXiv preprint arXiv:1902.06494},
  year={2019}
}

@article{ref50,
  title={When meta-learning meets online and continual learning: A survey},
  author={Son, Jaehyeon and Lee, Soochan and Kim, Gunhee},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}
@inproceedings{ref51,
  title={Packnet: Adding multiple tasks to a single network by iterative pruning},
  author={Mallya, Arun and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={7765--7773},
  year={2018}
}


@inproceedings{ref52,
  title={Overcoming catastrophic forgetting with hard attention to the task},
  author={Serra, Joan and Suris, Didac and Miron, Marius and Karatzoglou, Alexandros},
  booktitle={International conference on machine learning},
  pages={4548--4557},
  year={2018},
  organization={PMLR}
}



@inproceedings{ref53,
  title={Piggyback: Adapting a single network to multiple tasks by learning to mask weights},
  author={Mallya, Arun and Davis, Dillon and Lazebnik, Svetlana},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={67--82},
  year={2018}
}






@article{ref54,
  title={Pathnet: Evolution channels gradient descent in super neural networks},
  author={Fernando, Chrisantha and Banarse, Dylan and Blundell, Charles and Zwols, Yori and Ha, David and Rusu, Andrei A and Pritzel, Alexander and Wierstra, Daan},
  journal={arXiv preprint arXiv:1701.08734},
  year={2017}
}


@inproceedings{ref55,
  title={Representation compensation networks for continual semantic segmentation},
  author={Zhang, Chang-Bin and Xiao, Jia-Wen and Liu, Xialei and Chen, Ying-Cong and Cheng, Ming-Ming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7053--7064},
  year={2022}
}



@article{ref56,
  title={Decomposed knowledge distillation for class-incremental semantic segmentation},
  author={Baek, Donghyeon and Oh, Youngmin and Lee, Sanghoon and Lee, Junghyup and Ham, Bumsub},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={10380--10392},
  year={2022}
}

@article{ref57,
  title={A neural dirichlet process mixture model for task-free continual learning},
  author={Lee, Soochan and Ha, Junsoo and Zhang, Dongsu and Kim, Gunhee},
  journal={arXiv preprint arXiv:2001.00689},
  year={2020}
}


@inproceedings{ref58,
  title={Expert gate: Lifelong learning with a network of experts},
  author={Aljundi, Rahaf and Chakravarty, Punarjay and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3366--3375},
  year={2017}
}


@article{ref59,
  title={Progressive neural networks},
  author={Rusu, Andrei A and Rabinowitz, Neil C and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1606.04671},
  year={2016}
}



@article{ref60,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2935--2947},
  year={2017},
  publisher={IEEE}
}


@article{ref61,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Academy of Sciences}
}



@inproceedings{ref62,
  title={Continual learning through synaptic intelligence},
  author={Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={3987--3995},
  year={2017},
  organization={PMLR}
}



@inproceedings{ref63,
  title={Memory aware synapses: Learning what (not) to forget},
  author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={139--154},
  year={2018}
}




@article{ref64,
  title={Variational continual learning},
  author={Nguyen, Cuong V and Li, Yingzhen and Bui, Thang D and Turner, Richard E},
  journal={arXiv preprint arXiv:1710.10628},
  year={2017}
}








@article{ref65,
  title={Three scenarios for continual learning},
  author={Van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv preprint arXiv:1904.07734},
  year={2019}
}



@inproceedings{ref66,
  title={3d shapenets: A deep representation for volumetric shapes},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1912--1920},
  year={2015}
}


@article{ref66,
  title={Shapenet: An information-rich 3d model repository},
  author={Chang, Angel X and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and others},
  journal={arXiv preprint arXiv:1512.03012},
  year={2015}
}

@inproceedings{ref67,
  title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5828--5839},
  year={2017}
}



@inproceedings{ref68,
  title={3d semantic parsing of large-scale indoor spaces},
  author={Armeni, Iro and Sener, Ozan and Zamir, Amir R and Jiang, Helen and Brilakis, Ioannis and Fischer, Martin and Savarese, Silvio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1534--1543},
  year={2016}
}

@inproceedings{ref69,
  title={A benchmark for RGB-D visual odometry, 3D reconstruction and SLAM},
  author={Handa, Ankur and Whelan, Thomas and McDonald, John and Davison, Andrew J},
  booktitle={2014 IEEE international conference on Robotics and automation (ICRA)},
  pages={1524--1531},
  year={2014},
  organization={IEEE}
}



@inproceedings{ref70,
  title={A benchmark for the evaluation of RGB-D SLAM systems},
  author={Sturm, J{\"u}rgen and Engelhard, Nikolas and Endres, Felix and Burgard, Wolfram and Cremers, Daniel},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={573--580},
  year={2012},
  organization={IEEE}
}


@article{ref71,
  title={Towards 3D LiDAR-based semantic scene understanding of 3D point cloud sequences: The SemanticKITTI Dataset},
  author={Behley, Jens and Garbade, Martin and Milioto, Andres and Quenzel, Jan and Behnke, Sven and Gall, J{\"u}rgen and Stachniss, Cyrill},
  journal={The International Journal of Robotics Research},
  volume={40},
  number={8-9},
  pages={959--967},
  year={2021},
  publisher={SAGE Publications Sage UK: London, England}
}



@inproceedings{ref72,
  title={Semanticposs: A point cloud dataset with large quantity of dynamic instances},
  author={Pan, Yancheng and Gao, Biao and Mei, Jilin and Geng, Sibo and Li, Chengkun and Zhao, Huijing},
  booktitle={2020 IEEE intelligent vehicles symposium (IV)},
  pages={687--693},
  year={2020},
  organization={IEEE}
}



@inproceedings{ref73,
  title={Scalability in perception for autonomous driving: Waymo open dataset},
  author={Sun, Pei and Kretzschmar, Henrik and Dotiwalla, Xerxes and Chouard, Aurelien and Patnaik, Vijaysai and Tsui, Paul and Guo, James and Zhou, Yin and Chai, Yuning and Caine, Benjamin and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2446--2454},
  year={2020}
}




@inproceedings{ref74,
  title={DALES: A large-scale aerial LiDAR data set for semantic segmentation},
  author={Varney, Nina and Asari, Vijayan K and Graehling, Quinn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={186--187},
  year={2020}
}

@inproceedings{ref75,
  title={Towards semantic segmentation of urban-scale 3D point clouds: A dataset, benchmarks and challenges},
  author={Hu, Qingyong and Yang, Bo and Khalid, Sheikh and Xiao, Wen and Trigoni, Niki and Markham, Andrew},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4977--4987},
  year={2021}
}

@article{ref76,
  title={The ISPRS benchmark on urban object classification and 3D building reconstruction},
  author={Rottensteiner, Franz and Sohn, Gunho and Jung, Jaewook and Gerke, Markus and Baillard, Caroline and Benitez, Sebastien and Breitkopf, Uwe},
  journal={ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences; I-3},
  volume={1},
  number={1},
  pages={293--298},
  year={2012},
  publisher={G{\"o}ttingen: Copernicus GmbH}
}


@article{ref77,
  title={The Hessigheim 3D (H3D) benchmark on semantic segmentation of high-resolution 3D point clouds and textured meshes from UAV LiDAR and Multi-View-Stereo},
  author={K{\"o}lle, Michael and Laupheimer, Dominik and Schmohl, Stefan and Haala, Norbert and Rottensteiner, Franz and Wegner, Jan Dirk and Ledoux, Hugo},
  journal={ISPRS Open Journal of Photogrammetry and Remote Sensing},
  volume={1},
  pages={100001},
  year={2021},
  publisher={Elsevier}
}





@inproceedings{ref78,
  title={Scene coordinate regression forests for camera relocalization in RGB-D images},
  author={Shotton, Jamie and Glocker, Ben and Zach, Christopher and Izadi, Shahram and Criminisi, Antonio and Fitzgibbon, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2930--2937},
  year={2013}
}





@inproceedings{ref79,
  title={Learning to navigate the energy landscape},
  author={Valentin, Julien and Dai, Angela and Nie{\ss}ner, Matthias and Kohli, Pushmeet and Torr, Philip and Izadi, Shahram and Keskin, Cem},
  booktitle={2016 Fourth International Conference on 3D Vision (3DV)},
  pages={323--332},
  year={2016},
  organization={IEEE}
}



@inproceedings{ref80,
  title={nuscenes: A multimodal dataset for autonomous driving},
  author={Caesar, Holger and Bankiti, Varun and Lang, Alex H and Vora, Sourabh and Liong, Venice Erin and Xu, Qiang and Krishnan, Anush and Pan, Yu and Baldan, Giancarlo and Beijbom, Oscar},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11621--11631},
  year={2020}
}

@article{liu2024semi,
  author    = {Liu, B. and Yao, D. and Yang, R. and others},
  title     = {Semi-Supervised Online Continual Learning for 3D Object Detection in Mobile Robotics},
  journal   = {Journal of Intelligent \& Robotic Systems},
  volume    = {110},
  pages     = {153},
  year      = {2024},
  doi       = {10.1007/s10846-024-02178-0}
}
@article{nenakhov2023continuous,
  author    = {Nenakhov, Ivan and Mazhitov, Ruslan and Artemov, Kirill and Semochkin, Aleksandr and Kolyubin, Sergey},
  title     = {Continuous Learning with Random Memory for Object Detection in Robotic Applications},
  journal   = {Robotics and Autonomous Systems},
  year      = {2023}
}

@article{Geiger2013IJRR,
  author = {Andreas Geiger and Philip Lenz and Christoph Stiller and Raquel Urtasun},
  title = {Vision meets Robotics: The KITTI Dataset},
  journal = {International Journal of Robotics Research (IJRR)},
  year = {2013}
}
@inproceedings{lomonaco2017core50,
  author    = {Lomonaco, Vincenzo and Maltoni, Davide},
  title     = {{CORe50: A New Dataset and Benchmark for Continual Object Recognition}},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  series    = {PMLR},
  volume    = {78},
  pages     = {17--26},
  year      = {2017}
}

@inproceedings{caesar2020nuscenes,
  author    = {Caesar, Holger and Bankiti, Varun and Lang, Alex H. and Vora, Sourabh and Liong, Venice Erin and Xu, Qiang and Krishnan, Anush and Pan, Yu and Baldan, Giancarlo and Beijbom, Oscar},
  title     = {nuScenes: A Multimodal Dataset for Autonomous Driving},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2020}
}

@ARTICLE{6682899,
  author={Ionescu, Catalin and Papava, Dragos and Olaru, Vlad and Sminchisescu, Cristian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments}, 
  year={2014},
  volume={36},
  number={7},
  pages={1325-1339},
  keywords={Three-dimensional displays;Sensors;Training;Cameras;Joints;Solid modeling;Estimation;Modeling and recovery of physical attributes;Motion;3D human pose estimation;human motion capture data;articulated body modeling;optimization;large-scale learning;structured prediction;Fourier kernel approximations},
  doi={10.1109/TPAMI.2013.248}}

@INPROCEEDINGS{5459260,
  author={Pellegrini, S. and Ess, A. and Schindler, K. and van Gool, L.},
  booktitle={2009 IEEE 12th International Conference on Computer Vision}, 
  title={You'll never walk alone: Modeling social behavior for multi-target tracking}, 
  year={2009},
  volume={},
  number={},
  pages={261-268},
  keywords={Predictive models;Vehicle dynamics;Layout;Humans;Computer vision;Trajectory;Cameras;Legged locomotion;Path planning;Computer science},
  doi={10.1109/ICCV.2009.5459260}}

@inproceedings{robicquet2016learning,
  author    = {Robicquet, A. and Sadeghian, A. and Alahi, A. and Savarese, S.},
  title     = {Learning Social Etiquette: Human Trajectory Prediction in Crowded Scenes},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year      = {2016}
}

@article{RobotCarDatasetIJRR,
  Author = {Will Maddern and Geoff Pascoe and Chris Linegar and Paul Newman},
  Title = {{1 Year, 1000km: The Oxford RobotCar Dataset}},
  Journal = {The International Journal of Robotics Research (IJRR)},
  Volume = {36},
  Number = {1},
  Pages = {3-15},
  Year = {2017},
  doi = {10.1177/0278364916679498},
  URL =
{http://dx.doi.org/10.1177/0278364916679498},
  eprint =
{http://ijr.sagepub.com/content/early/2016/11/28/0278364916679498.full.pdf+html},
  Pdf = {http://robotcar-dataset.robots.ox.ac.uk/images/robotcar_ijrr.pdf}}

@inproceedings{Cordts2016Cityscapes,
title={The Cityscapes Dataset for Semantic Urban Scene Understanding},
author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
booktitle={Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2016}
}
@INPROCEEDINGS{5980145,
  author={Yun Jiang and Moseson, Stephen and Saxena, Ashutosh},
  booktitle={2011 IEEE International Conference on Robotics and Automation}, 
  title={Efficient grasping from RGBD images: Learning using a new rectangle representation}, 
  year={2011},
  volume={},
  number={},
  pages={3304-3311},
  keywords={Grasping;Grippers;Histograms;Three dimensional displays;Robots;Complexity theory;Image edge detection},
  doi={10.1109/ICRA.2011.5980145}}

@misc{chang2015shapenetinformationrich3dmodel,
      title={ShapeNet: An Information-Rich 3D Model Repository}, 
      author={Angel X. Chang and Thomas Funkhouser and Leonidas Guibas and Pat Hanrahan and Qixing Huang and Zimo Li and Silvio Savarese and Manolis Savva and Shuran Song and Hao Su and Jianxiong Xiao and Li Yi and Fisher Yu},
      year={2015},
      eprint={1512.03012},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/1512.03012}, 
}
@article{khansari-zadeh2011learning,
  author    = {Khansari-Zadeh, S. M. and Billard, A.},
  title     = {Learning Stable Non-Linear Dynamical Systems with Gaussian Mixture Models},
  journal   = {IEEE Transactions on Robotics},
  volume    = {27},
  number    = {5},
  pages     = {943--957},
  year      = {2011}
}

@misc{freire2009wall,
  author    = {Freire, A. and Veloso, M. and Barreto, G.},
  title     = {Wall-Following Robot Navigation Data},
  year      = {2009},
  howpublished = {UCI Machine Learning Repository},
  doi       = {10.24432/C57C8W}
}

@article{weinstein2013cancer,
  author    = {Weinstein, John N. and others},
  title     = {The Cancer Genome Atlas},
  journal   = {Nature Genetics},
  year      = {2013}
}

@misc{johnson2016mimiciii,
  author    = {Johnson, Alistair and Pollard, Tom and Mark, Roger},
  title     = {MIMIC-III Clinical Database (version 1.4)},
  year      = {2016},
  publisher = {PhysioNet},
  doi       = {10.13026/C2XW26},
  url       = {https://doi.org/10.13026/C2XW26}
}

@article{johnson2016mimiciii_data,
  author    = {Johnson, Alistair E. W. and Pollard, Tom J. and Shen, Li-Wei and Lehman, Li-Wei H. and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Celi, Leo Anthony and Mark, Roger G.},
  title     = {MIMIC-III, a freely accessible critical care database},
  journal   = {Scientific Data},
  volume    = {3},
  pages     = {160035},
  year      = {2016},
  doi       = {10.1038/sdata.2016.35}
}

@article{goldberger2000physionet,
  author    = {Goldberger, Ary L. and Amaral, Luis A. N. and Glass, Leon and Hausdorff, Jeffrey M. and Ivanov, Plamen Ch. and Mark, Roger and Stanley, H. Eugene},
  title     = {PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals},
  journal   = {Circulation},
  volume    = {101},
  number    = {23},
  pages     = {e215--e220},
  year      = {2000}
}

@misc{perezalday2020ecg,
  author    = {Perez Alday, E. A. and others},
  title     = {Classification of 12-lead ECGs: the PhysioNet – Computing in Cardiology Challenge 2020 (version 1.0.1)},
  year      = {2020},
  publisher = {PhysioNet}
}

@inproceedings{clifford2017af,
  author    = {Clifford, G. D. and others},
  title     = {AF classification from a short single lead ECG recording: the PhysioNet/Computing in Cardiology Challenge 2017},
  booktitle = {Computing in Cardiology},
  pages     = {1--4},
  year      = {2017}
}

@article{campello2021mnms,
  author    = {Campello, V. M. and others},
  title     = {Multi-Centre, Multi-Vendor and Multi-Disease Cardiac Segmentation: The M\&Ms Challenge},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2021},
  doi       = {10.1109/TMI.2021.3090082}
}

@article{martin-isla2023mnms,
  author    = {Martín-Isla, C. and others},
  title     = {Deep Learning Segmentation of the Right Ventricle in Cardiac MRI: The M\&Ms Challenge},
  journal   = {IEEE Journal of Biomedical and Health Informatics},
  year      = {2023},
  doi       = {10.1109/JBHI.2023.3267857}
}

@article{litjens2018camelyon,
  author    = {Geert Litjens and Peter Bandi and Babak Ehteshami Bejnordi and Oscar Geessink and Maschenka Balkenhol and Peter Bult and Altuna Halilovic and Meyke Hermsen and Rob van de Loo and Rob Vogels and Quirine F. Manson and Nikolas Stathonikos and Alexi Baidoshvili and Paul van Diest and Carla Wauters and Marcory van Dijk and Jeroen van der Laak},
  title     = {1399 H\&E-stained sentinel lymph node sections of breast cancer patients: the CAMELYON dataset},
  journal   = {GigaScience},
  year      = {2018},
  doi       = {10.1093/gigascience/giy065}
}

@article{bejnordi2017camelyon16,
  author    = {Babak Ehteshami Bejnordi and Mitko Veta and Paul Johannes van Diest and Bram van Ginneken and Nico Karssemeijer and Geert Litjens and Jeroen A. W. M. van der Laak and the CAMELYON16 Consortium},
  title     = {Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer},
  journal   = {JAMA},
  volume    = {318},
  number    = {22},
  pages     = {2199--2210},
  year      = {2017},
  doi       = {10.1001/jama.2017.14585}
}

@article{bandi2018camelyon17,
  author    = {Peter Bandi and Oscar Geessink and Quirine Manson and Marcory van Dijk and Maschenka Balkenhol and Meyke Hermsen and Babak Ehteshami Bejnordi and Byungjae Lee and Kyunghyun Paeng and Aoxiao Zhong and Quanzheng Li and Farhad Ghazvinian Zanjani and Svitlana Zinger and Keisuke Fukuta and Daisuke Komura and Vlado Ovtcharov and Shenghua Cheng and Shaoqun Zeng and Jeppe Thagaard and Anders B. Dahl and Huangjing Lin and Hao Chen and Ludwig Jacobsson and Martin Hedlund and Melih Cetin and Eren Halici and Hunter Jackson and Richard Chen and Fabian Both and Jorg Franke and Heidi Kusters-Vandevelde and Willem Vreuls and Peter Bult and Bram van Ginneken and Jeroen van der Laak and Geert Litjens},
  title     = {From detection of individual metastases to classification of lymph node status at the patient level: the CAMELYON17 challenge},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2018},
  doi       = {10.1109/TMI.2018.2867350}
}

@inproceedings{skinset,
author = {Sun, Xiaoxiao and Yang, Jufeng and Sun, Ming and Wang, Kai},
year = {2016},
month = {10},
pages = {206-222},
title = {A Benchmark for Automatic Visual Classification of Clinical Skin Disease Images},
volume = {9910},
isbn = {978-3-319-46465-7},
doi = {10.1007/978-3-319-46466-4_13}
}

@misc{codella2019skinlesionanalysismelanoma,
      title={Skin Lesion Analysis Toward Melanoma Detection 2018: A Challenge Hosted by the International Skin Imaging Collaboration (ISIC)}, 
      author={Noel Codella and Veronica Rotemberg and Philipp Tschandl and M. Emre Celebi and Stephen Dusza and David Gutman and Brian Helba and Aadi Kalloo and Konstantinos Liopyris and Michael Marchetti and Harald Kittler and Allan Halpern},
      year={2019},
      eprint={1902.03368},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1902.03368}, 
}
@misc{guttag2010chb,
  author       = {John Guttag},
  title        = {{CHB-MIT Scalp EEG Database} (version 1.0.0)},
  year         = {2010},
  publisher    = {PhysioNet},
  doi          = {10.13026/C2K01R},
  url          = {https://doi.org/10.13026/C2K01R}
}

@misc{armato2015lidc,
  author       = {Armato III, S. G. and McLennan, G. and Bidaut, L. and McNitt-Gray, M. F. and Meyer, C. R. and Reeves, A. P. and Zhao, B. and Aberle, D. R. and Henschke, C. I. and Hoffman, E. A. and Kazerooni, E. A. and MacMahon, H. and Van Beek, E. J. R. and Yankelevitz, D. and Biancardi, A. M. and Bland, P. H. and Brown, M. S. and Engelmann, R. M. and Laderach, G. E. and Max, D. and Pais, R. C. and Qing, D. P. Y. and Roberts, R. Y. and Smith, A. R. and Starkey, A. and Batra, P. and Caligiuri, P. and Farooqi, A. and Gladish, G. W. and Jude, C. M. and Munden, R. F. and Petkovska, I. and Quint, L. E. and Schwartz, L. H. and Sundaram, B. and Dodd, L. E. and Fenimore, C. and Gur, D. and Petrick, N. and Freymann, J. and Kirby, J. and Hughes, B. and Casteele, A. V. and Gupte, S. and Sallam, M. and Heath, M. D. and Kuhn, M. H. and Dharaiya, E. and Burns, R. and Fryd, D. S. and Salganicoff, M. and Anand, V. and Shreter, U. and Vastagh, S. and Croft, B. Y. and Clarke, L. P.},
  title        = {Data From LIDC-IDRI [Data set]},
  year         = {2015},
  publisher    = {The Cancer Imaging Archive},
  doi          = {10.7937/K9/TCIA.2015.LO9QL9SX},
  url          = {https://doi.org/10.7937/K9/TCIA.2015.LO9QL9SX}
}

@article{Yang_2023,
   title={MedMNIST v2 - A large-scale lightweight benchmark for 2D and 3D biomedical image classification},
   volume={10},
   ISSN={2052-4463},
   url={http://dx.doi.org/10.1038/s41597-022-01721-8},
   DOI={10.1038/s41597-022-01721-8},
   number={1},
   journal={Scientific Data},
   publisher={Springer Science and Business Media LLC},
   author={Yang, Jiancheng and Shi, Rui and Wei, Donglai and Liu, Zequan and Zhao, Lin and Ke, Bilian and Pfister, Hanspeter and Ni, Bingbing},
   year={2023},
   month={jan} 
}
@inproceedings{roy2023l3dmclifelonglearningusing,
  title={L3DMC: Lifelong learning using distillation via mixed-curvature space},
  author={Roy, Kaushik and Moghadam, Peyman and Harandi, Mehrtash},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={123--133},
  year={2023},
  organization={Springer}
}
@misc{ayromlou2022classimpressiondatafreeincremental,
      title={Class Impression for Data-free Incremental Learning}, 
      author={Sana Ayromlou and Purang Abolmaesumi and Teresa Tsang and Xiaoxiao Li},
      year={2022},
      eprint={2207.00005},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2207.00005}, 
}

@incollection{MCCLOSKEY1989109,
title = {Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem},
editor = {Gordon H. Bower},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {24},
pages = {109-165},
year = {1989},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(08)60536-8},
url = {https://www.sciencedirect.com/science/article/pii/S0079742108605368},
author = {Michael McCloskey and Neal J. Cohen},
abstract = {Publisher Summary
Connectionist networks in which information is stored in weights on connections among simple processing units have attracted considerable interest in cognitive science. Much of the interest centers around two characteristics of these networks. First, the weights on connections between units need not be prewired by the model builder but rather may be established through training in which items to be learned are presented repeatedly to the network and the connection weights are adjusted in small increments according to a learning algorithm. Second, the networks may represent information in a distributed fashion. This chapter discusses the catastrophic interference in connectionist networks. Distributed representations established through the application of learning algorithms have several properties that are claimed to be desirable from the standpoint of modeling human cognition. These properties include content-addressable memory and so-called automatic generalization in which a network trained on a set of items responds correctly to other untrained items within the same domain. New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks.}
}
@article{Robins1995CatastrophicFR,
  title={Catastrophic Forgetting, Rehearsal and Pseudorehearsal},
  author={Anthony V. Robins},
  journal={Connect. Sci.},
  year={1995},
  volume={7},
  pages={123-146},
  url={https://api.semanticscholar.org/CorpusID:22882861}
}
@article{Kirkpatrick_2017,
   title={Overcoming catastrophic forgetting in neural networks},
   volume={114},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.1611835114},
   DOI={10.1073/pnas.1611835114},
   number={13},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
   year={2017},
   month=mar, pages={3521–3526} }

@misc{rusu2016progressiveneuralnetworks,
      title={Progressive Neural Networks}, 
      author={Andrei A. Rusu and Neil C. Rabinowitz and Guillaume Desjardins and Hubert Soyer and James Kirkpatrick and Koray Kavukcuoglu and Razvan Pascanu and Raia Hadsell},
      year={2016},
      eprint={1606.04671},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1606.04671}, 
}
@misc{vandeven2019scenarioscontinuallearning,
      title={Three scenarios for continual learning}, 
      author={Gido M. van de Ven and Andreas S. Tolias},
      year={2019},
      eprint={1904.07734},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1904.07734}, 
}

@article{xia2017aid,
  title={AID: A benchmark data set for performance evaluation of aerial scene classification},
  author={Xia, Gui-Song and Hu, Jingwen and Hu, Fan and Shi, Baoguang and Bai, Xiang and Zhong, Yanfei and Zhang, Liangpei and Lu, Xiaoqiang},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={55},
  number={7},
  pages={3965--3981},
  year={2017},
  publisher={IEEE}
}

@article{li2017rsi,
  title={RSI-CB: A large scale remote sensing image classification benchmark via crowdsource data},
  author={Li, Haifeng and Dou, Xin and Tao, Chao and Hou, Zhixiang and Chen, Jie and Peng, Jian and Deng, Min and Zhao, Ling},
  journal={arXiv preprint arXiv:1705.10450},
  year={2017}
}

@article{cheng2017remote,
  title={Remote sensing image scene classification: Benchmark and state of the art},
  author={Cheng, Gong and Han, Junwei and Lu, Xiaoqiang},
  journal={Proceedings of the IEEE},
  volume={105},
  number={10},
  pages={1865--1883},
  year={2017},
  publisher={IEEE}
}

@inproceedings{demir2018deepglobe,
  title={Deepglobe 2018: A challenge to parse the earth through satellite images},
  author={Demir, Ilke and Koperski, Krzysztof and Lindenbaum, David and Pang, Guan and Huang, Jing and Basu, Saikat and Hughes, Forest and Tuia, Devis and Raskar, Ramesh},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={172--181},
  year={2018}
}

@inproceedings{waqas2019isaid,
  title={isaid: A large-scale dataset for instance segmentation in aerial images},
  author={Waqas Zamir, Syed and Arora, Aditya and Gupta, Akshita and Khan, Salman and Sun, Guolei and Shahbaz Khan, Fahad and Zhu, Fan and Shao, Ling and Xia, Gui-Song and Bai, Xiang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={28--37},
  year={2019}
}

@article{helber2019eurosat,
  title={Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification},
  author={Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={12},
  number={7},
  pages={2217--2226},
  year={2019},
  publisher={IEEE}
}

@inproceedings{xia2018dota,
  title={DOTA: A large-scale dataset for object detection in aerial images},
  author={Xia, Gui-Song and Bai, Xiang and Ding, Jian and Zhu, Zhen and Belongie, Serge and Luo, Jiebo and Datcu, Mihai and Pelillo, Marcello and Zhang, Liangpei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3974--3983},
  year={2018}
}

@article{li2020object,
  title={Object detection in optical remote sensing images: A survey and a new benchmark},
  author={Li, Ke and Wan, Gang and Cheng, Gong and Meng, Liqiu and Han, Junwei},
  journal={ISPRS journal of photogrammetry and remote sensing},
  volume={159},
  pages={296--307},
  year={2020},
  publisher={Elsevier}
}

@article{han2021soda10m,
  title={SODA10M: A large-scale 2D self/semi-supervised object detection dataset for autonomous driving},
  author={Han, Jianhua and Liang, Xiwen and Xu, Hang and Chen, Kai and Hong, Lanqing and Mao, Jiageng and Ye, Chaoqiang and Zhang, Wei and Li, Zhenguo and Liang, Xiaodan and others},
  journal={arXiv preprint arXiv:2106.11118},
  year={2021}
}

@inproceedings{yu2020bdd100k,
  title={Bdd100k: A diverse driving dataset for heterogeneous multitask learning},
  author={Yu, Fisher and Chen, Haofeng and Wang, Xin and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Madhavan, Vashisht and Darrell, Trevor},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2636--2645},
  year={2020}
}

@inproceedings{yang2019drivingstereo,
  title={Drivingstereo: A large-scale dataset for stereo matching in autonomous driving scenarios},
  author={Yang, Guorun and Song, Xiao and Huang, Chaoqin and Deng, Zhidong and Shi, Jianping and Zhou, Bolei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={899--908},
  year={2019}
}

@article{zhan2019interaction,
  title={Interaction dataset: An international, adversarial and cooperative motion dataset in interactive driving scenarios with semantic maps},
  author={Zhan, Wei and Sun, Liting and Wang, Di and Shi, Haojie and Clausse, Aubrey and Naumann, Maximilian and Kummerle, Julius and Konigshof, Hendrik and Stiller, Christoph and de La Fortelle, Arnaud and others},
  journal={arXiv preprint arXiv:1910.03088},
  year={2019}
}

@inproceedings{geiger2012we,
  title={Are we ready for autonomous driving? the kitti vision benchmark suite},
  author={Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={3354--3361},
  year={2012},
  organization={IEEE}
}

@inproceedings{Kumari2023ContinualLI,
  title={Continual Learning in Medical Image Analysis: A Comprehensive Review of Recent Advancements and Future Prospects},
  author={Pratibha Kumari and Joohi Chauhan and Afshin Bozorgpour and Reza Azad and Dorit Merhof},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:266573443}
}
@inproceedings{cui2024learning,
  title={Learning continual compatible representation for re-indexing free lifelong person re-identification},
  author={Cui, Zhenyu and Zhou, Jiahuan and Wang, Xun and Zhu, Manyu and Peng, Yuxin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16614--16623},
  year={2024}
}
@inproceedings{xu2024distribution,
  title={Distribution-aware knowledge prototyping for non-exemplar lifelong person re-identification},
  author={Xu, Kunlun and Zou, Xu and Peng, Yuxin and Zhou, Jiahuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16604--16613},
  year={2024}
}
@inproceedings{pu2021lifelong,
  title={Lifelong person re-identification via adaptive knowledge accumulation},
  author={Pu, Nan and Chen, Wei and Liu, Yu and Bakker, Erwin M and Lew, Michael S},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7901--7910},
  year={2021}
}
@article{li2024exemplar,
  title={Exemplar-Free Lifelong Person Re-identification via Prompt-Guided Adaptive Knowledge Consolidation},
  author={Li, Qiwei and Xu, Kunlun and Peng, Yuxin and Zhou, Jiahuan},
  journal={International Journal of Computer Vision},
  volume={132},
  number={11},
  pages={4850--4865},
  year={2024},
  publisher={Springer}
}
@inproceedings{yang2023prompt,
  title={Prompt Based Lifelong Person Re-identification},
  author={Yang, Chengde and Zhang, Yan and Dai, Pingyang},
  booktitle={Chinese Conference on Pattern Recognition and Computer Vision (PRCV)},
  pages={418--431},
  year={2023},
  organization={Springer}
}
@inproceedings{sugianto2019continuous,
  title={Continuous learning without forgetting for person re-identification},
  author={Sugianto, Nehemia and Tjondronegoro, Dian and Sorwar, Golam and Chakraborty, Prithwi and Yuwono, Elizabeth Irenne},
  booktitle={2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}
@inproceedings{wu2021generalising,
  title={Generalising without forgetting for lifelong person re-identification},
  author={Wu, Guile and Gong, Shaogang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={4},
  pages={2889--2897},
  year={2021}
}
@inproceedings{yu2023lifelong,
  title={Lifelong person re-identification via knowledge refreshing and consolidation},
  author={Yu, Chunlin and Shi, Ye and Liu, Zimo and Gao, Shenghua and Wang, Jingya},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={37},
  number={3},
  pages={3295--3303},
  year={2023}
}
@inproceedings{pu2022meta,
  title={Meta reconciliation normalization for lifelong person re-identification},
  author={Pu, Nan and Liu, Yu and Chen, Wei and Bakker, Erwin M and Lew, Michael S},
  booktitle={Proceedings of the 30th ACM international conference on multimedia},
  pages={541--549},
  year={2022}
}
@inproceedings{xu2024lstkc,
  title={Lstkc: Long short-term knowledge consolidation for lifelong person re-identification},
  author={Xu, Kunlun and Zou, Xu and Zhou, Jiahuan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={14},
  pages={16202--16210},
  year={2024}
}
@article{liu2024gcreid,
  title={GCReID: Generalized continual person re-identification via meta learning and knowledge accumulation},
  author={Liu, Zhaoshuo and Feng, Chaolu and Yu, Kun and Hu, Jun and Yang, Jinzhu},
  journal={Neural Networks},
  volume={179},
  pages={106561},
  year={2024},
  publisher={Elsevier}
}
@inproceedings{zhang2019learning,
  title={Learning incremental triplet margin for person re-identification},
  author={Zhang, Yingying and Zhong, Qiaoyong and Ma, Liang and Xie, Di and Pu, Shiliang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={9243--9250},
  year={2019}
}
@article{pu2023memorizing,
  title={A memorizing and generalizing framework for lifelong person re-identification},
  author={Pu, Nan and Zhong, Zhun and Sebe, Nicu and Lew, Michael S},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={11},
  pages={13567--13585},
  year={2023},
  publisher={IEEE}
}
@inproceedings{lu2022augmented,
  title={Augmented geometric distillation for data-free incremental person reid},
  author={Lu, Yichen and Wang, Mei and Deng, Weihong},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7329--7338},
  year={2022}
}
@inproceedings{wang2020smoothing,
  title={Smoothing adversarial domain attack and p-memory reconsolidation for cross-domain person re-identification},
  author={Wang, Guangcong and Lai, Jian-Huang and Liang, Wenqi and Wang, Guangrun},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10568--10577},
  year={2020}
}
@article{liu2023knowledge,
  title={Knowledge-preserving continual person re-identification using graph attention network},
  author={Liu, Zhaoshuo and Feng, Chaolu and Chen, Shuaizheng and Hu, Jun},
  journal={Neural Networks},
  volume={161},
  pages={105--115},
  year={2023},
  publisher={Elsevier}
}
@inproceedings{yang2024privacy,
  title={Privacy-Preserving Replay and Adaptive Relation Distillation for Camera Incremental Person Re-Identification},
  author={Yang, Zexian and Wu, Dayan and Zhang, Wanqian and Gu, Jingzi and Lin, Zheng and Wang, Weiping},
  booktitle={2024 IEEE International Conference on Multimedia and Expo (ICME)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}
@article{chen2023camera,
  title={Camera-aware recurrent learning and earth mover’s test-time adaption for generalizable person re-identification},
  author={Chen, Kaixiang and Gong, Tiantian and Zhang, Liyan},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={34},
  number={1},
  pages={357--370},
  year={2023},
  publisher={IEEE}
}
@article{yao2024camera,
  title={Camera-Incremental Object Re-Identification With Identity Knowledge Evolution},
  author={Yao, Hantao and Luo, Jifei and Yu, Lu and Xu, Changsheng},
  journal={IEEE Transactions on Multimedia},
  year={2024},
  publisher={IEEE}
}
@inproceedings{yang2023handling,
  title={Handling label uncertainty for camera incremental person re-identification},
  author={Yang, Zexian and Wu, Dayan and Zhang, Wanqian and Li, Bo and Wang, Weipinng},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={6253--6263},
  year={2023}
}
@article{wang2025distribution,
  title={Distribution aligned semantics adaption for lifelong person re-identification},
  author={Wang, Qizao and Qian, Xuelin and Li, Bin and Xue, Xiangyang},
  journal={Machine Learning},
  volume={114},
  number={3},
  pages={1--22},
  year={2025},
  publisher={Springer}
}
@inproceedings{huang2022lifelong,
  title={Lifelong unsupervised domain adaptive person re-identification with coordinated anti-forgetting and adaptation},
  author={Huang, Zhipeng and Zhang, Zhizheng and Lan, Cuiling and Zeng, Wenjun and Chu, Peng and You, Quanzeng and Wang, Jiang and Liu, Zicheng and Zha, Zheng-jun},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={14288--14297},
  year={2022}
}
@inproceedings{zhao2021continual,
  title={Continual representation learning for biometric identification},
  author={Zhao, Bo and Tang, Shixiang and Chen, Dapeng and Bilen, Hakan and Zhao, Rui},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={1198--1208},
  year={2021}
}
@inproceedings{ge2022lifelong,
  title={Lifelong person re-identification by pseudo task knowledge preservation},
  author={Ge, Wenhang and Du, Junlong and Wu, Ancong and Xian, Yuqiao and Yan, Ke and Huang, Feiyue and Zheng, Wei-Shi},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={36},
  number={1},
  pages={688--696},
  year={2022}
}
@inproceedings{sun2022patch,
  title={Patch-based knowledge distillation for lifelong person re-identification},
  author={Sun, Zhicheng and Mu, Yadong},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={696--707},
  year={2022}
}
@inproceedings{huang2022manifold,
  title={Manifold-Driven and Feature Replay Lifelong Representation Learning on Person ReID},
  author={Huang, Tianjun and Zhang, Jianguo},
  booktitle={Chinese Conference on Pattern Recognition and Computer Vision (PRCV)},
  pages={428--440},
  year={2022},
  organization={Springer}
}

@article{ammour2021continual,
  title={Continual learning using data regeneration for remote sensing scene classification},
  author={Ammour, Nassim},
  journal={IEEE Geoscience and Remote Sensing Letters},
  volume={19},
  pages={1--5},
  year={2021},
  publisher={IEEE}
}

@article{li2024robust,
  title={Robust Self-Paced Incremental Learning for Multitemporal Remote Sensing Image Classification},
  author={Li, Hao and Niu, Pengyang and Gong, Maoguo and Xing, Lining and Wu, Yue and Qin, A Kai},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

@article{li2022structural,
  title={Structural attention enhanced continual meta-learning for graph edge labeling based few-shot remote sensing scene classification},
  author={Li, Feimo and Li, Shuaibo and Fan, Xinxin and Li, Xiong and Chang, Hongxing},
  journal={Remote Sensing},
  volume={14},
  number={3},
  pages={485},
  year={2022},
  publisher={MDPI}
}

@article{ma2024unsupervised,
  title={Unsupervised Few-Shot Continual Learning for Remote Sensing Image Scene Classification},
  author={Ma’sum, Muhammad Anwar and Pratama, Mahardhika and Savitha, Ramasamy and Liu, Lin and Kowalczyk, Ryszard and others},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

@inproceedings{sun2024evaluation,
  title={An Evaluation of Representative Samples Replay and Knowledge Distillation Regularization for SAR ATR Continual Learning},
  author={Sun, Hao and Xu, Yanjie and Fu, Kai and Lei, Lin and Ji, Kefeng and Kuang, Gangyao},
  booktitle={2024 Photonics \& Electromagnetics Research Symposium (PIERS)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}

@inproceedings{liang2024conda,
  title={ConDA: Continual Adaptation in Remote Sensing Via Visual Style Playback},
  author={Liang, Shi and Zhong, Ketao and Zhao, Dong and Yang, Hu and Wang, Shuang and Guo, Yanhe},
  booktitle={IGARSS 2024-2024 IEEE International Geoscience and Remote Sensing Symposium},
  pages={8339--8342},
  year={2024},
  organization={IEEE}
}

@article{wang2024gradient,
  title={Gradient guided multi-scale feature collaboration networks for few-shot class-incremental remote sensing scene classification},
  author={Wang, Wuli and Zhang, Li and Fu, Sichao and Ren, Peng and Ren, Guangbo and Peng, Qinmu and Liu, Baodi},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

@article{zhang2024towards,
  title={Towards Cross-domain Class-incremental Remote Sensing Scene Classification},
  author={Zhang, Li and Fu, Sichao and Wang, Wuli and Ren, Peng and Peng, Qinmu and Ren, Guangbo and Liu, Baodi},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

@inproceedings{yu2023incremented,
  title={Incremented Scene Classification on Satellite Imagery Using Feature Map Distillation and Classifier Discrepancy},
  author={Yu, Chih-Chang and Chen, Tzu-Ying and Cheng, Hsu-Yung},
  booktitle={IGARSS 2023-2023 IEEE International Geoscience and Remote Sensing Symposium},
  pages={289--292},
  year={2023},
  organization={IEEE}
}

@article{liu2022incremental,
  title={Incremental learning with open-set recognition for remote sensing image scene classification},
  author={Liu, Weiwei and Nie, Xiangli and Zhang, Bo and Sun, Xian},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--16},
  year={2022},
  publisher={IEEE}
}
@article{de2021continual,
  title={A continual learning survey: Defying forgetting in classification tasks},
  author={De Lange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ale{\v{s}} and Slabaugh, Gregory and Tuytelaars, Tinne},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={7},
  pages={3366--3385},
  year={2021},
  publisher={IEEE}
}

@inproceedings{smith2023closer,
  title={A closer look at rehearsal-free continual learning},
  author={Smith, James Seale and Tian, Junjiao and Halbe, Shaunak and Hsu, Yen-Chang and Kira, Zsolt},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2410--2420},
  year={2023}
}

@inproceedings{lapacz2025exploring,
  title={Exploring the stability gap in continual learning: The role of the classification head},
  author={{\L}apacz, Wojciech and Marczak, Daniel and Szatkowski, Filip and Trzci{\'n}ski, Tomasz},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages={7562--7571},
  year={2025},
  organization={IEEE}
}
@inproceedings{kalb2022causes,
  title={Causes of catastrophic forgetting in class-incremental semantic segmentation},
  author={Kalb, Tobias and Beyerer, J{\"u}rgen},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  pages={56--73},
  year={2022}
}
@inproceedings{AFEC_wang,
author = {Wang, Liyuan and Zhang, Mingtian and Jia, Zhongfan and Li, Qian and Ma, Kaisheng and Bao, Chenglong and Zhu, Jun and Zhong, Yi},
title = {AFEC: active forgetting of negative transfer in continual learning},
year = {2021},
isbn = {9781713845393},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
articleno = {1714},
numpages = {13},
series = {NIPS '21}
}

@inproceedings{jin2022helpful,
  title={Helpful or harmful: Inter-task association in continual learning},
  author={Jin, Hyundong and Kim, Eunwoo},
  booktitle={European Conference on Computer Vision},
  pages={519--535},
  year={2022},
  organization={Springer}
}
@article{jung2020continual,
  title={Continual learning with node-importance based adaptive group sparse regularization},
  author={Jung, Sangwon and Ahn, Hongjoon and Cha, Sungmin and Moon, Taesup},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={3647--3658},
  year={2020}
}
@inproceedings{kang2022forget,
  title={Forget-free continual learning with winning subnetworks},
  author={Kang, Haeyong and Mina, Rusty John Lloyd and Madjid, Sultan Rizky Hikmawan and Yoon, Jaehong and Hasegawa-Johnson, Mark and Hwang, Sung Ju and Yoo, Chang D},
  booktitle={International Conference on Machine Learning},
  pages={10734--10750},
  year={2022},
  organization={PMLR}
}
@article{zhang2024dc,
  title={DC 2 T: Disentanglement-Guided Consolidation and Consistency Training for Semi-Supervised Cross-Site Continual Segmentation},
  author={Zhang, Jingyang and Pei, Jialun and Xu, Dunyuan and Jin, Yueming and Heng, Pheng-Ann},
  journal={IEEE Transactions on Medical Imaging},
  year={2024},
  publisher={IEEE}
}
@inproceedings{ceccon2025multi,
  title={Multi-label continual learning for the medical domain: A novel benchmark},
  author={Ceccon, Marina and Dalle Pezze, Davide and Fabris, Alessandro and Susto, Gian Antonio},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages={7163--7172},
  year={2025},
  organization={IEEE}
}
@article{tasai2025continual,
  title={Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images},
  author={Tasai, Ren and Li, Guang and Togo, Ren and Tang, Minghui and Yoshimura, Takaaki and Sugimori, Hiroyuki and Hirata, Kenji and Ogawa, Takahiro and Kudo, Kohsuke and Haseyama, Miki},
  journal={arXiv preprint arXiv:2501.04217},
  year={2025}
}
@inproceedings{patra2025attention,
  title={Attention Aware Continual Learning in Digital Pathology Contexts},
  author={Patra, Arijit and Chakraborti, Tapabrata},
  booktitle={2025 IEEE 22nd International Symposium on Biomedical Imaging (ISBI)},
  pages={1--5},
  year={2025},
  organization={IEEE}
}
@article{xu2025towards,
  title={Towards Synchronous Memorizability and Generalizability with Site-Modulated Diffusion Replay for Cross-Site Continual Segmentation},
  author={Xu, Dunyuan and Wang, Xi and Li, Jinpeng and Zhang, Jingyang and Heng, Pheng-Ann},
  journal={IEEE Transactions on Medical Imaging},
  year={2025},
  publisher={IEEE}
}
@inproceedings{zhao2025aidc,
  title={AIDC: Benchmark for Analytical Learning in Incremental Disease Classification},
  author={Zhao, Rongchang and Qi, Jianyu and Li, Rui and Zheng, Zhijie and Zhang, Jian and Li, Jiaxu},
  booktitle={ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2025},
  organization={IEEE}
}
@inproceedings{ranem2025ncadapt,
  title={NCAdapt: Dynamic adaptation with domain-specific Neural Cellular Automata for continual hippocampus segmentation},
  author={Ranem, Amin and Kalkhof, John and Mukhopadhyay, Anirban},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages={3834--3843},
  year={2025},
  organization={IEEE}
}
@article{wang2025cross,
  title={Cross-Domain Invariant Feature Absorption and Domain-Specific Feature Retention for Domain Incremental Chest X-Ray Classification},
  author={Wang, Mengchu and He, Yuhang and Peng, Lin and Song, Xiang and Dong, Songlin and Gong, Yihong},
  journal={IEEE Transactions on Medical Imaging},
  year={2025},
  publisher={IEEE}
}
@inproceedings{luo2025bid,
  title={BID-Net: Balanced Incremental Distillation Network for Fair Dermatological Disease Diagnosis},
  author={Luo, Yiqin and Gu, Tianlong and Hao, Fengrui and Chang, Liang},
  booktitle={ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2025},
  organization={IEEE}
}
@inproceedings{kumar2025pathology,
  title={Pathology Image Classification for Colorectal Cancer Prediction Using Experience Replay},
  author={Kumar, Penumacha Naveen and Krishna, Ch Nanda and Lukka, Sai Lasya},
  booktitle={2025 International Conference on Computational, Communication and Information Technology (ICCCIT)},
  pages={497--502},
  year={2025},
  organization={IEEE}
}
@inproceedings{wang2025enhancing,
  title={Enhancing Continual Learning for Medical Imaging: Efficient Knowledge Transfer and Multi-Disease Prediction},
  author={Wang, Enzhi and Li, Qicheng and Liu, Di and Yang, Bo},
  booktitle={ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2025},
  organization={IEEE}
}
@article{iqbal2025transforming,
  title={Transforming Healthcare Diagnostics With Tensorized Attention and Continual Learning on Multi-Modal Data},
  author={Iqbal, Saeed and Zhong, Xiaopin and Khan, Muhammad Attique and Shabaz, Mohammad and Wu, Zongze and AlHammadi, Dina Abdulaziz and Liu, Weixiang and Algamdi, Shabbab Ali and Li, Yang},
  journal={IEEE Transactions on Consumer Electronics},
  year={2025},
  publisher={IEEE}
}
@article{luo2025llm,
  title={LLM-guided Decoupled Probabilistic Prompt for Continual Learning in Medical Image Diagnosis},
  author={Luo, Yiwen and Li, Wuyang and Chen, Cheng and Li, Xiang and Liu, Tianming and Niu, Tianye and Yuan, Yixuan},
  journal={IEEE Transactions on Medical Imaging},
  year={2025},
  publisher={IEEE}
}
@article{wang2025efficient,
  title={An efficient fine tuning strategy of segment anything model for polyp segmentation},
  author={Wang, Mingyan and Xu, Cun and Fan, Kefeng},
  journal={Scientific Reports},
  volume={15},
  number={1},
  pages={14088},
  year={2025},
  publisher={Nature Publishing Group UK London}
}
@article{musa2025addressing,
  title={Addressing cross-population domain shift in chest X-ray classification through supervised adversarial domain adaptation},
  author={Musa, Aminu and Prasad, Rajesh and Hernandez, Monica},
  journal={Scientific Reports},
  volume={15},
  number={1},
  pages={11383},
  year={2025},
  publisher={Nature Publishing Group UK London}
}
@inproceedings{liang2025incremental,
  title={Incremental Object Keypoint Learning},
  author={Liang, Mingfu and Zhou, Jiahuan and Zou, Xu and Wu, Ying},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={25399--25410},
  year={2025}
}
@inproceedings{li2025advancing,
  title={Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging},
  author={Li, Xianrui and Cui, Yufei and Li, Jun and Chan, Antoni B},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={20800--20809},
  year={2025}
}
@article{aslam2025cel,
  title={Cel: A continual learning model for disease outbreak prediction by leveraging domain adaptation via elastic weight consolidation},
  author={Aslam, Saba and Rasool, Abdur and Li, Xiaoli and Wu, Hongyan},
  journal={Interdisciplinary Sciences: Computational Life Sciences},
  pages={1--19},
  year={2025},
  publisher={Springer}
}
@article{wang2025cross2,
  title={Cross-Scenario End-to-End Motion Planning in Off-Road Environment: A Lifelong Learning Perspective},
  author={Wang, Yuchun and Gong, Cheng and Gong, Jianwei and Li, Zirui and Zang, Zheng and Jia, Peng},
  journal={IEEE Robotics and Automation Letters},
  year={2025},
  publisher={IEEE}
}
@article{liu2024tactclnet,
  title={TactCLNet: Tactile Continual Learning Network Based on Generative Replay for Object Hardness Recognition},
  author={Liu, Yiwen and Yi, Zhengkun and Fang, Senlin and Zhang, Yupo and Wan, Feng and Yang, Zhi-Xin and Lu, Xu and Wu, Xinyu},
  journal={IEEE Transactions on Automation Science and Engineering},
  year={2024},
  publisher={IEEE}
}
@article{jiang2025continual,
  title={A Continual Learning Method for Generalized Grasping Manipulation in a Musculoskeletal Robot},
  author={Jiang, Bo and Song, Ci and Liu, Siyuan and Gan, Shuai and Chen, Jiahao},
  journal={IEEE Transactions on Automation Science and Engineering},
  year={2025},
  publisher={IEEE}
}
@article{meng2025preserving,
  title={Preserving and combining knowledge in robotic lifelong reinforcement learning},
  author={Meng, Yuan and Bing, Zhenshan and Yao, Xiangtong and Chen, Kejia and Huang, Kai and Gao, Yang and Sun, Fuchun and Knoll, Alois},
  journal={Nature Machine Intelligence},
  pages={1--14},
  year={2025},
  publisher={Nature Publishing Group UK London}
}
@inproceedings{yao2025think,
  title={Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation},
  author={Yao, Yuanqi and Liu, Siao and Song, Haoming and Qu, Delin and Chen, Qizhi and Ding, Yan and Zhao, Bin and Wang, Zhigang and Li, Xuelong and Wang, Dong},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={22573--22583},
  year={2025}
}


@inproceedings{resani2025continual,
  title={Continual learning in 3d point clouds: Employing spectral techniques for exemplar selection},
  author={Resani, Hossein and Nasihatkon, Behrooz and Jazi, Mohammadreza Alimoradi},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages={2921--2931},
  year={2025},
  organization={IEEE}
}

@article{zhuang2024online,
  title={Online Analytic Exemplar-Free Continual Learning with Large Models for Imbalanced Autonomous Driving Task},
  author={Zhuang, Huiping and Fang, Di and Tong, Kai and Liu, Yuchen and Zeng, Ziqian and Zhou, Xu and Chen, Cen},
  journal={IEEE Transactions on Vehicular Technology},
  year={2024},
  publisher={IEEE}
}

@article{yang2025human,
  title={Human-Guided Continual Learning for Personalized Decision-Making of Autonomous Driving},
  author={Yang, Haohan and Zhou, Yanxin and Wu, Jingda and Liu, Haochen and Yang, Lie and Lv, Chen},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2025},
  publisher={IEEE}
}

@article{liu2025dmotion,
  title={DMotion: Diverse Modalities Alignment Enhanced Motion Prediction for Autonomous Driving},
  author={Liu, Hongkun and Liu, Hongmin and Fan, Bin and Xu, Jinglin},
  journal={IEEE Transactions on Computational Social Systems},
  year={2025},
  publisher={IEEE}
}

@inproceedings{hazra2025reflective,
  title={Reflective Teacher: Semi-Supervised Multimodal 3D Object Detection in Bird's-Eye-View via Uncertainty Measure},
  author={Hazra, Saheli and Das, Sudip and Choudhary, Rohit and Das, Arindam and Sistu, Ganesh and Eising, Ciar{\'a}n and Bhattacharya, Ujjwal},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages={1649--1659},
  year={2025},
  organization={IEEE}
}

@inproceedings{hegde2025modality,
  title={Modality-Incremental Learning with Disjoint Relevance Mapping Networks for Image-based Semantic Segmentation},
  author={Hegde, Niharika and Muralidhara, Shishir and Schuster, Ren{\'e} and Stricker, Didier},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages={5540--5549},
  year={2025},
  organization={IEEE}
}

@article{wei2025class,
  title={Class Bias Correction Matters: A Class-Incremental Learning Framework for Remote Sensing Scene Classification},
  author={Wei, Yunze and Pan, Zongxu and Wu, Yirong},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2025},
  publisher={IEEE}
}

@article{hu2024class,
  title={A Class-Incremental Object Detection Method for Remote Sensing Images Based on Dynamic Multi-Prototype Matching},
  author={Hu, Mingtao and Yin, Wenxin and Diao, Wenhui and Gao, Xin and Sun, Xian},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

@article{li2025hyperkd,
  title={HyperKD: Lifelong hyperspectral image classification with cross spectral-spatial knowledge distillation},
  author={Li, Zhenlin and Xia, Shaobo and Yue, Jun and Fang, Leyuan},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2025},
  publisher={IEEE}
}

@article{wang2025incremental,
  title={Incremental Classification of Cross-Scene Hyperspectral Images Based on Dual Constraints and Knowledge Transfer},
  author={Wang, Ke and Li, Zhaokui and Guo, Jiaxu and Wang, Yan},
  journal={IEEE Geoscience and Remote Sensing Letters},
  year={2025},
  publisher={IEEE}
}

@article{wang2025cl,
  title={CL-BioGAN: Biologically-Inspired Cross-Domain Continual Learning for Hyperspectral Anomaly Detection},
  author={Wang, Jianing and Hua, Zheng and Zhang, Wan and Hao, Shengjia and Yao, Yuqiong and Gong, Maoguo},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2025},
  publisher={IEEE}
}

@article{jiang2025life,
  title={Life-Long Learning With Adaptive Knowledge Fusion and Class Margin Dynamic Adjustment for Hyperspectral Image Classification},
  author={Jiang, Zihui and Li, Zhaokui and Wang, Yan and Li, Wei and Wang, Ke and Tian, Jing and Wang, Chuanyun and Du, Qian},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2025},
  publisher={IEEE}
}

@article{karantaidis2025incsar,
  title={IncSAR: A Dual Fusion Incremental Learning Framework for SAR Target Recognition},
  author={Karantaidis, George and Pantsios, Athanasios and Kompatsiaris, Ioannis and Papadopoulos, Symeon},
  journal={IEEE Access},
  year={2025},
  publisher={IEEE}
}

@inproceedings{chu2025label,
  title={Label Relationship Graph-Enhanced Class Hierarchy for Incremental Classification of Remote Sensing Images},
  author={Chu, Yang and Qian, Yuntao},
  booktitle={ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2025},
  organization={IEEE}
}

@article{chen2025target,
  title={Target-Aspect Domain Continual Learning for SAR Target Recognition},
  author={Chen, Hongting and Du, Chuan and Zhu, Jinlin and Guo, Dandan},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2025},
  publisher={IEEE}
}

@article{chen2025layout,
  title={Layout-Anchored Prioritizing Continual Learning for Continuous Building Footprint Extraction From High-Resolution Remote Sensing Imagery},
  author={Chen, Dingyuan and Song, Zhaohui and Ma, Ailong and Zhong, Yanfei},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2025},
  publisher={IEEE}
}

@article{azeem2025memory,
  title={Memory-Augmented Detection Transformer for Few-Shot Object Detection in Remote Sensing Imagery},
  author={Azeem, Abdullah and Li, Zhengzhou and Siddique, Abubakar and Zhang, Yuting and Cao, Dong},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={63},
  pages={1--21},
  year={2025},
  publisher={IEEE}
}

@InProceedings{Cui_2025_CVPR,
    author    = {Cui, Zhenyu and Zhou, Jiahuan and Peng, Yuxin},
    title     = {DKC: Differentiated Knowledge Consolidation for Cloth-Hybrid Lifelong Person Re-identification},
    booktitle = {Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR)},
    month     = {June},
    year      = {2025},
    pages     = {3573-3582}
}
@ARTICLE{chen2025anti,
  author={Chen, Hao and Bremond, Francois and Sebe, Nicu and Zhang, Shiliang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Anti-Forgetting Adaptation for Unsupervised Person Re-Identification}, 
  year={2025},
  volume={47},
  number={2},
  pages={1056-1072},
  keywords={Adaptation models;Data models;Feature extraction;Contrastive learning;Prototypes;Training;Incremental learning;Cameras;Annotations;Training data;Re-identification;incremental learning;contrastive learning;domain generalization;backward compatible representation},
  doi={10.1109/TPAMI.2024.3490777}}

@inproceedings{sur2025hyperbolic,
  title={Hyperbolic Uncertainty-Aware Few-Shot Incremental Point Cloud Segmentation},
  author={Sur, Tanuj and Mukherjee, Samrat and Rahaman, Kaizer and Chaudhuri, Subhasis and Khan, Muhammad Haris and Banerjee, Biplab},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={11810--11821},
  year={2025}
}


@inproceedings{tian2025activating,
  title={Activating Sparse Part Concepts for 3D Class Incremental Learning},
  author={Tian, Zhenya and Xiao, Jun and Liu, Lupeng and Jiang, Haiyong},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={30343--30353},
  year={2025}
}

@ARTICLE{kang2025subnetworks,
  author={Kang, Haeyong and Yoon, Jaehong and Hwang, Sung Ju and Yoo, Chang D.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Continual Learning: Forget-Free Winning Subnetworks for Video Representations}, 
  year={2025},
  volume={47},
  number={3},
  pages={2140-2156},
  keywords={Wireless sensor networks;Incremental learning;Continuing education;Power capacitors;Training;Streaming media;Tail;Image representation;Natural language processing;Knowledge engineering;Continual learning (CL);task incremental learning (TIL);task-agnostic incremental learning (TaIL);video incremental learning (VIL);few-shot class incremental learning (FSCIL);regularized lottery ticket hypothesis (RLTH);wining subnetworks (WSN);soft-subnetwork (SoftNet);fourier subneural operator (FSO)},
  doi={10.1109/TPAMI.2024.3518588}
}

@InProceedings{Zou_2025_CVPR,
    author    = {Zou, Xiaohan and Ma, Wenchao and Zhao, Shu},
    title     = {Learning Conditional Space-Time Prompt Distributions for Video Class-Incremental Learning},
    booktitle = {Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR)},
    month     = {June},
    year      = {2025},
    pages     = {4862-4873}
}

@article{rusu2016progressive,
  title={Progressive neural networks},
  author={Rusu, Andrei A and Rabinowitz, Neil C and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1606.04671},
  year={2016}
}



@article{yoon2017lifelong,
  title={Lifelong learning with dynamically expandable networks},
  author={Yoon, Jaehong and Yang, Eunho and Lee, Jeongtae and Hwang, Sung Ju},
  journal={arXiv preprint arXiv:1708.01547},
  year={2017}
}

@inproceedings{veniat2020efficient,
  author       = {Tom Veniat, Ludovic Denoyer, Marc'Aurelio Ranzato},
  title        = {Efficient Continual Learning with Modular Networks and Task-Driven Priors},
  booktitle    = {9th International Conference on Learning Representations, {ICLR} 2021, Virtual Event, Austria, May 3-7,2021},
  publisher    = {OpenReview.net},
  year         = {2021},
  url          = {https://openreview.net/forum?id=EKV158tSfwv},
  timestamp    = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/VeniatDR21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{CHEN2023883,
title = {Real-time human-computer interaction using eye gazes},
journal = {Manufacturing Letters},
volume = {35},
pages = {883-894},
year = {2023},
note = {51st SME North American Manufacturing Research Conference (NAMRC 51)},
issn = {2213-8463},
doi = {https://doi.org/10.1016/j.mfglet.2023.07.024},
url = {https://www.sciencedirect.com/science/article/pii/S2213846323000561},
author = {Haodong Chen and Niloofar Zendehdel and Ming C. Leu and Zhaozheng Yin},
keywords = {Eye gaze recognition, Human-computer interaction, Instance segmentation, Mask R-CNN}
}

@inproceedings{Brown2023,
author = {Brown, Barry and Broth, Mathias and Vinkhuyzen, Erik},
title = {The Halting problem: Video analysis of self-driving cars in traffic},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581045},
doi = {10.1145/3544548.3581045},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {12},
numpages = {14},
location = {Hamburg, Germany},
series = {CHI '23}
}